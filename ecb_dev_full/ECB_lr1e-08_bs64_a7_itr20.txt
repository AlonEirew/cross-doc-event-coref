1: 6464: loss: 0.7098416692:
1: 12864: loss: 0.7092258152:
1: 19264: loss: 0.7089237920:
1: 25664: loss: 0.7086197755:
1: 32064: loss: 0.7084289823:
1: 38464: loss: 0.7083891119:
1: 44864: loss: 0.7083523446:
1: 51264: loss: 0.7082368711:
1: 57664: loss: 0.7080817464:
1: 64064: loss: 0.7079826972:
1: 70464: loss: 0.7078919226:
1: 76864: loss: 0.7077534518:
1: 83264: loss: 0.7076330823:
1: 89664: loss: 0.7075848772:
1: 96064: loss: 0.7075061240:
1: 102464: loss: 0.7073765352:
1: 108864: loss: 0.7073801977:
1: 115264: loss: 0.7073023039:
1: 121664: loss: 0.7071975653:
Dev-Acc: 1: Accuracy: 0.2943324447: precision: 0.0639279173: recall: 0.8131270192: f1: 0.1185365128
Train-Acc: 1: Accuracy: 0.3448162675: precision: 0.1386452487: recall: 0.8136874630: f1: 0.2369211922
2: 6464: loss: 0.7040370125:
2: 12864: loss: 0.7040908417:
2: 19264: loss: 0.7044615422:
2: 25664: loss: 0.7043902007:
2: 32064: loss: 0.7041991663:
2: 38464: loss: 0.7040612420:
2: 44864: loss: 0.7040696535:
2: 51264: loss: 0.7039327444:
2: 57664: loss: 0.7038545669:
2: 64064: loss: 0.7037645562:
2: 70464: loss: 0.7036734324:
2: 76864: loss: 0.7036350994:
2: 83264: loss: 0.7036231913:
2: 89664: loss: 0.7035797227:
2: 96064: loss: 0.7034994334:
2: 102464: loss: 0.7033835331:
2: 108864: loss: 0.7033236309:
2: 115264: loss: 0.7032662071:
2: 121664: loss: 0.7031655930:
Dev-Acc: 2: Accuracy: 0.3397563100: precision: 0.0651354180: recall: 0.7724876722: f1: 0.1201406886
Train-Acc: 2: Accuracy: 0.3871787190: precision: 0.1416290358: recall: 0.7711524555: f1: 0.2393071721
3: 6464: loss: 0.7012757671:
3: 12864: loss: 0.7008671108:
3: 19264: loss: 0.7010025698:
3: 25664: loss: 0.7008813615:
3: 32064: loss: 0.7008348895:
3: 38464: loss: 0.7008040739:
3: 44864: loss: 0.7007652710:
3: 51264: loss: 0.7007616450:
3: 57664: loss: 0.7006482467:
3: 64064: loss: 0.7006231528:
3: 70464: loss: 0.7004121874:
3: 76864: loss: 0.7003047250:
3: 83264: loss: 0.7002694757:
3: 89664: loss: 0.7002099379:
3: 96064: loss: 0.7001770764:
3: 102464: loss: 0.7000275103:
3: 108864: loss: 0.6999312127:
3: 115264: loss: 0.6998321732:
3: 121664: loss: 0.6997210933:
Dev-Acc: 3: Accuracy: 0.3935346901: precision: 0.0662678036: recall: 0.7175650400: f1: 0.1213306115
Train-Acc: 3: Accuracy: 0.4304861724: precision: 0.1438222667: recall: 0.7179672605: f1: 0.2396401339
4: 6464: loss: 0.6975492817:
4: 12864: loss: 0.6976678362:
4: 19264: loss: 0.6975616465:
4: 25664: loss: 0.6974270327:
4: 32064: loss: 0.6973752171:
4: 38464: loss: 0.6974047817:
4: 44864: loss: 0.6972519313:
4: 51264: loss: 0.6970971802:
4: 57664: loss: 0.6970187001:
4: 64064: loss: 0.6969079346:
4: 70464: loss: 0.6968410414:
4: 76864: loss: 0.6968509157:
4: 83264: loss: 0.6967918874:
4: 89664: loss: 0.6967066050:
4: 96064: loss: 0.6966063033:
4: 102464: loss: 0.6965270214:
4: 108864: loss: 0.6964292369:
4: 115264: loss: 0.6963596003:
4: 121664: loss: 0.6962680071:
Dev-Acc: 4: Accuracy: 0.4463903010: precision: 0.0654815795: recall: 0.6395170889: f1: 0.1187990587
Train-Acc: 4: Accuracy: 0.4769492745: precision: 0.1461486763: recall: 0.6576161988: f1: 0.2391488853
5: 6464: loss: 0.6940928316:
5: 12864: loss: 0.6937246376:
5: 19264: loss: 0.6938306765:
5: 25664: loss: 0.6939391597:
5: 32064: loss: 0.6937457156:
5: 38464: loss: 0.6937598617:
5: 44864: loss: 0.6937160191:
5: 51264: loss: 0.6935931058:
5: 57664: loss: 0.6934194799:
5: 64064: loss: 0.6933794282:
5: 70464: loss: 0.6933296062:
5: 76864: loss: 0.6933246026:
5: 83264: loss: 0.6932409373:
5: 89664: loss: 0.6932206630:
5: 96064: loss: 0.6930674640:
5: 102464: loss: 0.6930263420:
5: 108864: loss: 0.6929290837:
5: 115264: loss: 0.6927991544:
5: 121664: loss: 0.6927384155:
Dev-Acc: 5: Accuracy: 0.5019447207: precision: 0.0627528367: recall: 0.5407243666: f1: 0.1124549119
Train-Acc: 5: Accuracy: 0.5264282823: precision: 0.1482077396: recall: 0.5874038525: f1: 0.2366950118
6: 6464: loss: 0.6901640528:
6: 12864: loss: 0.6899160603:
6: 19264: loss: 0.6900170368:
6: 25664: loss: 0.6899130204:
6: 32064: loss: 0.6899707922:
6: 38464: loss: 0.6899821846:
6: 44864: loss: 0.6900212614:
6: 51264: loss: 0.6900248649:
6: 57664: loss: 0.6900034084:
6: 64064: loss: 0.6899542742:
6: 70464: loss: 0.6897570757:
6: 76864: loss: 0.6896223711:
6: 83264: loss: 0.6895912226:
6: 89664: loss: 0.6895012642:
6: 96064: loss: 0.6893515085:
6: 102464: loss: 0.6893092478:
6: 108864: loss: 0.6892107652:
6: 115264: loss: 0.6891467387:
6: 121664: loss: 0.6890583797:
Dev-Acc: 6: Accuracy: 0.5592058301: precision: 0.0620398146: recall: 0.4642067676: f1: 0.1094517390
Train-Acc: 6: Accuracy: 0.5752005577: precision: 0.1523139677: recall: 0.5253435014: f1: 0.2361581086
7: 6464: loss: 0.6873943251:
7: 12864: loss: 0.6879744846:
7: 19264: loss: 0.6876692488:
7: 25664: loss: 0.6872149269:
7: 32064: loss: 0.6871177320:
7: 38464: loss: 0.6870109462:
7: 44864: loss: 0.6868693607:
7: 51264: loss: 0.6867981271:
7: 57664: loss: 0.6866714689:
7: 64064: loss: 0.6865808022:
7: 70464: loss: 0.6864740032:
7: 76864: loss: 0.6864033098:
7: 83264: loss: 0.6863548829:
7: 89664: loss: 0.6862640647:
7: 96064: loss: 0.6861805113:
7: 102464: loss: 0.6860120538:
7: 108864: loss: 0.6859431709:
7: 115264: loss: 0.6858443953:
7: 121664: loss: 0.6857618177:
Dev-Acc: 7: Accuracy: 0.6130635738: precision: 0.0633669110: recall: 0.4086039789: f1: 0.1097185124
Train-Acc: 7: Accuracy: 0.6214253306: precision: 0.1586690560: recall: 0.4715008875: f1: 0.2374362709
8: 6464: loss: 0.6838389033:
8: 12864: loss: 0.6838215634:
8: 19264: loss: 0.6840216941:
8: 25664: loss: 0.6838533963:
8: 32064: loss: 0.6836801912:
8: 38464: loss: 0.6837433269:
8: 44864: loss: 0.6836818235:
8: 51264: loss: 0.6835307288:
8: 57664: loss: 0.6833917070:
8: 64064: loss: 0.6833492609:
8: 70464: loss: 0.6831752344:
8: 76864: loss: 0.6830665684:
8: 83264: loss: 0.6829923563:
8: 89664: loss: 0.6828424414:
8: 96064: loss: 0.6827421647:
8: 102464: loss: 0.6826466658:
8: 108864: loss: 0.6825707133:
8: 115264: loss: 0.6824972717:
8: 121664: loss: 0.6824179533:
Dev-Acc: 8: Accuracy: 0.6612656713: precision: 0.0644843105: recall: 0.3557218160: f1: 0.1091772565
Train-Acc: 8: Accuracy: 0.6654477119: precision: 0.1671713480: recall: 0.4210111104: f1: 0.2393168781
9: 6464: loss: 0.6816874158:
9: 12864: loss: 0.6811448085:
9: 19264: loss: 0.6811701435:
9: 25664: loss: 0.6807847443:
9: 32064: loss: 0.6807205567:
9: 38464: loss: 0.6806318493:
9: 44864: loss: 0.6805476820:
9: 51264: loss: 0.6803216984:
9: 57664: loss: 0.6801648017:
9: 64064: loss: 0.6801061797:
9: 70464: loss: 0.6799765023:
9: 76864: loss: 0.6799182705:
9: 83264: loss: 0.6798217623:
9: 89664: loss: 0.6797253283:
9: 96064: loss: 0.6795889392:
9: 102464: loss: 0.6793934247:
9: 108864: loss: 0.6793205172:
9: 115264: loss: 0.6792098734:
9: 121664: loss: 0.6790667059:
Dev-Acc: 9: Accuracy: 0.7076718211: precision: 0.0664460379: recall: 0.3072606700: f1: 0.1092635143
Train-Acc: 9: Accuracy: 0.7045559287: precision: 0.1769213994: recall: 0.3733482348: f1: 0.2400760938
10: 6464: loss: 0.6771451229:
10: 12864: loss: 0.6773292875:
10: 19264: loss: 0.6770562865:
10: 25664: loss: 0.6772149147:
10: 32064: loss: 0.6769402065:
10: 38464: loss: 0.6768481337:
10: 44864: loss: 0.6768057446:
10: 51264: loss: 0.6766150580:
10: 57664: loss: 0.6764717764:
10: 64064: loss: 0.6764594960:
10: 70464: loss: 0.6763829404:
10: 76864: loss: 0.6762497157:
10: 83264: loss: 0.6762279301:
10: 89664: loss: 0.6761166750:
10: 96064: loss: 0.6760576739:
10: 102464: loss: 0.6759120065:
10: 108864: loss: 0.6758511233:
10: 115264: loss: 0.6757288424:
10: 121664: loss: 0.6756105422:
Dev-Acc: 10: Accuracy: 0.7474301457: precision: 0.0675592082: recall: 0.2599897977: f1: 0.1072493249
Train-Acc: 10: Accuracy: 0.7379281521: precision: 0.1874297279: recall: 0.3287752285: f1: 0.2387511040
11: 6464: loss: 0.6741430837:
11: 12864: loss: 0.6740825257:
11: 19264: loss: 0.6738525633:
11: 25664: loss: 0.6734944549:
11: 32064: loss: 0.6735348914:
11: 38464: loss: 0.6735279632:
11: 44864: loss: 0.6733407411:
11: 51264: loss: 0.6732250234:
11: 57664: loss: 0.6730682097:
11: 64064: loss: 0.6729197364:
11: 70464: loss: 0.6728355203:
11: 76864: loss: 0.6727228894:
11: 83264: loss: 0.6725425251:
11: 89664: loss: 0.6724931917:
11: 96064: loss: 0.6724525017:
11: 102464: loss: 0.6723540877:
11: 108864: loss: 0.6723200580:
11: 115264: loss: 0.6722550589:
11: 121664: loss: 0.6722152171:
Dev-Acc: 11: Accuracy: 0.7799353004: precision: 0.0702457547: recall: 0.2264920932: f1: 0.1072334259
Train-Acc: 11: Accuracy: 0.7686954141: precision: 0.2019904165: recall: 0.2882124778: f1: 0.2375186239
12: 6464: loss: 0.6701827538:
12: 12864: loss: 0.6697214961:
12: 19264: loss: 0.6700530809:
12: 25664: loss: 0.6700214875:
12: 32064: loss: 0.6696560686:
12: 38464: loss: 0.6694540816:
12: 44864: loss: 0.6694044840:
12: 51264: loss: 0.6695358107:
12: 57664: loss: 0.6695494833:
12: 64064: loss: 0.6694624592:
12: 70464: loss: 0.6693842446:
12: 76864: loss: 0.6693643566:
12: 83264: loss: 0.6692196614:
12: 89664: loss: 0.6692219283:
12: 96064: loss: 0.6691454014:
12: 102464: loss: 0.6690439273:
12: 108864: loss: 0.6689993297:
12: 115264: loss: 0.6689556724:
12: 121664: loss: 0.6688237247:
Dev-Acc: 12: Accuracy: 0.8078861833: precision: 0.0724389470: recall: 0.1941846625: f1: 0.1055160307
Train-Acc: 12: Accuracy: 0.7932171226: precision: 0.2175295186: recall: 0.2519229505: f1: 0.2334663539
13: 6464: loss: 0.6669995821:
13: 12864: loss: 0.6668416426:
13: 19264: loss: 0.6669441823:
13: 25664: loss: 0.6672007303:
13: 32064: loss: 0.6674237123:
13: 38464: loss: 0.6671408888:
13: 44864: loss: 0.6669205979:
13: 51264: loss: 0.6666795722:
13: 57664: loss: 0.6666222444:
13: 64064: loss: 0.6664668849:
13: 70464: loss: 0.6662898666:
13: 76864: loss: 0.6661879713:
13: 83264: loss: 0.6661499983:
13: 89664: loss: 0.6660917681:
13: 96064: loss: 0.6659603858:
13: 102464: loss: 0.6658577329:
13: 108864: loss: 0.6657897278:
13: 115264: loss: 0.6656615453:
13: 121664: loss: 0.6655823410:
Dev-Acc: 13: Accuracy: 0.8313124776: precision: 0.0744029394: recall: 0.1652780139: f1: 0.1026128266
Train-Acc: 13: Accuracy: 0.8130054474: precision: 0.2345531316: recall: 0.2191177437: f1: 0.2265728561
14: 6464: loss: 0.6647254139:
14: 12864: loss: 0.6635905668:
14: 19264: loss: 0.6639822529:
14: 25664: loss: 0.6639762601:
14: 32064: loss: 0.6639949127:
14: 38464: loss: 0.6638835609:
14: 44864: loss: 0.6638096578:
14: 51264: loss: 0.6636984519:
14: 57664: loss: 0.6635225070:
14: 64064: loss: 0.6633510126:
14: 70464: loss: 0.6632352669:
14: 76864: loss: 0.6631855210:
14: 83264: loss: 0.6630857016:
14: 89664: loss: 0.6629904458:
14: 96064: loss: 0.6628872081:
14: 102464: loss: 0.6628128295:
14: 108864: loss: 0.6626891421:
14: 115264: loss: 0.6626204605:
14: 121664: loss: 0.6624442611:
Dev-Acc: 14: Accuracy: 0.8534787297: precision: 0.0780626781: recall: 0.1397721476: f1: 0.1001767107
Train-Acc: 14: Accuracy: 0.8279206157: precision: 0.2500218169: recall: 0.1883505358: f1: 0.2148481440
15: 6464: loss: 0.6604623240:
15: 12864: loss: 0.6604415309:
15: 19264: loss: 0.6603087759:
15: 25664: loss: 0.6605483297:
15: 32064: loss: 0.6604651157:
15: 38464: loss: 0.6603266352:
15: 44864: loss: 0.6601268227:
15: 51264: loss: 0.6599872351:
15: 57664: loss: 0.6598817211:
15: 64064: loss: 0.6597400643:
15: 70464: loss: 0.6597098755:
15: 76864: loss: 0.6595875518:
15: 83264: loss: 0.6594067694:
15: 89664: loss: 0.6593333713:
15: 96064: loss: 0.6592688980:
15: 102464: loss: 0.6592172092:
15: 108864: loss: 0.6591024299:
15: 115264: loss: 0.6590367722:
15: 121664: loss: 0.6589776507:
Dev-Acc: 15: Accuracy: 0.8714974523: precision: 0.0828416332: recall: 0.1193674545: f1: 0.0978056426
Train-Acc: 15: Accuracy: 0.8400171399: precision: 0.2667397260: recall: 0.1600157781: f1: 0.2000328731
16: 6464: loss: 0.6572818321:
16: 12864: loss: 0.6573574725:
16: 19264: loss: 0.6573725480:
16: 25664: loss: 0.6568974306:
16: 32064: loss: 0.6567437782:
16: 38464: loss: 0.6567021220:
16: 44864: loss: 0.6567014489:
16: 51264: loss: 0.6565545231:
16: 57664: loss: 0.6564611576:
16: 64064: loss: 0.6564129817:
16: 70464: loss: 0.6563082122:
16: 76864: loss: 0.6562595435:
16: 83264: loss: 0.6561981230:
16: 89664: loss: 0.6560734312:
16: 96064: loss: 0.6560471367:
16: 102464: loss: 0.6559773066:
16: 108864: loss: 0.6559100326:
16: 115264: loss: 0.6558498798:
16: 121664: loss: 0.6557812684:
Dev-Acc: 16: Accuracy: 0.8862121105: precision: 0.0866992159: recall: 0.0996429179: f1: 0.0927215190
Train-Acc: 16: Accuracy: 0.8500099182: precision: 0.2899571764: recall: 0.1379922425: f1: 0.1869933185
17: 6464: loss: 0.6539921904:
17: 12864: loss: 0.6541651639:
17: 19264: loss: 0.6541405394:
17: 25664: loss: 0.6539257365:
17: 32064: loss: 0.6538331221:
17: 38464: loss: 0.6536950959:
17: 44864: loss: 0.6537480595:
17: 51264: loss: 0.6536126062:
17: 57664: loss: 0.6536429418:
17: 64064: loss: 0.6534270943:
17: 70464: loss: 0.6533528126:
17: 76864: loss: 0.6532541796:
17: 83264: loss: 0.6532870118:
17: 89664: loss: 0.6531503384:
17: 96064: loss: 0.6530665963:
17: 102464: loss: 0.6529427643:
17: 108864: loss: 0.6527843896:
17: 115264: loss: 0.6526999244:
17: 121664: loss: 0.6525846048:
Dev-Acc: 17: Accuracy: 0.8995376229: precision: 0.0933307781: recall: 0.0828090461: f1: 0.0877556537
Train-Acc: 17: Accuracy: 0.8569949865: precision: 0.3059344553: recall: 0.1135362567: f1: 0.1656118143
18: 6464: loss: 0.6511243576:
18: 12864: loss: 0.6509583315:
18: 19264: loss: 0.6508833265:
18: 25664: loss: 0.6506245318:
18: 32064: loss: 0.6506875569:
18: 38464: loss: 0.6506354422:
18: 44864: loss: 0.6505592017:
18: 51264: loss: 0.6504367331:
18: 57664: loss: 0.6503786429:
18: 64064: loss: 0.6501673750:
18: 70464: loss: 0.6500796947:
18: 76864: loss: 0.6500177614:
18: 83264: loss: 0.6498879744:
18: 89664: loss: 0.6497590252:
18: 96064: loss: 0.6495617321:
18: 102464: loss: 0.6494507165:
18: 108864: loss: 0.6494009655:
18: 115264: loss: 0.6493792477:
18: 121664: loss: 0.6493050160:
Dev-Acc: 18: Accuracy: 0.9105314016: precision: 0.0954592363: recall: 0.0629144703: f1: 0.0758429845
Train-Acc: 18: Accuracy: 0.8625501990: precision: 0.3248554913: recall: 0.0923673657: f1: 0.1438370188
19: 6464: loss: 0.6461983001:
19: 12864: loss: 0.6472597992:
19: 19264: loss: 0.6473632777:
19: 25664: loss: 0.6471540219:
19: 32064: loss: 0.6474871775:
19: 38464: loss: 0.6473477211:
19: 44864: loss: 0.6471519686:
19: 51264: loss: 0.6470110171:
19: 57664: loss: 0.6468836223:
19: 64064: loss: 0.6468076447:
19: 70464: loss: 0.6467280236:
19: 76864: loss: 0.6466381903:
19: 83264: loss: 0.6465408881:
19: 89664: loss: 0.6464943626:
19: 96064: loss: 0.6464221465:
19: 102464: loss: 0.6464412322:
19: 108864: loss: 0.6463178308:
19: 115264: loss: 0.6463111788:
19: 121664: loss: 0.6461919371:
Dev-Acc: 19: Accuracy: 0.9186378717: precision: 0.0980935875: recall: 0.0481210678: f1: 0.0645676477
Train-Acc: 19: Accuracy: 0.8663960695: precision: 0.3436846820: recall: 0.0756689238: f1: 0.1240301724
20: 6464: loss: 0.6451204622:
20: 12864: loss: 0.6446890905:
20: 19264: loss: 0.6445448593:
20: 25664: loss: 0.6443588074:
20: 32064: loss: 0.6445302353:
20: 38464: loss: 0.6442745325:
20: 44864: loss: 0.6439777825:
20: 51264: loss: 0.6439374837:
20: 57664: loss: 0.6440308454:
20: 64064: loss: 0.6439269325:
20: 70464: loss: 0.6439083455:
20: 76864: loss: 0.6438451023:
20: 83264: loss: 0.6437092720:
20: 89664: loss: 0.6436550010:
20: 96064: loss: 0.6435351842:
20: 102464: loss: 0.6434174037:
20: 108864: loss: 0.6432062785:
20: 115264: loss: 0.6431094579:
20: 121664: loss: 0.6430135318:
Dev-Acc: 20: Accuracy: 0.9251170754: precision: 0.0960232784: recall: 0.0336677436: f1: 0.0498552184
Train-Acc: 20: Accuracy: 0.8685655594: precision: 0.3478429848: recall: 0.0588389981: f1: 0.1006522717
