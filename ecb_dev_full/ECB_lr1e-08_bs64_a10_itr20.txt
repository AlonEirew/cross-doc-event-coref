1: 6464: loss: 0.7113682002:
1: 12864: loss: 0.7104491517:
1: 19264: loss: 0.7106599907:
1: 25664: loss: 0.7107508428:
1: 32064: loss: 0.7106424487:
1: 38464: loss: 0.7106277045:
1: 44864: loss: 0.7105598955:
1: 51264: loss: 0.7103802390:
1: 57664: loss: 0.7101827459:
1: 64064: loss: 0.7101253650:
1: 70464: loss: 0.7099948221:
1: 76864: loss: 0.7099058801:
1: 83264: loss: 0.7097865386:
1: 89664: loss: 0.7096974427:
1: 96064: loss: 0.7095992720:
1: 102464: loss: 0.7095301833:
1: 108864: loss: 0.7094165779:
1: 115264: loss: 0.7093081681:
1: 121664: loss: 0.7092581744:
1: 128064: loss: 0.7091473463:
1: 134464: loss: 0.7090188174:
1: 140864: loss: 0.7088728806:
1: 147264: loss: 0.7087874614:
1: 153664: loss: 0.7086741627:
1: 160064: loss: 0.7085458637:
1: 166464: loss: 0.7084267934:
Dev-Acc: 1: Accuracy: 0.3163597286: precision: 0.0644309589: recall: 0.7925522870: f1: 0.1191736340
Train-Acc: 1: Accuracy: 0.3396584988: precision: 0.1006789606: recall: 0.7896259286: f1: 0.1785876248
2: 6464: loss: 0.7061260718:
2: 12864: loss: 0.7058534914:
2: 19264: loss: 0.7055740889:
2: 25664: loss: 0.7052597719:
2: 32064: loss: 0.7051198647:
2: 38464: loss: 0.7049664592:
2: 44864: loss: 0.7047045875:
2: 51264: loss: 0.7045272303:
2: 57664: loss: 0.7044186906:
2: 64064: loss: 0.7042977129:
2: 70464: loss: 0.7042203703:
2: 76864: loss: 0.7040766757:
2: 83264: loss: 0.7040503577:
2: 89664: loss: 0.7039760609:
2: 96064: loss: 0.7038140990:
2: 102464: loss: 0.7036901111:
2: 108864: loss: 0.7035883033:
2: 115264: loss: 0.7034686316:
2: 121664: loss: 0.7033790062:
2: 128064: loss: 0.7032793509:
2: 134464: loss: 0.7031756666:
2: 140864: loss: 0.7030378732:
2: 147264: loss: 0.7029876512:
2: 153664: loss: 0.7028604823:
2: 160064: loss: 0.7027178635:
2: 166464: loss: 0.7026472305:
Dev-Acc: 2: Accuracy: 0.3939216435: precision: 0.0648451788: recall: 0.6993708553: f1: 0.1186858850
Train-Acc: 2: Accuracy: 0.4102473855: precision: 0.1023979879: recall: 0.7065939123: f1: 0.1788739661
3: 6464: loss: 0.6988072044:
3: 12864: loss: 0.6987059209:
3: 19264: loss: 0.6989199579:
3: 25664: loss: 0.6987641193:
3: 32064: loss: 0.6988470756:
3: 38464: loss: 0.6988598592:
3: 44864: loss: 0.6987264767:
3: 51264: loss: 0.6987324828:
3: 57664: loss: 0.6985331349:
3: 64064: loss: 0.6984092355:
3: 70464: loss: 0.6983155036:
3: 76864: loss: 0.6982388246:
3: 83264: loss: 0.6982001069:
3: 89664: loss: 0.6981168309:
3: 96064: loss: 0.6980568785:
3: 102464: loss: 0.6979148180:
3: 108864: loss: 0.6978168450:
3: 115264: loss: 0.6976576731:
3: 121664: loss: 0.6975368284:
3: 128064: loss: 0.6974344582:
3: 134464: loss: 0.6973499626:
3: 140864: loss: 0.6972462021:
3: 147264: loss: 0.6971509249:
3: 153664: loss: 0.6970433627:
3: 160064: loss: 0.6969228362:
3: 166464: loss: 0.6968009408:
Dev-Acc: 3: Accuracy: 0.4751647115: precision: 0.0599752911: recall: 0.5448053052: f1: 0.1080552417
Train-Acc: 3: Accuracy: 0.4913668931: precision: 0.1039640987: recall: 0.6031161659: f1: 0.1773559007
4: 6464: loss: 0.6930560976:
4: 12864: loss: 0.6934565368:
4: 19264: loss: 0.6936370893:
4: 25664: loss: 0.6936233845:
4: 32064: loss: 0.6934914752:
4: 38464: loss: 0.6933843813:
4: 44864: loss: 0.6933635945:
4: 51264: loss: 0.6932979030:
4: 57664: loss: 0.6932345167:
4: 64064: loss: 0.6932302047:
4: 70464: loss: 0.6931038245:
4: 76864: loss: 0.6929099858:
4: 83264: loss: 0.6927937563:
4: 89664: loss: 0.6926808141:
4: 96064: loss: 0.6925756818:
4: 102464: loss: 0.6924394985:
4: 108864: loss: 0.6923485390:
4: 115264: loss: 0.6921862171:
4: 121664: loss: 0.6920371534:
4: 128064: loss: 0.6919264095:
4: 134464: loss: 0.6918080695:
4: 140864: loss: 0.6916991950:
4: 147264: loss: 0.6915808770:
4: 153664: loss: 0.6914673462:
4: 160064: loss: 0.6913637710:
4: 166464: loss: 0.6912240603:
Dev-Acc: 4: Accuracy: 0.5579457283: precision: 0.0593048433: recall: 0.4424417616: f1: 0.1045904012
Train-Acc: 4: Accuracy: 0.5695101023: precision: 0.1080529228: recall: 0.5148905397: f1: 0.1786211143
5: 6464: loss: 0.6887551045:
5: 12864: loss: 0.6887716737:
5: 19264: loss: 0.6885433666:
5: 25664: loss: 0.6881336516:
5: 32064: loss: 0.6878177803:
5: 38464: loss: 0.6876910286:
5: 44864: loss: 0.6874139832:
5: 51264: loss: 0.6873319672:
5: 57664: loss: 0.6871891964:
5: 64064: loss: 0.6871354067:
5: 70464: loss: 0.6871119211:
5: 76864: loss: 0.6870289493:
5: 83264: loss: 0.6868863930:
5: 89664: loss: 0.6868257027:
5: 96064: loss: 0.6867127745:
5: 102464: loss: 0.6865988443:
5: 108864: loss: 0.6864854037:
5: 115264: loss: 0.6864301620:
5: 121664: loss: 0.6862741281:
5: 128064: loss: 0.6861895327:
5: 134464: loss: 0.6861170145:
5: 140864: loss: 0.6860130817:
5: 147264: loss: 0.6858869915:
5: 153664: loss: 0.6857719825:
5: 160064: loss: 0.6856946863:
5: 166464: loss: 0.6855781159:
Dev-Acc: 5: Accuracy: 0.6352595687: precision: 0.0608413687: recall: 0.3637136541: f1: 0.1042448462
Train-Acc: 5: Accuracy: 0.6409117579: precision: 0.1139710943: recall: 0.4354743278: f1: 0.1806602937
6: 6464: loss: 0.6827445614:
6: 12864: loss: 0.6829147828:
6: 19264: loss: 0.6831110022:
6: 25664: loss: 0.6826431395:
6: 32064: loss: 0.6826327145:
6: 38464: loss: 0.6824407775:
6: 44864: loss: 0.6823701927:
6: 51264: loss: 0.6822466574:
6: 57664: loss: 0.6821384862:
6: 64064: loss: 0.6820344767:
6: 70464: loss: 0.6819080066:
6: 76864: loss: 0.6817212034:
6: 83264: loss: 0.6816396111:
6: 89664: loss: 0.6814954563:
6: 96064: loss: 0.6813456888:
6: 102464: loss: 0.6812177332:
6: 108864: loss: 0.6811241178:
6: 115264: loss: 0.6809970436:
6: 121664: loss: 0.6808612853:
6: 128064: loss: 0.6807825554:
6: 134464: loss: 0.6806762611:
6: 140864: loss: 0.6805665724:
6: 147264: loss: 0.6804497555:
6: 153664: loss: 0.6803535970:
6: 160064: loss: 0.6802924599:
6: 166464: loss: 0.6801584183:
Dev-Acc: 6: Accuracy: 0.7046158314: precision: 0.0628408301: recall: 0.2919571501: f1: 0.1034212745
Train-Acc: 6: Accuracy: 0.7038327456: precision: 0.1223610134: recall: 0.3657879166: f1: 0.1833792001
7: 6464: loss: 0.6771164370:
7: 12864: loss: 0.6769251180:
7: 19264: loss: 0.6768418318:
7: 25664: loss: 0.6769711734:
7: 32064: loss: 0.6766874492:
7: 38464: loss: 0.6766234366:
7: 44864: loss: 0.6766044692:
7: 51264: loss: 0.6765728036:
7: 57664: loss: 0.6764434371:
7: 64064: loss: 0.6763872150:
7: 70464: loss: 0.6762442649:
7: 76864: loss: 0.6760920305:
7: 83264: loss: 0.6759887233:
7: 89664: loss: 0.6759231906:
7: 96064: loss: 0.6758235602:
7: 102464: loss: 0.6757239744:
7: 108864: loss: 0.6755685984:
7: 115264: loss: 0.6754364842:
7: 121664: loss: 0.6753078475:
7: 128064: loss: 0.6752455804:
7: 134464: loss: 0.6751567851:
7: 140864: loss: 0.6750290688:
7: 147264: loss: 0.6749262891:
7: 153664: loss: 0.6747883635:
7: 160064: loss: 0.6747083028:
7: 166464: loss: 0.6746286334:
Dev-Acc: 7: Accuracy: 0.7597932220: precision: 0.0642415597: recall: 0.2297228363: f1: 0.1004050388
Train-Acc: 7: Accuracy: 0.7566772699: precision: 0.1303200742: recall: 0.2955098284: f1: 0.1808743939
8: 6464: loss: 0.6704849458:
8: 12864: loss: 0.6706182849:
8: 19264: loss: 0.6711325866:
8: 25664: loss: 0.6711276841:
8: 32064: loss: 0.6711683152:
8: 38464: loss: 0.6710399241:
8: 44864: loss: 0.6708276840:
8: 51264: loss: 0.6708922622:
8: 57664: loss: 0.6707869130:
8: 64064: loss: 0.6707584852:
8: 70464: loss: 0.6705596825:
8: 76864: loss: 0.6704579372:
8: 83264: loss: 0.6703926412:
8: 89664: loss: 0.6703244560:
8: 96064: loss: 0.6702230744:
8: 102464: loss: 0.6701410266:
8: 108864: loss: 0.6700626303:
8: 115264: loss: 0.6699658458:
8: 121664: loss: 0.6698770759:
8: 128064: loss: 0.6697645240:
8: 134464: loss: 0.6696412056:
8: 140864: loss: 0.6695024591:
8: 147264: loss: 0.6694379653:
8: 153664: loss: 0.6693535498:
8: 160064: loss: 0.6692483348:
8: 166464: loss: 0.6691678998:
Dev-Acc: 8: Accuracy: 0.8031731248: precision: 0.0642562758: recall: 0.1749702432: f1: 0.0939940626
Train-Acc: 8: Accuracy: 0.8000071645: precision: 0.1411042945: recall: 0.2358819276: f1: 0.1765791481
9: 6464: loss: 0.6657790434:
9: 12864: loss: 0.6668122405:
9: 19264: loss: 0.6665155639:
9: 25664: loss: 0.6664061730:
9: 32064: loss: 0.6660152307:
9: 38464: loss: 0.6659056005:
9: 44864: loss: 0.6657382451:
9: 51264: loss: 0.6656542756:
9: 57664: loss: 0.6656092699:
9: 64064: loss: 0.6655653241:
9: 70464: loss: 0.6654105535:
9: 76864: loss: 0.6652864049:
9: 83264: loss: 0.6651638152:
9: 89664: loss: 0.6650625110:
9: 96064: loss: 0.6650011950:
9: 102464: loss: 0.6648397769:
9: 108864: loss: 0.6646850636:
9: 115264: loss: 0.6645701191:
9: 121664: loss: 0.6644994691:
9: 128064: loss: 0.6644367205:
9: 134464: loss: 0.6643180919:
9: 140864: loss: 0.6642220127:
9: 147264: loss: 0.6641416478:
9: 153664: loss: 0.6640264596:
9: 160064: loss: 0.6639400580:
9: 166464: loss: 0.6638698393:
Dev-Acc: 9: Accuracy: 0.8369681835: precision: 0.0628211503: recall: 0.1288896446: f1: 0.0844709422
Train-Acc: 9: Accuracy: 0.8325015903: precision: 0.1537796509: recall: 0.1871014397: f1: 0.1688119106
10: 6464: loss: 0.6597898161:
10: 12864: loss: 0.6603323126:
10: 19264: loss: 0.6605011910:
10: 25664: loss: 0.6604048194:
10: 32064: loss: 0.6602891597:
10: 38464: loss: 0.6600253211:
10: 44864: loss: 0.6600036078:
10: 51264: loss: 0.6600894210:
10: 57664: loss: 0.6599789599:
10: 64064: loss: 0.6599293690:
10: 70464: loss: 0.6598230409:
10: 76864: loss: 0.6597373978:
10: 83264: loss: 0.6596367242:
10: 89664: loss: 0.6595094202:
10: 96064: loss: 0.6594221647:
10: 102464: loss: 0.6593706685:
10: 108864: loss: 0.6594018538:
10: 115264: loss: 0.6593347887:
10: 121664: loss: 0.6592598375:
10: 128064: loss: 0.6591420940:
10: 134464: loss: 0.6590623320:
10: 140864: loss: 0.6589575386:
10: 147264: loss: 0.6588452298:
10: 153664: loss: 0.6587339010:
10: 160064: loss: 0.6586002391:
10: 166464: loss: 0.6585308831:
Dev-Acc: 10: Accuracy: 0.8665462732: precision: 0.0676339541: recall: 0.1006631525: f1: 0.0809074757
Train-Acc: 10: Accuracy: 0.8567783237: precision: 0.1660944533: recall: 0.1431201104: f1: 0.1537537962
11: 6464: loss: 0.6559123766:
11: 12864: loss: 0.6558079585:
11: 19264: loss: 0.6554675321:
11: 25664: loss: 0.6555025013:
11: 32064: loss: 0.6551939604:
11: 38464: loss: 0.6552890524:
11: 44864: loss: 0.6553456604:
11: 51264: loss: 0.6552389837:
11: 57664: loss: 0.6550211877:
11: 64064: loss: 0.6548933938:
11: 70464: loss: 0.6547694869:
11: 76864: loss: 0.6546701673:
11: 83264: loss: 0.6546129179:
11: 89664: loss: 0.6546228425:
11: 96064: loss: 0.6545327134:
11: 102464: loss: 0.6544778874:
11: 108864: loss: 0.6543316746:
11: 115264: loss: 0.6542434651:
11: 121664: loss: 0.6541333231:
11: 128064: loss: 0.6540631372:
11: 134464: loss: 0.6539982580:
11: 140864: loss: 0.6538707829:
11: 147264: loss: 0.6537593437:
11: 153664: loss: 0.6536311934:
11: 160064: loss: 0.6535342025:
11: 166464: loss: 0.6533499707:
Dev-Acc: 11: Accuracy: 0.8885537386: precision: 0.0690932517: recall: 0.0729467778: f1: 0.0709677419
Train-Acc: 11: Accuracy: 0.8737934828: precision: 0.1782523426: recall: 0.1075537440: f1: 0.1341588421
12: 6464: loss: 0.6501829904:
12: 12864: loss: 0.6505576482:
12: 19264: loss: 0.6503452333:
12: 25664: loss: 0.6503661637:
12: 32064: loss: 0.6503509834:
12: 38464: loss: 0.6500611925:
12: 44864: loss: 0.6498310017:
12: 51264: loss: 0.6498196011:
12: 57664: loss: 0.6497049658:
12: 64064: loss: 0.6495137302:
12: 70464: loss: 0.6493860917:
12: 76864: loss: 0.6493190596:
12: 83264: loss: 0.6492092672:
12: 89664: loss: 0.6490989757:
12: 96064: loss: 0.6489905597:
12: 102464: loss: 0.6489542039:
12: 108864: loss: 0.6488856817:
12: 115264: loss: 0.6489501887:
12: 121664: loss: 0.6487704559:
12: 128064: loss: 0.6487020645:
12: 134464: loss: 0.6486276694:
12: 140864: loss: 0.6485692512:
12: 147264: loss: 0.6484273389:
12: 153664: loss: 0.6483348722:
12: 160064: loss: 0.6482176409:
12: 166464: loss: 0.6481170000:
Dev-Acc: 12: Accuracy: 0.9066617489: precision: 0.0666175025: recall: 0.0460805985: f1: 0.0544778370
Train-Acc: 12: Accuracy: 0.8855732679: precision: 0.1849479584: recall: 0.0759318914: f1: 0.1076621924
13: 6464: loss: 0.6463966286:
13: 12864: loss: 0.6460563779:
13: 19264: loss: 0.6450949423:
13: 25664: loss: 0.6450635873:
13: 32064: loss: 0.6450529920:
13: 38464: loss: 0.6448443419:
13: 44864: loss: 0.6448058967:
13: 51264: loss: 0.6446237453:
13: 57664: loss: 0.6445302766:
13: 64064: loss: 0.6444181926:
13: 70464: loss: 0.6441896965:
13: 76864: loss: 0.6440218376:
13: 83264: loss: 0.6439324249:
13: 89664: loss: 0.6438960712:
13: 96064: loss: 0.6438342450:
13: 102464: loss: 0.6438244618:
13: 108864: loss: 0.6436723822:
13: 115264: loss: 0.6435961938:
13: 121664: loss: 0.6434879073:
13: 128064: loss: 0.6434183683:
13: 134464: loss: 0.6433743981:
13: 140864: loss: 0.6433335568:
13: 147264: loss: 0.6432120015:
13: 153664: loss: 0.6431124028:
13: 160064: loss: 0.6430192979:
13: 166464: loss: 0.6429251422:
Dev-Acc: 13: Accuracy: 0.9190843701: precision: 0.0673515982: recall: 0.0300969223: f1: 0.0416030086
Train-Acc: 13: Accuracy: 0.8936057091: precision: 0.1916210426: recall: 0.0529222273: f1: 0.0829383886
14: 6464: loss: 0.6391022819:
14: 12864: loss: 0.6401252830:
14: 19264: loss: 0.6398108290:
14: 25664: loss: 0.6398245774:
14: 32064: loss: 0.6397242278:
14: 38464: loss: 0.6395784023:
14: 44864: loss: 0.6395523467:
14: 51264: loss: 0.6394877975:
14: 57664: loss: 0.6394085444:
14: 64064: loss: 0.6392714287:
14: 70464: loss: 0.6392121363:
14: 76864: loss: 0.6390945448:
14: 83264: loss: 0.6389553227:
14: 89664: loss: 0.6388741495:
14: 96064: loss: 0.6387669666:
14: 102464: loss: 0.6386527438:
14: 108864: loss: 0.6384251820:
14: 115264: loss: 0.6383597279:
14: 121664: loss: 0.6383049066:
14: 128064: loss: 0.6382482288:
14: 134464: loss: 0.6381546238:
14: 140864: loss: 0.6380891701:
14: 147264: loss: 0.6379717628:
14: 153664: loss: 0.6379109014:
14: 160064: loss: 0.6378033230:
14: 166464: loss: 0.6377282208:
Dev-Acc: 14: Accuracy: 0.9269129634: precision: 0.0567164179: recall: 0.0161537154: f1: 0.0251455797
Train-Acc: 14: Accuracy: 0.8993133307: precision: 0.2070200573: recall: 0.0379988166: f1: 0.0642115203
15: 6464: loss: 0.6357795554:
15: 12864: loss: 0.6354494357:
15: 19264: loss: 0.6348602953:
15: 25664: loss: 0.6350477919:
15: 32064: loss: 0.6345852774:
15: 38464: loss: 0.6344589730:
15: 44864: loss: 0.6343121403:
15: 51264: loss: 0.6340470912:
15: 57664: loss: 0.6341493951:
15: 64064: loss: 0.6340212880:
15: 70464: loss: 0.6338847659:
15: 76864: loss: 0.6338244281:
15: 83264: loss: 0.6338143828:
15: 89664: loss: 0.6337188354:
15: 96064: loss: 0.6335744366:
15: 102464: loss: 0.6335241471:
15: 108864: loss: 0.6333947841:
15: 115264: loss: 0.6332505971:
15: 121664: loss: 0.6332118493:
15: 128064: loss: 0.6330907007:
15: 134464: loss: 0.6330251001:
15: 140864: loss: 0.6329724948:
15: 147264: loss: 0.6329122897:
15: 153664: loss: 0.6328161548:
15: 160064: loss: 0.6327628369:
15: 166464: loss: 0.6326273822:
Dev-Acc: 15: Accuracy: 0.9320328236: precision: 0.0583409298: recall: 0.0108825030: f1: 0.0183433649
Train-Acc: 15: Accuracy: 0.9025824666: precision: 0.2194744977: recall: 0.0280060483: f1: 0.0496735075
16: 6464: loss: 0.6299671739:
16: 12864: loss: 0.6301996037:
16: 19264: loss: 0.6299943715:
16: 25664: loss: 0.6298044729:
16: 32064: loss: 0.6296716508:
16: 38464: loss: 0.6294968713:
16: 44864: loss: 0.6295696740:
16: 51264: loss: 0.6293121268:
16: 57664: loss: 0.6292993145:
16: 64064: loss: 0.6291770043:
16: 70464: loss: 0.6289837447:
16: 76864: loss: 0.6288873196:
16: 83264: loss: 0.6287883909:
16: 89664: loss: 0.6286839953:
16: 96064: loss: 0.6285306078:
16: 102464: loss: 0.6284273743:
16: 108864: loss: 0.6282337110:
16: 115264: loss: 0.6281180034:
16: 121664: loss: 0.6279940954:
16: 128064: loss: 0.6279245493:
16: 134464: loss: 0.6278335672:
16: 140864: loss: 0.6277551950:
16: 147264: loss: 0.6277163964:
16: 153664: loss: 0.6276329832:
16: 160064: loss: 0.6276109784:
16: 166464: loss: 0.6275643350:
Dev-Acc: 16: Accuracy: 0.9360116720: precision: 0.0748502994: recall: 0.0085019554: f1: 0.0152695068
Train-Acc: 16: Accuracy: 0.9046025276: precision: 0.2095901005: recall: 0.0178160542: f1: 0.0328405235
17: 6464: loss: 0.6248239791:
17: 12864: loss: 0.6246990800:
17: 19264: loss: 0.6250947968:
17: 25664: loss: 0.6248559964:
17: 32064: loss: 0.6249275686:
17: 38464: loss: 0.6247336836:
17: 44864: loss: 0.6247143739:
17: 51264: loss: 0.6246308882:
17: 57664: loss: 0.6244210958:
17: 64064: loss: 0.6242803469:
17: 70464: loss: 0.6241652456:
17: 76864: loss: 0.6240862359:
17: 83264: loss: 0.6240245996:
17: 89664: loss: 0.6239142722:
17: 96064: loss: 0.6237647181:
17: 102464: loss: 0.6236657956:
17: 108864: loss: 0.6236345773:
17: 115264: loss: 0.6235584864:
17: 121664: loss: 0.6235279135:
17: 128064: loss: 0.6234373508:
17: 134464: loss: 0.6231971211:
17: 140864: loss: 0.6230876232:
17: 147264: loss: 0.6229272180:
17: 153664: loss: 0.6228339443:
17: 160064: loss: 0.6226834318:
17: 166464: loss: 0.6226077052:
Dev-Acc: 17: Accuracy: 0.9384227395: precision: 0.0947630923: recall: 0.0064614861: f1: 0.0120980579
Train-Acc: 17: Accuracy: 0.9061086178: precision: 0.1968408262: recall: 0.0106501874: f1: 0.0202070600
18: 6464: loss: 0.6194758332:
18: 12864: loss: 0.6197133562:
18: 19264: loss: 0.6196153210:
18: 25664: loss: 0.6194733615:
18: 32064: loss: 0.6193091248:
18: 38464: loss: 0.6191648653:
18: 44864: loss: 0.6192320905:
18: 51264: loss: 0.6189716688:
18: 57664: loss: 0.6189826332:
18: 64064: loss: 0.6188564034:
18: 70464: loss: 0.6188051336:
18: 76864: loss: 0.6187000872:
18: 83264: loss: 0.6186151019:
18: 89664: loss: 0.6185775489:
18: 96064: loss: 0.6187235196:
18: 102464: loss: 0.6186132889:
18: 108864: loss: 0.6185020803:
18: 115264: loss: 0.6184623647:
18: 121664: loss: 0.6183074307:
18: 128064: loss: 0.6182067901:
18: 134464: loss: 0.6181717509:
18: 140864: loss: 0.6180815628:
18: 147264: loss: 0.6179344811:
18: 153664: loss: 0.6178969130:
18: 160064: loss: 0.6178186632:
18: 166464: loss: 0.6177643149:
Dev-Acc: 18: Accuracy: 0.9395737052: precision: 0.0803212851: recall: 0.0034007822: f1: 0.0065252855
Train-Acc: 18: Accuracy: 0.9073098898: precision: 0.2031872510: recall: 0.0067056735: f1: 0.0129828804
19: 6464: loss: 0.6151946974:
19: 12864: loss: 0.6157702199:
19: 19264: loss: 0.6152228191:
19: 25664: loss: 0.6152554840:
19: 32064: loss: 0.6146717738:
19: 38464: loss: 0.6145470411:
19: 44864: loss: 0.6145223344:
19: 51264: loss: 0.6143521624:
19: 57664: loss: 0.6143122794:
19: 64064: loss: 0.6141667993:
19: 70464: loss: 0.6141548959:
19: 76864: loss: 0.6140510761:
19: 83264: loss: 0.6139558438:
19: 89664: loss: 0.6139440757:
19: 96064: loss: 0.6138428328:
19: 102464: loss: 0.6137946652:
19: 108864: loss: 0.6137069667:
19: 115264: loss: 0.6135977316:
19: 121664: loss: 0.6134973904:
19: 128064: loss: 0.6134322742:
19: 134464: loss: 0.6133066109:
19: 140864: loss: 0.6132838265:
19: 147264: loss: 0.6131038502:
19: 153664: loss: 0.6129871538:
19: 160064: loss: 0.6129007285:
19: 166464: loss: 0.6128075832:
Dev-Acc: 19: Accuracy: 0.9405758977: precision: 0.1142857143: recall: 0.0027206257: f1: 0.0053147318
Train-Acc: 19: Accuracy: 0.9080330729: precision: 0.2000000000: recall: 0.0038787719: f1: 0.0076099574
20: 6464: loss: 0.6113718754:
20: 12864: loss: 0.6111241612:
20: 19264: loss: 0.6107514038:
20: 25664: loss: 0.6100245668:
20: 32064: loss: 0.6101134652:
20: 38464: loss: 0.6098753702:
20: 44864: loss: 0.6099227312:
20: 51264: loss: 0.6097928951:
20: 57664: loss: 0.6096677068:
20: 64064: loss: 0.6095052784:
20: 70464: loss: 0.6093423543:
20: 76864: loss: 0.6091708768:
20: 83264: loss: 0.6089808030:
20: 89664: loss: 0.6088498150:
20: 96064: loss: 0.6088240320:
20: 102464: loss: 0.6087315707:
20: 108864: loss: 0.6086703685:
20: 115264: loss: 0.6086049606:
20: 121664: loss: 0.6085151255:
20: 128064: loss: 0.6084188694:
20: 134464: loss: 0.6082582460:
20: 140864: loss: 0.6081327659:
20: 147264: loss: 0.6081000246:
20: 153664: loss: 0.6080295043:
20: 160064: loss: 0.6079465234:
20: 166464: loss: 0.6078549636:
Dev-Acc: 20: Accuracy: 0.9408934116: precision: 0.0957446809: recall: 0.0015303520: f1: 0.0030125523
Train-Acc: 20: Accuracy: 0.9084633589: precision: 0.2099447514: recall: 0.0024981921: f1: 0.0049376299
