1: 6464: loss: 0.7014699525:
1: 12864: loss: 0.7008828735:
1: 19264: loss: 0.7010216971:
1: 25664: loss: 0.7009029625:
1: 32064: loss: 0.7006469584:
1: 38464: loss: 0.7008001239:
1: 44864: loss: 0.7008696383:
1: 51264: loss: 0.7008704954:
1: 57664: loss: 0.7007889199:
Dev-Acc: 1: Accuracy: 0.2678698897: precision: 0.0632605284: recall: 0.8362523380: f1: 0.1176231420
Train-Acc: 1: Accuracy: 0.4001709521: precision: 0.2733081986: recall: 0.8435342844: f1: 0.4128511213
2: 6464: loss: 0.6995425642:
2: 12864: loss: 0.7001154539:
2: 19264: loss: 0.6996640990:
2: 25664: loss: 0.6994695444:
2: 32064: loss: 0.6995636909:
2: 38464: loss: 0.6996555251:
2: 44864: loss: 0.6996897548:
2: 51264: loss: 0.6996150639:
2: 57664: loss: 0.6995677705:
Dev-Acc: 2: Accuracy: 0.2834080756: precision: 0.0639427880: recall: 0.8270702262: f1: 0.1187079769
Train-Acc: 2: Accuracy: 0.4119551778: precision: 0.2762304713: recall: 0.8345933864: f1: 0.4150795338
3: 6464: loss: 0.6984251475:
3: 12864: loss: 0.6985128605:
3: 19264: loss: 0.6983655874:
3: 25664: loss: 0.6981502610:
3: 32064: loss: 0.6980516095:
3: 38464: loss: 0.6981611863:
3: 44864: loss: 0.6981043615:
3: 51264: loss: 0.6979381573:
3: 57664: loss: 0.6977958230:
Dev-Acc: 3: Accuracy: 0.2977754474: precision: 0.0645182938: recall: 0.8173779969: f1: 0.1195964522
Train-Acc: 3: Accuracy: 0.4257445335: precision: 0.2797463550: recall: 0.8236802314: f1: 0.4176472549
4: 6464: loss: 0.6968287659:
4: 12864: loss: 0.6966887629:
4: 19264: loss: 0.6966553164:
4: 25664: loss: 0.6966424845:
4: 32064: loss: 0.6965787694:
4: 38464: loss: 0.6966284058:
4: 44864: loss: 0.6966008580:
4: 51264: loss: 0.6965665063:
4: 57664: loss: 0.6965660882:
Dev-Acc: 4: Accuracy: 0.3138394952: precision: 0.0650682577: recall: 0.8047951029: f1: 0.1204019334
Train-Acc: 4: Accuracy: 0.4421142936: precision: 0.2849105564: recall: 0.8156597199: f1: 0.4223084516
5: 6464: loss: 0.6962286562:
5: 12864: loss: 0.6957530019:
5: 19264: loss: 0.6959679091:
5: 25664: loss: 0.6959113199:
5: 32064: loss: 0.6957745972:
5: 38464: loss: 0.6954758903:
5: 44864: loss: 0.6954126378:
5: 51264: loss: 0.6953330659:
5: 57664: loss: 0.6953583126:
Dev-Acc: 5: Accuracy: 0.3298539519: precision: 0.0656899345: recall: 0.7928923652: f1: 0.1213280254
Train-Acc: 5: Accuracy: 0.4574485719: precision: 0.2894288553: recall: 0.8042206298: f1: 0.4256659185
6: 6464: loss: 0.6945166266:
6: 12864: loss: 0.6940680623:
6: 19264: loss: 0.6943200719:
6: 25664: loss: 0.6945028128:
6: 32064: loss: 0.6945644234:
6: 38464: loss: 0.6943811772:
6: 44864: loss: 0.6942009535:
6: 51264: loss: 0.6941784700:
6: 57664: loss: 0.6941886502:
Dev-Acc: 6: Accuracy: 0.3474162519: precision: 0.0665180446: recall: 0.7813297058: f1: 0.1225987193
Train-Acc: 6: Accuracy: 0.4738018811: precision: 0.2947856881: recall: 0.7935047005: f1: 0.4298739226
7: 6464: loss: 0.6928618222:
7: 12864: loss: 0.6924282545:
7: 19264: loss: 0.6926851759:
7: 25664: loss: 0.6927979150:
7: 32064: loss: 0.6927922792:
7: 38464: loss: 0.6926230799:
7: 44864: loss: 0.6925842629:
7: 51264: loss: 0.6925247326:
7: 57664: loss: 0.6925129280:
Dev-Acc: 7: Accuracy: 0.3654647470: precision: 0.0674294568: recall: 0.7695970073: f1: 0.1239949043
Train-Acc: 7: Accuracy: 0.4919466376: precision: 0.3012078701: recall: 0.7819998685: f1: 0.4349018317
8: 6464: loss: 0.6904672164:
8: 12864: loss: 0.6914384955:
8: 19264: loss: 0.6917130248:
8: 25664: loss: 0.6913794652:
8: 32064: loss: 0.6912387263:
8: 38464: loss: 0.6911482169:
8: 44864: loss: 0.6910299969:
8: 51264: loss: 0.6909480879:
8: 57664: loss: 0.6909120231:
Dev-Acc: 8: Accuracy: 0.3837910593: precision: 0.0683189754: recall: 0.7565039959: f1: 0.1253204135
Train-Acc: 8: Accuracy: 0.5111268163: precision: 0.3084203311: recall: 0.7691144566: f1: 0.4402837627
9: 6464: loss: 0.6902295011:
9: 12864: loss: 0.6901433086:
9: 19264: loss: 0.6902350668:
9: 25664: loss: 0.6902598886:
9: 32064: loss: 0.6901406221:
9: 38464: loss: 0.6901228808:
9: 44864: loss: 0.6901285672:
9: 51264: loss: 0.6900823160:
9: 57664: loss: 0.6898940057:
Dev-Acc: 9: Accuracy: 0.4013732374: precision: 0.0691554177: recall: 0.7430709063: f1: 0.1265346305
Train-Acc: 9: Accuracy: 0.5311288238: precision: 0.3165854062: recall: 0.7555716258: f1: 0.4462087976
10: 6464: loss: 0.6893207133:
10: 12864: loss: 0.6892281324:
10: 19264: loss: 0.6891503555:
10: 25664: loss: 0.6891568285:
10: 32064: loss: 0.6890133499:
10: 38464: loss: 0.6889285590:
10: 44864: loss: 0.6888858271:
10: 51264: loss: 0.6888468593:
10: 57664: loss: 0.6888040086:
Dev-Acc: 10: Accuracy: 0.4182409942: precision: 0.0696536083: recall: 0.7258969563: f1: 0.1271103171
Train-Acc: 10: Accuracy: 0.5526099801: precision: 0.3263848734: recall: 0.7421602787: f1: 0.4533825980
11: 6464: loss: 0.6869629776:
11: 12864: loss: 0.6872112748:
11: 19264: loss: 0.6874705573:
11: 25664: loss: 0.6874110191:
11: 32064: loss: 0.6872796340:
11: 38464: loss: 0.6873978997:
11: 44864: loss: 0.6874295373:
11: 51264: loss: 0.6874692088:
11: 57664: loss: 0.6873701586:
Dev-Acc: 11: Accuracy: 0.4362795651: precision: 0.0701058424: recall: 0.7061724197: f1: 0.1275491400
Train-Acc: 11: Accuracy: 0.5724475980: precision: 0.3359552950: recall: 0.7272368681: f1: 0.4595953301
12: 6464: loss: 0.6870645988:
12: 12864: loss: 0.6864390987:
12: 19264: loss: 0.6865325594:
12: 25664: loss: 0.6864273678:
12: 32064: loss: 0.6863130836:
12: 38464: loss: 0.6862440931:
12: 44864: loss: 0.6861782788:
12: 51264: loss: 0.6861522812:
12: 57664: loss: 0.6861078654:
Dev-Acc: 12: Accuracy: 0.4550722241: precision: 0.0705340410: recall: 0.6847474919: f1: 0.1278940515
Train-Acc: 12: Accuracy: 0.5921866298: precision: 0.3460329677: recall: 0.7093550720: f1: 0.4651563814
13: 6464: loss: 0.6843265027:
13: 12864: loss: 0.6846528488:
13: 19264: loss: 0.6850230308:
13: 25664: loss: 0.6850727025:
13: 32064: loss: 0.6851815208:
13: 38464: loss: 0.6851402419:
13: 44864: loss: 0.6851185687:
13: 51264: loss: 0.6850421041:
13: 57664: loss: 0.6849510432:
Dev-Acc: 13: Accuracy: 0.4733290970: precision: 0.0714402455: recall: 0.6689338548: f1: 0.1290936536
Train-Acc: 13: Accuracy: 0.6137170792: precision: 0.3587586019: recall: 0.6923279206: f1: 0.4726130371
14: 6464: loss: 0.6845070422:
14: 12864: loss: 0.6841707185:
14: 19264: loss: 0.6841477297:
14: 25664: loss: 0.6841938896:
14: 32064: loss: 0.6839157976:
14: 38464: loss: 0.6837575342:
14: 44864: loss: 0.6837587495:
14: 51264: loss: 0.6838286410:
14: 57664: loss: 0.6836603090:
Dev-Acc: 14: Accuracy: 0.4927468598: precision: 0.0723495160: recall: 0.6507396701: f1: 0.1302210048
Train-Acc: 14: Accuracy: 0.6324206591: precision: 0.3706983806: recall: 0.6741831569: f1: 0.4783673469
15: 6464: loss: 0.6829768169:
15: 12864: loss: 0.6827587885:
15: 19264: loss: 0.6826186540:
15: 25664: loss: 0.6826104976:
15: 32064: loss: 0.6824141403:
15: 38464: loss: 0.6824774561:
15: 44864: loss: 0.6823629171:
15: 51264: loss: 0.6822989870:
15: 57664: loss: 0.6822940100:
Dev-Acc: 15: Accuracy: 0.5096145868: precision: 0.0735524563: recall: 0.6384968543: f1: 0.1319094374
Train-Acc: 15: Accuracy: 0.6515186429: precision: 0.3846627656: recall: 0.6568930379: f1: 0.4852016413
16: 6464: loss: 0.6818369460:
16: 12864: loss: 0.6818018478:
16: 19264: loss: 0.6816824524:
16: 25664: loss: 0.6814497139:
16: 32064: loss: 0.6813251270:
16: 38464: loss: 0.6813220451:
16: 44864: loss: 0.6812636606:
16: 51264: loss: 0.6811792113:
16: 57664: loss: 0.6810155141:
Dev-Acc: 16: Accuracy: 0.5272563100: precision: 0.0743579291: recall: 0.6203026696: f1: 0.1327970004
Train-Acc: 16: Accuracy: 0.6701564789: precision: 0.4003282725: recall: 0.6413779502: f1: 0.4929637958
17: 6464: loss: 0.6807365835:
17: 12864: loss: 0.6808356255:
17: 19264: loss: 0.6807209911:
17: 25664: loss: 0.6804881728:
17: 32064: loss: 0.6802061582:
17: 38464: loss: 0.6800540304:
17: 44864: loss: 0.6798267656:
17: 51264: loss: 0.6797581799:
17: 57664: loss: 0.6796917340:
Dev-Acc: 17: Accuracy: 0.5465053916: precision: 0.0753465558: recall: 0.6007481721: f1: 0.1338993008
Train-Acc: 17: Accuracy: 0.6865755320: precision: 0.4155468989: recall: 0.6241535731: f1: 0.4989226969
18: 6464: loss: 0.6790536034:
18: 12864: loss: 0.6791382098:
18: 19264: loss: 0.6789874979:
18: 25664: loss: 0.6789904164:
18: 32064: loss: 0.6788942113:
18: 38464: loss: 0.6787951615:
18: 44864: loss: 0.6787832580:
18: 51264: loss: 0.6787664326:
18: 57664: loss: 0.6786217523:
Dev-Acc: 18: Accuracy: 0.5647820830: precision: 0.0766040933: recall: 0.5842543785: f1: 0.1354489012
Train-Acc: 18: Accuracy: 0.7015153766: precision: 0.4310747664: recall: 0.6064690027: f1: 0.5039469012
19: 6464: loss: 0.6776600492:
19: 12864: loss: 0.6776573047:
19: 19264: loss: 0.6778003448:
19: 25664: loss: 0.6774920887:
19: 32064: loss: 0.6774239661:
19: 38464: loss: 0.6773976989:
19: 44864: loss: 0.6772963775:
19: 51264: loss: 0.6772214747:
19: 57664: loss: 0.6772862493:
Dev-Acc: 19: Accuracy: 0.5839617252: precision: 0.0780880597: recall: 0.5672504676: f1: 0.1372783013
Train-Acc: 19: Accuracy: 0.7148774266: precision: 0.4468381512: recall: 0.5904279798: f1: 0.5086944208
20: 6464: loss: 0.6757986313:
20: 12864: loss: 0.6755827507:
20: 19264: loss: 0.6757235867:
20: 25664: loss: 0.6756849408:
20: 32064: loss: 0.6758215652:
20: 38464: loss: 0.6759391367:
20: 44864: loss: 0.6757830097:
20: 51264: loss: 0.6757224645:
20: 57664: loss: 0.6757793933:
Dev-Acc: 20: Accuracy: 0.6010477543: precision: 0.0794805831: recall: 0.5516068696: f1: 0.1389412369
Train-Acc: 20: Accuracy: 0.7259877920: precision: 0.4613103120: recall: 0.5726119256: f1: 0.5109703156
