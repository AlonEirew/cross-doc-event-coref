1: 6464: loss: 0.7008432919:
1: 12864: loss: 0.6996336207:
1: 19264: loss: 0.6991445661:
1: 25664: loss: 0.6984112529:
1: 32064: loss: 0.6975483468:
1: 38464: loss: 0.6970634178:
1: 44864: loss: 0.6964610200:
1: 51264: loss: 0.6958114500:
1: 57664: loss: 0.6951298360:
Dev-Acc: 1: Accuracy: 0.4179929197: precision: 0.0696673190: recall: 0.7264070736: f1: 0.1271409652
Train-Acc: 1: Accuracy: 0.5522977114: precision: 0.3261554470: recall: 0.7418315693: f1: 0.4530999036
2: 6464: loss: 0.6873446077:
2: 12864: loss: 0.6872052109:
2: 19264: loss: 0.6861112277:
2: 25664: loss: 0.6853120041:
2: 32064: loss: 0.6847385774:
2: 38464: loss: 0.6842024174:
2: 44864: loss: 0.6836077546:
2: 51264: loss: 0.6829126116:
2: 57664: loss: 0.6823076934:
Dev-Acc: 2: Accuracy: 0.5997082591: precision: 0.0793418290: recall: 0.5526271042: f1: 0.1387613944
Train-Acc: 2: Accuracy: 0.7254454494: precision: 0.4606095760: recall: 0.5742554730: f1: 0.5111923921
3: 6464: loss: 0.6747755575:
3: 12864: loss: 0.6741054747:
3: 19264: loss: 0.6734917118:
3: 25664: loss: 0.6727575141:
3: 32064: loss: 0.6721609168:
3: 38464: loss: 0.6715565296:
3: 44864: loss: 0.6709393508:
3: 51264: loss: 0.6701406603:
3: 57664: loss: 0.6693997822:
Dev-Acc: 3: Accuracy: 0.7403655052: precision: 0.0963467049: recall: 0.4116646829: f1: 0.1561482150
Train-Acc: 3: Accuracy: 0.8052232265: precision: 0.6642871113: recall: 0.4465847084: f1: 0.5341038644
4: 6464: loss: 0.6617642069:
4: 12864: loss: 0.6612756339:
4: 19264: loss: 0.6608557423:
4: 25664: loss: 0.6599875771:
4: 32064: loss: 0.6594726533:
4: 38464: loss: 0.6588183736:
4: 44864: loss: 0.6583468607:
4: 51264: loss: 0.6578680465:
4: 57664: loss: 0.6572209767:
Dev-Acc: 4: Accuracy: 0.8219558597: precision: 0.1222994552: recall: 0.3320863799: f1: 0.1787643021
Train-Acc: 4: Accuracy: 0.8281013966: precision: 0.8471654004: recall: 0.3811715206: f1: 0.5257764679
5: 6464: loss: 0.6505402821:
5: 12864: loss: 0.6491776025:
5: 19264: loss: 0.6487395543:
5: 25664: loss: 0.6481296578:
5: 32064: loss: 0.6476077274:
5: 38464: loss: 0.6469526303:
5: 44864: loss: 0.6464954173:
5: 51264: loss: 0.6459491161:
5: 57664: loss: 0.6454290661:
Dev-Acc: 5: Accuracy: 0.8697015047: precision: 0.1556653053: recall: 0.2786940996: f1: 0.1997562462
Train-Acc: 5: Accuracy: 0.8310105205: precision: 0.9483354557: recall: 0.3427125107: f1: 0.5034769171
6: 6464: loss: 0.6386602581:
6: 12864: loss: 0.6372450966:
6: 19264: loss: 0.6375970119:
6: 25664: loss: 0.6368639794:
6: 32064: loss: 0.6364109485:
6: 38464: loss: 0.6357158222:
6: 44864: loss: 0.6351962900:
6: 51264: loss: 0.6344139145:
6: 57664: loss: 0.6338758707:
Dev-Acc: 6: Accuracy: 0.8945268989: precision: 0.1920632862: recall: 0.2518279204: f1: 0.2179223072
Train-Acc: 6: Accuracy: 0.8273618221: precision: 0.9811899407: recall: 0.3154953652: f1: 0.4774649289
7: 6464: loss: 0.6263207871:
7: 12864: loss: 0.6255530754:
7: 19264: loss: 0.6253365936:
7: 25664: loss: 0.6248014639:
7: 32064: loss: 0.6243735006:
7: 38464: loss: 0.6238401173:
7: 44864: loss: 0.6232134001:
7: 51264: loss: 0.6224922930:
7: 57664: loss: 0.6217572190:
Dev-Acc: 7: Accuracy: 0.9084278941: precision: 0.2260229133: recall: 0.2348240095: f1: 0.2303394212
Train-Acc: 7: Accuracy: 0.8238117695: precision: 0.9921104536: recall: 0.2976135691: f1: 0.4578739759
8: 6464: loss: 0.6133863050:
8: 12864: loss: 0.6135141078:
8: 19264: loss: 0.6129198744:
8: 25664: loss: 0.6126453188:
8: 32064: loss: 0.6120256368:
8: 38464: loss: 0.6115881060:
8: 44864: loss: 0.6111279322:
8: 51264: loss: 0.6104210886:
8: 57664: loss: 0.6098108863:
Dev-Acc: 8: Accuracy: 0.9159687757: precision: 0.2542726927: recall: 0.2276823669: f1: 0.2402440118
Train-Acc: 8: Accuracy: 0.8208698034: precision: 0.9981515712: recall: 0.2840049964: f1: 0.4421925380
9: 6464: loss: 0.6036957413:
9: 12864: loss: 0.6030986628:
9: 19264: loss: 0.6023610530:
9: 25664: loss: 0.6019803408:
9: 32064: loss: 0.6013297951:
9: 38464: loss: 0.6004699647:
9: 44864: loss: 0.6003170727:
9: 51264: loss: 0.5994200554:
9: 57664: loss: 0.5987337701:
Dev-Acc: 9: Accuracy: 0.9208108187: precision: 0.2781065089: recall: 0.2237714674: f1: 0.2479977386
Train-Acc: 9: Accuracy: 0.8189797401: precision: 0.9992862241: recall: 0.2761159687: f1: 0.4326774493
10: 6464: loss: 0.5898804033:
10: 12864: loss: 0.5916765568:
10: 19264: loss: 0.5917247826:
10: 25664: loss: 0.5908714001:
10: 32064: loss: 0.5904922006:
10: 38464: loss: 0.5900353594:
10: 44864: loss: 0.5892116776:
10: 51264: loss: 0.5882406171:
10: 57664: loss: 0.5877116610:
Dev-Acc: 10: Accuracy: 0.9238470197: precision: 0.2961363636: recall: 0.2215609590: f1: 0.2534772882
Train-Acc: 10: Accuracy: 0.8186345696: precision: 0.9997606510: recall: 0.2746039051: f1: 0.4308628604
11: 6464: loss: 0.5758932894:
11: 12864: loss: 0.5771950501:
11: 19264: loss: 0.5775285528:
11: 25664: loss: 0.5776343045:
11: 32064: loss: 0.5775237983:
11: 38464: loss: 0.5770663302:
11: 44864: loss: 0.5765185206:
11: 51264: loss: 0.5762115646:
11: 57664: loss: 0.5758291605:
Dev-Acc: 11: Accuracy: 0.9256429672: precision: 0.3092027443: recall: 0.2222411155: f1: 0.2586070439
Train-Acc: 11: Accuracy: 0.8189304471: precision: 1.0000000000: recall: 0.2757215173: f1: 0.4322597269
12: 6464: loss: 0.5697451526:
12: 12864: loss: 0.5690017790:
12: 19264: loss: 0.5685006440:
12: 25664: loss: 0.5682187988:
12: 32064: loss: 0.5666484269:
12: 38464: loss: 0.5655710801:
12: 44864: loss: 0.5651513172:
12: 51264: loss: 0.5652274157:
12: 57664: loss: 0.5647199275:
Dev-Acc: 12: Accuracy: 0.9265061617: precision: 0.3196217494: recall: 0.2298928754: f1: 0.2674315102
Train-Acc: 12: Accuracy: 0.8202781081: precision: 1.0000000000: recall: 0.2811123529: f1: 0.4388566737
13: 6464: loss: 0.5576343983:
13: 12864: loss: 0.5564658582:
13: 19264: loss: 0.5569266188:
13: 25664: loss: 0.5564463967:
13: 32064: loss: 0.5554848322:
13: 38464: loss: 0.5549890146:
13: 44864: loss: 0.5548612073:
13: 51264: loss: 0.5541956045:
13: 57664: loss: 0.5535104046:
Dev-Acc: 13: Accuracy: 0.9266946912: precision: 0.3265024177: recall: 0.2411154566: f1: 0.2773865415
Train-Acc: 13: Accuracy: 0.8217737675: precision: 1.0000000000: recall: 0.2870948656: f1: 0.4461129840
14: 6464: loss: 0.5456722775:
14: 12864: loss: 0.5457788013:
14: 19264: loss: 0.5452936545:
14: 25664: loss: 0.5451823577:
14: 32064: loss: 0.5447975688:
14: 38464: loss: 0.5441760472:
14: 44864: loss: 0.5436764170:
14: 51264: loss: 0.5429393544:
14: 57664: loss: 0.5423229693:
Dev-Acc: 14: Accuracy: 0.9263474345: precision: 0.3324641460: recall: 0.2601598368: f1: 0.2919011733
Train-Acc: 14: Accuracy: 0.8245513439: precision: 1.0000000000: recall: 0.2982052462: f1: 0.4594115562
15: 6464: loss: 0.5332150817:
15: 12864: loss: 0.5326186915:
15: 19264: loss: 0.5335855170:
15: 25664: loss: 0.5340905350:
15: 32064: loss: 0.5336624385:
15: 38464: loss: 0.5334857732:
15: 44864: loss: 0.5327461563:
15: 51264: loss: 0.5315539142:
15: 57664: loss: 0.5307404183:
Dev-Acc: 15: Accuracy: 0.9252361655: precision: 0.3352589641: recall: 0.2861758204: f1: 0.3087790111
Train-Acc: 15: Accuracy: 0.8271645904: precision: 1.0000000000: recall: 0.3086582079: f1: 0.4717170702
16: 6464: loss: 0.5235346189:
16: 12864: loss: 0.5229159214:
16: 19264: loss: 0.5232790497:
16: 25664: loss: 0.5223500214:
16: 32064: loss: 0.5211640937:
16: 38464: loss: 0.5213118052:
16: 44864: loss: 0.5210263199:
16: 51264: loss: 0.5208897721:
16: 57664: loss: 0.5197651399:
Dev-Acc: 16: Accuracy: 0.9236386418: precision: 0.3319133173: recall: 0.3047100833: f1: 0.3177304965
Train-Acc: 16: Accuracy: 0.8302215934: precision: 1.0000000000: recall: 0.3208862008: f1: 0.4858650209
17: 6464: loss: 0.5140289176:
17: 12864: loss: 0.5129447749:
17: 19264: loss: 0.5135249590:
17: 25664: loss: 0.5127541927:
17: 32064: loss: 0.5112319467:
17: 38464: loss: 0.5103444760:
17: 44864: loss: 0.5094337716:
17: 51264: loss: 0.5090365567:
17: 57664: loss: 0.5080496123:
Dev-Acc: 17: Accuracy: 0.9212176204: precision: 0.3233224644: recall: 0.3203536813: f1: 0.3218312265
Train-Acc: 17: Accuracy: 0.8332950473: precision: 1.0000000000: recall: 0.3331799356: f1: 0.4998274077
18: 6464: loss: 0.5001243868:
18: 12864: loss: 0.4992295654:
18: 19264: loss: 0.4999372360:
18: 25664: loss: 0.4994111423:
18: 32064: loss: 0.4986207583:
18: 38464: loss: 0.4987049422:
18: 44864: loss: 0.4987875156:
18: 51264: loss: 0.4981709469:
18: 57664: loss: 0.4975333549:
Dev-Acc: 18: Accuracy: 0.9183005095: precision: 0.3122706239: recall: 0.3327665363: f1: 0.3221929536
Train-Acc: 18: Accuracy: 0.8377490640: precision: 1.0000000000: recall: 0.3509959897: f1: 0.5196107056
19: 6464: loss: 0.4921112761:
19: 12864: loss: 0.4895554410:
19: 19264: loss: 0.4889432930:
19: 25664: loss: 0.4884491649:
19: 32064: loss: 0.4877680752:
19: 38464: loss: 0.4868222787:
19: 44864: loss: 0.4869677836:
19: 51264: loss: 0.4859326119:
19: 57664: loss: 0.4861251781:
Dev-Acc: 19: Accuracy: 0.9159787297: precision: 0.3083419766: recall: 0.3538513858: f1: 0.3295328583
Train-Acc: 19: Accuracy: 0.8414634466: precision: 0.9998203700: recall: 0.3659194004: f1: 0.5357589758
20: 6464: loss: 0.4751848292:
20: 12864: loss: 0.4779678303:
20: 19264: loss: 0.4763235200:
20: 25664: loss: 0.4758746435:
20: 32064: loss: 0.4766072620:
20: 38464: loss: 0.4763136355:
20: 44864: loss: 0.4760030915:
20: 51264: loss: 0.4756025170:
20: 57664: loss: 0.4750993907:
Dev-Acc: 20: Accuracy: 0.9129524231: precision: 0.2994452150: recall: 0.3671144363: f1: 0.3298449316
Train-Acc: 20: Accuracy: 0.8440274000: precision: 0.9998252665: recall: 0.3761751364: f1: 0.5466704882
