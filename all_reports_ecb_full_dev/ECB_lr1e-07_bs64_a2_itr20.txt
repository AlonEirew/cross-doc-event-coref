1: 6464: loss: 0.6960402548:
1: 12864: loss: 0.6952602127:
1: 19264: loss: 0.6946942725:
1: 25664: loss: 0.6942771445:
1: 32064: loss: 0.6934524621:
1: 38464: loss: 0.6929695079:
1: 44864: loss: 0.6923817954:
Dev-Acc: 1: Accuracy: 0.3333961666: precision: 0.0669049907: recall: 0.8051351811: f1: 0.1235437621
Train-Acc: 1: Accuracy: 0.5314136744: precision: 0.4012100647: recall: 0.8239431990: f1: 0.5396456328
2: 6464: loss: 0.6876254892:
2: 12864: loss: 0.6874245822:
2: 19264: loss: 0.6866907926:
2: 25664: loss: 0.6860296075:
2: 32064: loss: 0.6854697890:
2: 38464: loss: 0.6850107374:
2: 44864: loss: 0.6845284442:
Dev-Acc: 2: Accuracy: 0.4185188115: precision: 0.0723382164: recall: 0.7582043870: f1: 0.1320754717
Train-Acc: 2: Accuracy: 0.6430214643: precision: 0.4783376832: recall: 0.7831832227: f1: 0.5939276099
3: 6464: loss: 0.6803782773:
3: 12864: loss: 0.6801295501:
3: 19264: loss: 0.6795519173:
3: 25664: loss: 0.6789629963:
3: 32064: loss: 0.6786163311:
3: 38464: loss: 0.6778738124:
3: 44864: loss: 0.6773753036:
Dev-Acc: 3: Accuracy: 0.5005655885: precision: 0.0788266950: recall: 0.7073626934: f1: 0.1418463899
Train-Acc: 3: Accuracy: 0.7371419668: precision: 0.5846939850: recall: 0.7298008021: f1: 0.6492382373
4: 6464: loss: 0.6732636386:
4: 12864: loss: 0.6726169828:
4: 19264: loss: 0.6716562178:
4: 25664: loss: 0.6710182729:
4: 32064: loss: 0.6707561628:
4: 38464: loss: 0.6702751290:
4: 44864: loss: 0.6698687767:
Dev-Acc: 4: Accuracy: 0.5763712525: precision: 0.0881918654: recall: 0.6702941677: f1: 0.1558749679
Train-Acc: 4: Accuracy: 0.7969013453: precision: 0.7013620655: recall: 0.6804286372: f1: 0.6907367859
5: 6464: loss: 0.6651093179:
5: 12864: loss: 0.6646242446:
5: 19264: loss: 0.6646524868:
5: 25664: loss: 0.6641264793:
5: 32064: loss: 0.6634869094:
5: 38464: loss: 0.6629773417:
5: 44864: loss: 0.6624354370:
Dev-Acc: 5: Accuracy: 0.6414311528: precision: 0.0986602998: recall: 0.6323754464: f1: 0.1706902882
Train-Acc: 5: Accuracy: 0.8277562261: precision: 0.8043388259: recall: 0.6386167905: f1: 0.7119613017
6: 6464: loss: 0.6587702268:
6: 12864: loss: 0.6583980900:
6: 19264: loss: 0.6575461324:
6: 25664: loss: 0.6569841361:
6: 32064: loss: 0.6562302639:
6: 38464: loss: 0.6557730423:
6: 44864: loss: 0.6552996126:
Dev-Acc: 6: Accuracy: 0.6946836710: precision: 0.1112638221: recall: 0.6056793062: f1: 0.1879931389
Train-Acc: 6: Accuracy: 0.8409045935: precision: 0.8764321560: recall: 0.6085070015: f1: 0.7182989291
7: 6464: loss: 0.6505816430:
7: 12864: loss: 0.6506063411:
7: 19264: loss: 0.6501767598:
7: 25664: loss: 0.6494788030:
7: 32064: loss: 0.6488577977:
7: 38464: loss: 0.6483829726:
7: 44864: loss: 0.6478802044:
Dev-Acc: 7: Accuracy: 0.7338268161: precision: 0.1240351822: recall: 0.5874851216: f1: 0.2048257055
Train-Acc: 7: Accuracy: 0.8435781002: precision: 0.9131102241: recall: 0.5865492078: f1: 0.7142742775
8: 6464: loss: 0.6440513986:
8: 12864: loss: 0.6432874861:
8: 19264: loss: 0.6432625035:
8: 25664: loss: 0.6426506877:
8: 32064: loss: 0.6419077169:
8: 38464: loss: 0.6413191749:
8: 44864: loss: 0.6409804623:
Dev-Acc: 8: Accuracy: 0.7637422681: precision: 0.1364557989: recall: 0.5721816018: f1: 0.2203595167
Train-Acc: 8: Accuracy: 0.8453969359: precision: 0.9399137001: recall: 0.5728091513: f1: 0.7118173277
9: 6464: loss: 0.6383212012:
9: 12864: loss: 0.6367560709:
9: 19264: loss: 0.6357618292:
9: 25664: loss: 0.6352800171:
9: 32064: loss: 0.6346671290:
9: 38464: loss: 0.6338190552:
9: 44864: loss: 0.6331960295:
Dev-Acc: 9: Accuracy: 0.7848864794: precision: 0.1474853853: recall: 0.5619792552: f1: 0.2336514669
Train-Acc: 9: Accuracy: 0.8453750610: precision: 0.9523017194: recall: 0.5643941884: f1: 0.7087426732
10: 6464: loss: 0.6312375873:
10: 12864: loss: 0.6295068198:
10: 19264: loss: 0.6282979534:
10: 25664: loss: 0.6273879656:
10: 32064: loss: 0.6269827461:
10: 38464: loss: 0.6264930236:
10: 44864: loss: 0.6259569986:
Dev-Acc: 10: Accuracy: 0.8004841805: precision: 0.1578567649: recall: 0.5580683557: f1: 0.2461007798
Train-Acc: 10: Accuracy: 0.8448710442: precision: 0.9601629697: recall: 0.5577542568: f1: 0.7056181644
11: 6464: loss: 0.6223071337:
11: 12864: loss: 0.6209479728:
11: 19264: loss: 0.6204004860:
11: 25664: loss: 0.6193010288:
11: 32064: loss: 0.6187755708:
11: 38464: loss: 0.6184214774:
11: 44864: loss: 0.6179689473:
Dev-Acc: 11: Accuracy: 0.8111406565: precision: 0.1658452314: recall: 0.5550076518: f1: 0.2553790783
Train-Acc: 11: Accuracy: 0.8442136049: precision: 0.9649908173: recall: 0.5526921307: f1: 0.7028382728
12: 6464: loss: 0.6133411384:
12: 12864: loss: 0.6130778575:
12: 19264: loss: 0.6125172067:
12: 25664: loss: 0.6121853544:
12: 32064: loss: 0.6116832387:
12: 38464: loss: 0.6112404200:
12: 44864: loss: 0.6105059922:
Dev-Acc: 12: Accuracy: 0.8186517358: precision: 0.1721675659: recall: 0.5534772998: f1: 0.2626376730
Train-Acc: 12: Accuracy: 0.8441259265: precision: 0.9670126874: recall: 0.5511800671: f1: 0.7021481512
13: 6464: loss: 0.6069933629:
13: 12864: loss: 0.6048818707:
13: 19264: loss: 0.6040883613:
13: 25664: loss: 0.6037044291:
13: 32064: loss: 0.6032881119:
13: 38464: loss: 0.6030712303:
13: 44864: loss: 0.6026816142:
Dev-Acc: 13: Accuracy: 0.8238708377: precision: 0.1775157574: recall: 0.5555177691: f1: 0.2690549722
Train-Acc: 13: Accuracy: 0.8447395563: precision: 0.9683033656: recall: 0.5522976793: f1: 0.7033951522
14: 6464: loss: 0.5996641582:
14: 12864: loss: 0.5991654366:
14: 19264: loss: 0.5977005313:
14: 25664: loss: 0.5966006106:
14: 32064: loss: 0.5961187669:
14: 38464: loss: 0.5957096686:
14: 44864: loss: 0.5949619320:
Dev-Acc: 14: Accuracy: 0.8271253109: precision: 0.1811954480: recall: 0.5577282775: f1: 0.2735270817
Train-Acc: 14: Accuracy: 0.8453093171: precision: 0.9683980694: recall: 0.5540069686: f1: 0.7048049178
15: 6464: loss: 0.5912924248:
15: 12864: loss: 0.5901984534:
15: 19264: loss: 0.5897224327:
15: 25664: loss: 0.5894066237:
15: 32064: loss: 0.5884225552:
15: 38464: loss: 0.5876729350:
15: 44864: loss: 0.5871882344:
Dev-Acc: 15: Accuracy: 0.8289212584: precision: 0.1832022754: recall: 0.5585784730: f1: 0.2759113052
Train-Acc: 15: Accuracy: 0.8460763097: precision: 0.9688466384: recall: 0.5561107094: f1: 0.7066243422
16: 6464: loss: 0.5819999021:
16: 12864: loss: 0.5818622106:
16: 19264: loss: 0.5810229615:
16: 25664: loss: 0.5806434803:
16: 32064: loss: 0.5798305389:
16: 38464: loss: 0.5793650652:
16: 44864: loss: 0.5790237894:
Dev-Acc: 16: Accuracy: 0.8295165896: precision: 0.1844882461: recall: 0.5618092161: f1: 0.2777637663
Train-Acc: 16: Accuracy: 0.8471938968: precision: 0.9697764599: recall: 0.5590033528: f1: 0.7092038867
17: 6464: loss: 0.5742195916:
17: 12864: loss: 0.5731421944:
17: 19264: loss: 0.5730482602:
17: 25664: loss: 0.5732277936:
17: 32064: loss: 0.5724380639:
17: 38464: loss: 0.5717119435:
17: 44864: loss: 0.5708061559:
Dev-Acc: 17: Accuracy: 0.8290502429: precision: 0.1842866682: recall: 0.5631695290: f1: 0.2777009181
Train-Acc: 17: Accuracy: 0.8483115435: precision: 0.9698446888: recall: 0.5624219315: f1: 0.7119673768
18: 6464: loss: 0.5663099915:
18: 12864: loss: 0.5643877760:
18: 19264: loss: 0.5644296132:
18: 25664: loss: 0.5636434981:
18: 32064: loss: 0.5628205310:
18: 38464: loss: 0.5626584849:
18: 44864: loss: 0.5624229994:
Dev-Acc: 18: Accuracy: 0.8277801871: precision: 0.1830884790: recall: 0.5636796463: f1: 0.2763997165
Train-Acc: 18: Accuracy: 0.8501084447: precision: 0.9699113057: recall: 0.5679442509: f1: 0.7163943942
19: 6464: loss: 0.5577642798:
19: 12864: loss: 0.5567805156:
19: 19264: loss: 0.5565017903:
19: 25664: loss: 0.5560027854:
19: 32064: loss: 0.5559930912:
19: 38464: loss: 0.5548823165:
19: 44864: loss: 0.5543722777:
Dev-Acc: 19: Accuracy: 0.8256369829: precision: 0.1822826087: recall: 0.5703111716: f1: 0.2762653927
Train-Acc: 19: Accuracy: 0.8515548110: precision: 0.9702374317: recall: 0.5722174742: f1: 0.7198742867
20: 6464: loss: 0.5533890533:
20: 12864: loss: 0.5508535606:
20: 19264: loss: 0.5501298747:
20: 25664: loss: 0.5496060072:
20: 32064: loss: 0.5489093696:
20: 38464: loss: 0.5477081655:
20: 44864: loss: 0.5464379972:
Dev-Acc: 20: Accuracy: 0.8234937787: precision: 0.1812292537: recall: 0.5755823839: f1: 0.2756626898
Train-Acc: 20: Accuracy: 0.8527600765: precision: 0.9698981850: recall: 0.5761619880: f1: 0.7228935538
