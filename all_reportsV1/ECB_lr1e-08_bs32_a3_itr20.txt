1: 3232: loss: 0.7023466277:
1: 6432: loss: 0.7010228211:
1: 9632: loss: 0.7012513673:
1: 12832: loss: 0.7008954832:
1: 16032: loss: 0.7008829293:
1: 19232: loss: 0.7009633703:
1: 22432: loss: 0.7008928200:
1: 25632: loss: 0.7007430954:
1: 28832: loss: 0.7006115197:
1: 32032: loss: 0.7004601020:
1: 35232: loss: 0.7003165411:
1: 38432: loss: 0.7003476019:
1: 41632: loss: 0.7003550136:
1: 44832: loss: 0.7003598128:
1: 48032: loss: 0.7003955051:
1: 51232: loss: 0.7003727700:
1: 54432: loss: 0.7002883122:
1: 57632: loss: 0.7002604845:
1: 60832: loss: 0.7002182353:
Dev-Acc: 1: Accuracy: 0.2791514397: precision: 0.0637552759: recall: 0.8296208128: f1: 0.1184108339
Train-Acc: 1: Accuracy: 0.4084544182: precision: 0.2753162504: recall: 0.8370258366: f1: 0.4143452226
2: 3232: loss: 0.6980956930:
2: 6432: loss: 0.6982385337:
2: 9632: loss: 0.6985294720:
2: 12832: loss: 0.6986844148:
2: 16032: loss: 0.6984811976:
2: 19232: loss: 0.6981415999:
2: 22432: loss: 0.6982695340:
2: 25632: loss: 0.6980942301:
2: 28832: loss: 0.6981152185:
2: 32032: loss: 0.6981933423:
2: 35232: loss: 0.6982351338:
2: 38432: loss: 0.6981576705:
2: 41632: loss: 0.6980551577:
2: 44832: loss: 0.6980236345:
2: 48032: loss: 0.6979705441:
2: 51232: loss: 0.6979310399:
2: 54432: loss: 0.6978308614:
2: 57632: loss: 0.6978288335:
2: 60832: loss: 0.6977518771:
Dev-Acc: 2: Accuracy: 0.3047110736: precision: 0.0647873192: recall: 0.8124468628: f1: 0.1200050232
Train-Acc: 2: Accuracy: 0.4308066666: precision: 0.2809941586: recall: 0.8190782986: f1: 0.4184382872
3: 3232: loss: 0.6963667375:
3: 6432: loss: 0.6962549677:
3: 9632: loss: 0.6960141766:
3: 12832: loss: 0.6962718044:
3: 16032: loss: 0.6960763525:
3: 19232: loss: 0.6961401201:
3: 22432: loss: 0.6963266878:
3: 25632: loss: 0.6962007210:
3: 28832: loss: 0.6960810781:
3: 32032: loss: 0.6959330271:
3: 35232: loss: 0.6959781054:
3: 38432: loss: 0.6960700665:
3: 41632: loss: 0.6959612871:
3: 44832: loss: 0.6959115672:
3: 48032: loss: 0.6959869730:
3: 51232: loss: 0.6958568247:
3: 54432: loss: 0.6958613707:
3: 57632: loss: 0.6957157162:
3: 60832: loss: 0.6956692287:
Dev-Acc: 3: Accuracy: 0.3318979144: precision: 0.0657584194: recall: 0.7911919742: f1: 0.1214248434
Train-Acc: 3: Accuracy: 0.4583360851: precision: 0.2893799848: recall: 0.8014594701: f1: 0.4252254138
4: 3232: loss: 0.6934152353:
4: 6432: loss: 0.6946969101:
4: 9632: loss: 0.6948125356:
4: 12832: loss: 0.6946318448:
4: 16032: loss: 0.6945933123:
4: 19232: loss: 0.6943265965:
4: 22432: loss: 0.6944333513:
4: 25632: loss: 0.6942744404:
4: 28832: loss: 0.6942336222:
4: 32032: loss: 0.6941617346:
4: 35232: loss: 0.6941557285:
4: 38432: loss: 0.6940932131:
4: 41632: loss: 0.6940053830:
4: 44832: loss: 0.6939052812:
4: 48032: loss: 0.6939084766:
4: 51232: loss: 0.6938052524:
4: 54432: loss: 0.6937002158:
4: 57632: loss: 0.6936569485:
4: 60832: loss: 0.6935191303:
Dev-Acc: 4: Accuracy: 0.3618133664: precision: 0.0670104620: recall: 0.7689168509: f1: 0.1232774014
Train-Acc: 4: Accuracy: 0.4867694676: precision: 0.2986523182: recall: 0.7808822563: f1: 0.4320608188
5: 3232: loss: 0.6928265917:
5: 6432: loss: 0.6927403581:
5: 9632: loss: 0.6925457114:
5: 12832: loss: 0.6927601619:
5: 16032: loss: 0.6927155451:
5: 19232: loss: 0.6926835360:
5: 22432: loss: 0.6924343861:
5: 25632: loss: 0.6923170336:
5: 28832: loss: 0.6923414513:
5: 32032: loss: 0.6921770144:
5: 35232: loss: 0.6919427963:
5: 38432: loss: 0.6918657076:
5: 41632: loss: 0.6918162780:
5: 44832: loss: 0.6917165429:
5: 48032: loss: 0.6916546388:
5: 51232: loss: 0.6916182689:
5: 54432: loss: 0.6915526460:
5: 57632: loss: 0.6914951190:
5: 60832: loss: 0.6914043757:
Dev-Acc: 5: Accuracy: 0.3927607536: precision: 0.0685820348: recall: 0.7476619623: f1: 0.1256393405
Train-Acc: 5: Accuracy: 0.5189830065: precision: 0.3107598686: recall: 0.7587272369: f1: 0.4409253281
6: 3232: loss: 0.6896020770:
6: 6432: loss: 0.6899814996:
6: 9632: loss: 0.6899051529:
6: 12832: loss: 0.6897682935:
6: 16032: loss: 0.6896794310:
6: 19232: loss: 0.6896159889:
6: 22432: loss: 0.6895257636:
6: 25632: loss: 0.6895287609:
6: 28832: loss: 0.6895848898:
6: 32032: loss: 0.6896095688:
6: 35232: loss: 0.6895307780:
6: 38432: loss: 0.6894957610:
6: 41632: loss: 0.6894587836:
6: 44832: loss: 0.6893131540:
6: 48032: loss: 0.6892276881:
6: 51232: loss: 0.6891564892:
6: 54432: loss: 0.6891397479:
6: 57632: loss: 0.6891171174:
6: 60832: loss: 0.6890753803:
Dev-Acc: 6: Accuracy: 0.4222991765: precision: 0.0697399139: recall: 0.7213059004: f1: 0.1271830543
Train-Acc: 6: Accuracy: 0.5530866385: precision: 0.3254160231: recall: 0.7340740254: f1: 0.4509328810
7: 3232: loss: 0.6877533484:
7: 6432: loss: 0.6875665748:
7: 9632: loss: 0.6870596872:
7: 12832: loss: 0.6872636108:
7: 16032: loss: 0.6874492197:
7: 19232: loss: 0.6873701752:
7: 22432: loss: 0.6875153151:
7: 25632: loss: 0.6876137716:
7: 28832: loss: 0.6875679509:
7: 32032: loss: 0.6874674914:
7: 35232: loss: 0.6874782375:
7: 38432: loss: 0.6873717561:
7: 41632: loss: 0.6874005059:
7: 44832: loss: 0.6872498729:
7: 48032: loss: 0.6871407675:
7: 51232: loss: 0.6870942574:
7: 54432: loss: 0.6870246119:
7: 57632: loss: 0.6870229765:
7: 60832: loss: 0.6869547530:
Dev-Acc: 7: Accuracy: 0.4540998638: precision: 0.0703079910: recall: 0.6835572182: f1: 0.1275016651
Train-Acc: 7: Accuracy: 0.5866807103: precision: 0.3416818022: recall: 0.7049503649: f1: 0.4602738550
8: 3232: loss: 0.6847010082:
8: 6432: loss: 0.6848658121:
8: 9632: loss: 0.6857250444:
8: 12832: loss: 0.6856033491:
8: 16032: loss: 0.6857251930:
8: 19232: loss: 0.6858359336:
8: 22432: loss: 0.6857594610:
8: 25632: loss: 0.6857686969:
8: 28832: loss: 0.6856264210:
8: 32032: loss: 0.6854921186:
8: 35232: loss: 0.6854247198:
8: 38432: loss: 0.6853406287:
8: 41632: loss: 0.6852345186:
8: 44832: loss: 0.6851650333:
8: 48032: loss: 0.6851501859:
8: 51232: loss: 0.6851402856:
8: 54432: loss: 0.6851252985:
8: 57632: loss: 0.6850739448:
8: 60832: loss: 0.6850757978:
Dev-Acc: 8: Accuracy: 0.4853448868: precision: 0.0715829483: recall: 0.6532902568: f1: 0.1290279247
Train-Acc: 8: Accuracy: 0.6203734279: precision: 0.3611492553: recall: 0.6743146407: f1: 0.4703751261
9: 3232: loss: 0.6843507576:
9: 6432: loss: 0.6842463019:
9: 9632: loss: 0.6840341353:
9: 12832: loss: 0.6836685069:
9: 16032: loss: 0.6835150181:
9: 19232: loss: 0.6834878389:
9: 22432: loss: 0.6834536910:
9: 25632: loss: 0.6834972572:
9: 28832: loss: 0.6835074974:
9: 32032: loss: 0.6833110532:
9: 35232: loss: 0.6831372292:
9: 38432: loss: 0.6832128248:
9: 41632: loss: 0.6831908642:
9: 44832: loss: 0.6831058020:
9: 48032: loss: 0.6829769187:
9: 51232: loss: 0.6828286109:
9: 54432: loss: 0.6827537593:
9: 57632: loss: 0.6826413254:
9: 60832: loss: 0.6826282257:
Dev-Acc: 9: Accuracy: 0.5149527788: precision: 0.0734745695: recall: 0.6298248597: f1: 0.1315971790
Train-Acc: 9: Accuracy: 0.6524719000: precision: 0.3839292700: recall: 0.6451909802: f1: 0.4813970029
10: 3232: loss: 0.6813855892:
10: 6432: loss: 0.6806191429:
10: 9632: loss: 0.6811489733:
10: 12832: loss: 0.6814720909:
10: 16032: loss: 0.6811545422:
10: 19232: loss: 0.6812418983:
10: 22432: loss: 0.6813752232:
10: 25632: loss: 0.6814035169:
10: 28832: loss: 0.6814213525:
10: 32032: loss: 0.6813902943:
10: 35232: loss: 0.6813707757:
10: 38432: loss: 0.6812931920:
10: 41632: loss: 0.6812438961:
10: 44832: loss: 0.6811075415:
10: 48032: loss: 0.6809552737:
10: 51232: loss: 0.6808605184:
10: 54432: loss: 0.6808002027:
10: 57632: loss: 0.6806947338:
10: 60832: loss: 0.6806420828:
Dev-Acc: 10: Accuracy: 0.5471602678: precision: 0.0750171028: recall: 0.5966672335: f1: 0.1332776269
Train-Acc: 10: Accuracy: 0.6823351979: precision: 0.4100738281: recall: 0.6171191901: f1: 0.4927300404
11: 3232: loss: 0.6789849901:
11: 6432: loss: 0.6785106283:
11: 9632: loss: 0.6785714654:
11: 12832: loss: 0.6788120413:
11: 16032: loss: 0.6787775110:
11: 19232: loss: 0.6788986418:
11: 22432: loss: 0.6789209482:
11: 25632: loss: 0.6787271743:
11: 28832: loss: 0.6785895424:
11: 32032: loss: 0.6785478922:
11: 35232: loss: 0.6786816285:
11: 38432: loss: 0.6786737859:
11: 41632: loss: 0.6787458185:
11: 44832: loss: 0.6785678998:
11: 48032: loss: 0.6785703271:
11: 51232: loss: 0.6785831610:
11: 54432: loss: 0.6785837618:
11: 57632: loss: 0.6784663264:
11: 60832: loss: 0.6784463673:
Dev-Acc: 11: Accuracy: 0.5785045028: precision: 0.0770564171: recall: 0.5669103894: f1: 0.1356718483
Train-Acc: 11: Accuracy: 0.7064788938: precision: 0.4354712935: recall: 0.5874038525: f1: 0.5001539366
12: 3232: loss: 0.6782386351:
12: 6432: loss: 0.6776106375:
12: 9632: loss: 0.6774191362:
12: 12832: loss: 0.6771893646:
12: 16032: loss: 0.6772283537:
12: 19232: loss: 0.6771214891:
12: 22432: loss: 0.6770261287:
12: 25632: loss: 0.6770353758:
12: 28832: loss: 0.6768658500:
12: 32032: loss: 0.6767371166:
12: 35232: loss: 0.6768491907:
12: 38432: loss: 0.6767425162:
12: 41632: loss: 0.6767447632:
12: 44832: loss: 0.6766576485:
12: 48032: loss: 0.6766543675:
12: 51232: loss: 0.6766297830:
12: 54432: loss: 0.6765682717:
12: 57632: loss: 0.6765438966:
12: 60832: loss: 0.6764758764:
Dev-Acc: 12: Accuracy: 0.6085291505: precision: 0.0790852787: recall: 0.5363033498: f1: 0.1378436257
Train-Acc: 12: Accuracy: 0.7263000607: precision: 0.4606870229: recall: 0.5554532904: f1: 0.5036511579
13: 3232: loss: 0.6751369607:
13: 6432: loss: 0.6751671523:
13: 9632: loss: 0.6750464475:
13: 12832: loss: 0.6747287561:
13: 16032: loss: 0.6750784005:
13: 19232: loss: 0.6750659285:
13: 22432: loss: 0.6750777207:
13: 25632: loss: 0.6751120280:
13: 28832: loss: 0.6750256275:
13: 32032: loss: 0.6749813346:
13: 35232: loss: 0.6750189981:
13: 38432: loss: 0.6749426461:
13: 41632: loss: 0.6748413753:
13: 44832: loss: 0.6748220542:
13: 48032: loss: 0.6747066087:
13: 51232: loss: 0.6746784875:
13: 54432: loss: 0.6746245868:
13: 57632: loss: 0.6745343757:
13: 60832: loss: 0.6745053340:
Dev-Acc: 13: Accuracy: 0.6351107359: precision: 0.0797649491: recall: 0.4985546676: f1: 0.1375266775
Train-Acc: 13: Accuracy: 0.7450200915: precision: 0.4907435694: recall: 0.5280389192: f1: 0.5087085946
14: 3232: loss: 0.6718157381:
14: 6432: loss: 0.6727618891:
14: 9632: loss: 0.6726577789:
14: 12832: loss: 0.6726362024:
14: 16032: loss: 0.6724899806:
14: 19232: loss: 0.6723639660:
14: 22432: loss: 0.6723807303:
14: 25632: loss: 0.6725720499:
14: 28832: loss: 0.6723939510:
14: 32032: loss: 0.6723303400:
14: 35232: loss: 0.6721990475:
14: 38432: loss: 0.6721311526:
14: 41632: loss: 0.6720410264:
14: 44832: loss: 0.6720892607:
14: 48032: loss: 0.6721682628:
14: 51232: loss: 0.6721471694:
14: 54432: loss: 0.6720805524:
14: 57632: loss: 0.6720715942:
14: 60832: loss: 0.6720632490:
Dev-Acc: 14: Accuracy: 0.6620991230: precision: 0.0817647408: recall: 0.4682877062: f1: 0.1392209893
Train-Acc: 14: Accuracy: 0.7624909878: precision: 0.5261096606: recall: 0.5033857077: f1: 0.5144968923
15: 3232: loss: 0.6710200071:
15: 6432: loss: 0.6715138915:
15: 9632: loss: 0.6714166484:
15: 12832: loss: 0.6712674190:
15: 16032: loss: 0.6710788939:
15: 19232: loss: 0.6711228413:
15: 22432: loss: 0.6710284698:
15: 25632: loss: 0.6710613404:
15: 28832: loss: 0.6709502431:
15: 32032: loss: 0.6708024029:
15: 35232: loss: 0.6706626586:
15: 38432: loss: 0.6706022325:
15: 41632: loss: 0.6705863384:
15: 44832: loss: 0.6704614625:
15: 48032: loss: 0.6703848744:
15: 51232: loss: 0.6703609120:
15: 54432: loss: 0.6702980605:
15: 57632: loss: 0.6702692941:
15: 60832: loss: 0.6702326594:
Dev-Acc: 15: Accuracy: 0.6883136034: precision: 0.0848995253: recall: 0.4439721136: f1: 0.1425412857
Train-Acc: 15: Accuracy: 0.7763953805: precision: 0.5615231382: recall: 0.4818223654: f1: 0.5186285957
16: 3232: loss: 0.6688155848:
16: 6432: loss: 0.6688738090:
16: 9632: loss: 0.6690758431:
16: 12832: loss: 0.6688914032:
16: 16032: loss: 0.6685781624:
16: 19232: loss: 0.6688332690:
16: 22432: loss: 0.6684360992:
16: 25632: loss: 0.6684069867:
16: 28832: loss: 0.6683666960:
16: 32032: loss: 0.6683297626:
16: 35232: loss: 0.6683042006:
16: 38432: loss: 0.6682726203:
16: 41632: loss: 0.6681626528:
16: 44832: loss: 0.6681881568:
16: 48032: loss: 0.6682114737:
16: 51232: loss: 0.6681577809:
16: 54432: loss: 0.6681097050:
16: 57632: loss: 0.6680877767:
16: 60832: loss: 0.6680319466:
Dev-Acc: 16: Accuracy: 0.7117399573: precision: 0.0881296882: recall: 0.4215269512: f1: 0.1457806527
Train-Acc: 16: Accuracy: 0.7868976593: precision: 0.5958828052: recall: 0.4586154756: f1: 0.5183148822
17: 3232: loss: 0.6676599145:
17: 6432: loss: 0.6667575899:
17: 9632: loss: 0.6668739394:
17: 12832: loss: 0.6669762495:
17: 16032: loss: 0.6666898968:
17: 19232: loss: 0.6665691149:
17: 22432: loss: 0.6668807645:
17: 25632: loss: 0.6669324312:
17: 28832: loss: 0.6668465055:
17: 32032: loss: 0.6667338215:
17: 35232: loss: 0.6666232395:
17: 38432: loss: 0.6664458921:
17: 41632: loss: 0.6663995242:
17: 44832: loss: 0.6663439993:
17: 48032: loss: 0.6662684854:
17: 51232: loss: 0.6662647010:
17: 54432: loss: 0.6661757202:
17: 57632: loss: 0.6661070646:
17: 60832: loss: 0.6660476288:
Dev-Acc: 17: Accuracy: 0.7326460481: precision: 0.0916879895: recall: 0.4021424928: f1: 0.1493291239
Train-Acc: 17: Accuracy: 0.7958056927: precision: 0.6309311284: recall: 0.4414568404: f1: 0.5194554034
18: 3232: loss: 0.6646908569:
18: 6432: loss: 0.6649811122:
18: 9632: loss: 0.6647329640:
18: 12832: loss: 0.6644530047:
18: 16032: loss: 0.6644536574:
18: 19232: loss: 0.6643984899:
18: 22432: loss: 0.6644129606:
18: 25632: loss: 0.6642023539:
18: 28832: loss: 0.6641274478:
18: 32032: loss: 0.6639981307:
18: 35232: loss: 0.6641142614:
18: 38432: loss: 0.6640019929:
18: 41632: loss: 0.6639934224:
18: 44832: loss: 0.6639778488:
18: 48032: loss: 0.6639844250:
18: 51232: loss: 0.6639474490:
18: 54432: loss: 0.6639266168:
18: 57632: loss: 0.6639005885:
18: 60832: loss: 0.6639025539:
Dev-Acc: 18: Accuracy: 0.7501587272: precision: 0.0950522473: recall: 0.3851385819: f1: 0.1524739145
Train-Acc: 18: Accuracy: 0.8022648692: precision: 0.6637824475: recall: 0.4236407863: f1: 0.5171957141
19: 3232: loss: 0.6624332279:
19: 6432: loss: 0.6629366311:
19: 9632: loss: 0.6629432543:
19: 12832: loss: 0.6625989969:
19: 16032: loss: 0.6625849172:
19: 19232: loss: 0.6624029872:
19: 22432: loss: 0.6621518878:
19: 25632: loss: 0.6621149123:
19: 28832: loss: 0.6621722469:
19: 32032: loss: 0.6621900174:
19: 35232: loss: 0.6621674487:
19: 38432: loss: 0.6621184772:
19: 41632: loss: 0.6621912359:
19: 44832: loss: 0.6621177308:
19: 48032: loss: 0.6620087586:
19: 51232: loss: 0.6619599450:
19: 54432: loss: 0.6620058264:
19: 57632: loss: 0.6619287507:
19: 60832: loss: 0.6619354897:
Dev-Acc: 19: Accuracy: 0.7677210569: precision: 0.0985663903: recall: 0.3659241626: f1: 0.1553005701
Train-Acc: 19: Accuracy: 0.8088883162: precision: 0.7011791129: recall: 0.4104924068: f1: 0.5178304860
20: 3232: loss: 0.6607773066:
20: 6432: loss: 0.6604406497:
20: 9632: loss: 0.6607307907:
20: 12832: loss: 0.6605311908:
20: 16032: loss: 0.6604640334:
20: 19232: loss: 0.6602419252:
20: 22432: loss: 0.6602273107:
20: 25632: loss: 0.6602848122:
20: 28832: loss: 0.6602766562:
20: 32032: loss: 0.6603435188:
20: 35232: loss: 0.6604055412:
20: 38432: loss: 0.6604314504:
20: 41632: loss: 0.6604371631:
20: 44832: loss: 0.6602776199:
20: 48032: loss: 0.6602522936:
20: 51232: loss: 0.6601864552:
20: 54432: loss: 0.6601708487:
20: 57632: loss: 0.6601859797:
20: 60832: loss: 0.6600680687:
Dev-Acc: 20: Accuracy: 0.7835072875: precision: 0.1037294878: recall: 0.3547015814: f1: 0.1605171021
Train-Acc: 20: Accuracy: 0.8136382103: precision: 0.7362704418: recall: 0.3966208665: f1: 0.5155308695
