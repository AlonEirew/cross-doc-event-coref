1: 6464: loss: 0.7081020194:
1: 12864: loss: 0.7071998858:
1: 19264: loss: 0.7068931603:
1: 25664: loss: 0.7069462077:
1: 32064: loss: 0.7067312253:
1: 38464: loss: 0.7066769271:
1: 44864: loss: 0.7066004646:
1: 51264: loss: 0.7065774199:
1: 57664: loss: 0.7064023517:
1: 64064: loss: 0.7063392209:
1: 70464: loss: 0.7063289238:
1: 76864: loss: 0.7063480062:
1: 83264: loss: 0.7063301376:
1: 89664: loss: 0.7062207773:
1: 96064: loss: 0.7061261095:
1: 102464: loss: 0.7059704999:
Dev-Acc: 1: Accuracy: 0.2875853181: precision: 0.0637103713: recall: 0.8183982316: f1: 0.1182177683
Train-Acc: 1: Accuracy: 0.3537759483: precision: 0.1588915902: recall: 0.8206561041: f1: 0.2662358436
2: 6464: loss: 0.7041723269:
2: 12864: loss: 0.7042641014:
2: 19264: loss: 0.7041415322:
2: 25664: loss: 0.7038687874:
2: 32064: loss: 0.7036579869:
2: 38464: loss: 0.7035873443:
2: 44864: loss: 0.7034793565:
2: 51264: loss: 0.7033768971:
2: 57664: loss: 0.7033102006:
2: 64064: loss: 0.7032610295:
2: 70464: loss: 0.7031858315:
2: 76864: loss: 0.7031297612:
2: 83264: loss: 0.7030790160:
2: 89664: loss: 0.7028846909:
2: 96064: loss: 0.7027516921:
2: 102464: loss: 0.7027461526:
Dev-Acc: 2: Accuracy: 0.3240494430: precision: 0.0648246546: recall: 0.7883013093: f1: 0.1197979250
Train-Acc: 2: Accuracy: 0.3874076009: precision: 0.1620175154: recall: 0.7881138650: f1: 0.2687801980
3: 6464: loss: 0.7012475818:
3: 12864: loss: 0.7012124297:
3: 19264: loss: 0.7011183161:
3: 25664: loss: 0.7011242510:
3: 32064: loss: 0.7011161804:
3: 38464: loss: 0.7008927703:
3: 44864: loss: 0.7008312705:
3: 51264: loss: 0.7006552181:
3: 57664: loss: 0.7004767036:
3: 64064: loss: 0.7003624276:
3: 70464: loss: 0.7002840946:
3: 76864: loss: 0.7001614993:
3: 83264: loss: 0.7001070776:
3: 89664: loss: 0.7000610504:
3: 96064: loss: 0.7000707649:
3: 102464: loss: 0.7000177463:
Dev-Acc: 3: Accuracy: 0.3672606647: precision: 0.0658737420: recall: 0.7468117667: f1: 0.1210684456
Train-Acc: 3: Accuracy: 0.4235562682: precision: 0.1656067564: recall: 0.7515613701: f1: 0.2714085611
4: 6464: loss: 0.6985829234:
4: 12864: loss: 0.6984391770:
4: 19264: loss: 0.6983499042:
4: 25664: loss: 0.6981520276:
4: 32064: loss: 0.6981451783:
4: 38464: loss: 0.6980998497:
4: 44864: loss: 0.6979896659:
4: 51264: loss: 0.6978205173:
4: 57664: loss: 0.6977412934:
4: 64064: loss: 0.6975775550:
4: 70464: loss: 0.6975196938:
4: 76864: loss: 0.6974483498:
4: 83264: loss: 0.6974141474:
4: 89664: loss: 0.6973427274:
4: 96064: loss: 0.6972337049:
4: 102464: loss: 0.6971423108:
Dev-Acc: 4: Accuracy: 0.4110077024: precision: 0.0662470802: recall: 0.6944397211: f1: 0.1209554414
Train-Acc: 4: Accuracy: 0.4600712061: precision: 0.1685195929: recall: 0.7065281704: f1: 0.2721310645
5: 6464: loss: 0.6963271153:
5: 12864: loss: 0.6954315987:
5: 19264: loss: 0.6958087405:
5: 25664: loss: 0.6953644586:
5: 32064: loss: 0.6953421090:
5: 38464: loss: 0.6952301673:
5: 44864: loss: 0.6948951002:
5: 51264: loss: 0.6947174548:
5: 57664: loss: 0.6946275906:
5: 64064: loss: 0.6946424234:
5: 70464: loss: 0.6945181971:
5: 76864: loss: 0.6943684196:
5: 83264: loss: 0.6942651690:
5: 89664: loss: 0.6941606499:
5: 96064: loss: 0.6940960567:
5: 102464: loss: 0.6940268950:
Dev-Acc: 5: Accuracy: 0.4562430382: precision: 0.0657256991: recall: 0.6294847815: f1: 0.1190238884
Train-Acc: 5: Accuracy: 0.4999295771: precision: 0.1720611819: recall: 0.6559726514: f1: 0.2726155023
6: 6464: loss: 0.6931437063:
6: 12864: loss: 0.6930258581:
6: 19264: loss: 0.6924322917:
6: 25664: loss: 0.6922406843:
6: 32064: loss: 0.6921948483:
6: 38464: loss: 0.6921700301:
6: 44864: loss: 0.6920741120:
6: 51264: loss: 0.6920105480:
6: 57664: loss: 0.6919025911:
6: 64064: loss: 0.6917923840:
6: 70464: loss: 0.6917195064:
6: 76864: loss: 0.6917014704:
6: 83264: loss: 0.6915600149:
6: 89664: loss: 0.6914712273:
6: 96064: loss: 0.6914148550:
6: 102464: loss: 0.6912867609:
Dev-Acc: 6: Accuracy: 0.5020142198: precision: 0.0645148608: recall: 0.5580683557: f1: 0.1156590841
Train-Acc: 6: Accuracy: 0.5402762890: precision: 0.1747295760: recall: 0.5957530734: f1: 0.2702090229
7: 6464: loss: 0.6904210764:
7: 12864: loss: 0.6901846233:
7: 19264: loss: 0.6901745739:
7: 25664: loss: 0.6900988647:
7: 32064: loss: 0.6898007729:
7: 38464: loss: 0.6896873128:
7: 44864: loss: 0.6895284681:
7: 51264: loss: 0.6894354594:
7: 57664: loss: 0.6892917006:
7: 64064: loss: 0.6891354638:
7: 70464: loss: 0.6890710688:
7: 76864: loss: 0.6889764377:
7: 83264: loss: 0.6888797442:
7: 89664: loss: 0.6888040380:
7: 96064: loss: 0.6887171956:
7: 102464: loss: 0.6886142716:
Dev-Acc: 7: Accuracy: 0.5492538214: precision: 0.0640089961: recall: 0.4936235334: f1: 0.1133231838
Train-Acc: 7: Accuracy: 0.5805197358: precision: 0.1797503588: recall: 0.5434225232: f1: 0.2701439613
8: 6464: loss: 0.6866401291:
8: 12864: loss: 0.6861250752:
8: 19264: loss: 0.6862642451:
8: 25664: loss: 0.6863531737:
8: 32064: loss: 0.6863745816:
8: 38464: loss: 0.6861296913:
8: 44864: loss: 0.6860688915:
8: 51264: loss: 0.6860956913:
8: 57664: loss: 0.6860696319:
8: 64064: loss: 0.6860603417:
8: 70464: loss: 0.6859295804:
8: 76864: loss: 0.6859006186:
8: 83264: loss: 0.6858274419:
8: 89664: loss: 0.6857599144:
8: 96064: loss: 0.6856313904:
8: 102464: loss: 0.6855511605:
Dev-Acc: 8: Accuracy: 0.5945388079: precision: 0.0641616625: recall: 0.4378507057: f1: 0.1119224584
Train-Acc: 8: Accuracy: 0.6184434295: precision: 0.1865936668: recall: 0.4974031951: f1: 0.2713821984
9: 6464: loss: 0.6839305282:
9: 12864: loss: 0.6839298266:
9: 19264: loss: 0.6838055201:
9: 25664: loss: 0.6836602342:
9: 32064: loss: 0.6835534999:
9: 38464: loss: 0.6836042936:
9: 44864: loss: 0.6835820222:
9: 51264: loss: 0.6834147426:
9: 57664: loss: 0.6833782447:
9: 64064: loss: 0.6832686768:
9: 70464: loss: 0.6832057856:
9: 76864: loss: 0.6831522032:
9: 83264: loss: 0.6831298692:
9: 89664: loss: 0.6830716684:
9: 96064: loss: 0.6830162579:
9: 102464: loss: 0.6829282777:
Dev-Acc: 9: Accuracy: 0.6364998221: precision: 0.0659157633: recall: 0.3970413195: f1: 0.1130613727
Train-Acc: 9: Accuracy: 0.6554561257: precision: 0.1963462572: recall: 0.4564459930: f1: 0.2745788183
10: 6464: loss: 0.6817622721:
10: 12864: loss: 0.6814547369:
10: 19264: loss: 0.6812400744:
10: 25664: loss: 0.6811603419:
10: 32064: loss: 0.6813704929:
10: 38464: loss: 0.6810829910:
10: 44864: loss: 0.6808320609:
10: 51264: loss: 0.6807470992:
10: 57664: loss: 0.6806528523:
10: 64064: loss: 0.6805616072:
10: 70464: loss: 0.6805283038:
10: 76864: loss: 0.6804297485:
10: 83264: loss: 0.6803601815:
10: 89664: loss: 0.6802711249:
10: 96064: loss: 0.6801977605:
10: 102464: loss: 0.6800693649:
Dev-Acc: 10: Accuracy: 0.6759207845: precision: 0.0673645440: recall: 0.3545315423: f1: 0.1132167680
Train-Acc: 10: Accuracy: 0.6881486177: precision: 0.2064791857: recall: 0.4160804681: f1: 0.2759959008
11: 6464: loss: 0.6776647598:
11: 12864: loss: 0.6782495162:
11: 19264: loss: 0.6781347491:
11: 25664: loss: 0.6781677260:
11: 32064: loss: 0.6781043839:
11: 38464: loss: 0.6780282058:
11: 44864: loss: 0.6778542426:
11: 51264: loss: 0.6778194817:
11: 57664: loss: 0.6778314529:
11: 64064: loss: 0.6777302784:
11: 70464: loss: 0.6776966396:
11: 76864: loss: 0.6776067131:
11: 83264: loss: 0.6775103675:
11: 89664: loss: 0.6773829633:
11: 96064: loss: 0.6773357172:
11: 102464: loss: 0.6772631657:
Dev-Acc: 11: Accuracy: 0.7125734091: precision: 0.0695133321: recall: 0.3169528992: f1: 0.1140200636
Train-Acc: 11: Accuracy: 0.7176197767: precision: 0.2179526124: recall: 0.3773584906: f1: 0.2763135726
12: 6464: loss: 0.6738619357:
12: 12864: loss: 0.6747185493:
12: 19264: loss: 0.6747629704:
12: 25664: loss: 0.6747970971:
12: 32064: loss: 0.6750540200:
12: 38464: loss: 0.6750813622:
12: 44864: loss: 0.6750342688:
12: 51264: loss: 0.6750912235:
12: 57664: loss: 0.6750365556:
12: 64064: loss: 0.6750038552:
12: 70464: loss: 0.6748882915:
12: 76864: loss: 0.6747965130:
12: 83264: loss: 0.6747300500:
12: 89664: loss: 0.6746552735:
12: 96064: loss: 0.6745326218:
12: 102464: loss: 0.6745151753:
Dev-Acc: 12: Accuracy: 0.7458326817: precision: 0.0721130914: recall: 0.2827750383: f1: 0.1149194942
Train-Acc: 12: Accuracy: 0.7452689409: precision: 0.2336076572: recall: 0.3433699297: f1: 0.2780483910
13: 6464: loss: 0.6729745036:
13: 12864: loss: 0.6729201347:
13: 19264: loss: 0.6729690746:
13: 25664: loss: 0.6726684456:
13: 32064: loss: 0.6726918151:
13: 38464: loss: 0.6726326042:
13: 44864: loss: 0.6726267862:
13: 51264: loss: 0.6725003047:
13: 57664: loss: 0.6723463270:
13: 64064: loss: 0.6723838885:
13: 70464: loss: 0.6723370917:
13: 76864: loss: 0.6722560459:
13: 83264: loss: 0.6722302901:
13: 89664: loss: 0.6721101197:
13: 96064: loss: 0.6720345343:
13: 102464: loss: 0.6719528759:
Dev-Acc: 13: Accuracy: 0.7732378244: precision: 0.0730062893: recall: 0.2467267472: f1: 0.1126727753
Train-Acc: 13: Accuracy: 0.7681283355: precision: 0.2491530807: recall: 0.3094471106: f1: 0.2760460957
14: 6464: loss: 0.6705421573:
14: 12864: loss: 0.6709998181:
14: 19264: loss: 0.6704215185:
14: 25664: loss: 0.6703719428:
14: 32064: loss: 0.6701671629:
14: 38464: loss: 0.6699617836:
14: 44864: loss: 0.6698555815:
14: 51264: loss: 0.6697527298:
14: 57664: loss: 0.6696440299:
14: 64064: loss: 0.6696357496:
14: 70464: loss: 0.6696118155:
14: 76864: loss: 0.6694836477:
14: 83264: loss: 0.6693747720:
14: 89664: loss: 0.6692807865:
14: 96064: loss: 0.6691271198:
14: 102464: loss: 0.6690445813:
Dev-Acc: 14: Accuracy: 0.7965450883: precision: 0.0756239118: recall: 0.2215609590: f1: 0.1127601575
Train-Acc: 14: Accuracy: 0.7868177891: precision: 0.2662921348: recall: 0.2804549339: f1: 0.2731900996
15: 6464: loss: 0.6674785984:
15: 12864: loss: 0.6679716590:
15: 19264: loss: 0.6673798623:
15: 25664: loss: 0.6672411756:
15: 32064: loss: 0.6672188207:
15: 38464: loss: 0.6671865816:
15: 44864: loss: 0.6670438183:
15: 51264: loss: 0.6668342613:
15: 57664: loss: 0.6667794362:
15: 64064: loss: 0.6667790295:
15: 70464: loss: 0.6666696123:
15: 76864: loss: 0.6665776386:
15: 83264: loss: 0.6664840379:
15: 89664: loss: 0.6663782287:
15: 96064: loss: 0.6663351747:
15: 102464: loss: 0.6663346588:
Dev-Acc: 15: Accuracy: 0.8171435595: precision: 0.0781901304: recall: 0.1977554838: f1: 0.1120693809
Train-Acc: 15: Accuracy: 0.8032814860: precision: 0.2873247794: recall: 0.2546841102: f1: 0.2700216073
16: 6464: loss: 0.6649082857:
16: 12864: loss: 0.6649099758:
16: 19264: loss: 0.6648513007:
16: 25664: loss: 0.6647489797:
16: 32064: loss: 0.6646533462:
16: 38464: loss: 0.6645345978:
16: 44864: loss: 0.6643784126:
16: 51264: loss: 0.6641047657:
16: 57664: loss: 0.6640270767:
16: 64064: loss: 0.6640312840:
16: 70464: loss: 0.6640225137:
16: 76864: loss: 0.6639399024:
16: 83264: loss: 0.6639124410:
16: 89664: loss: 0.6638163365:
16: 96064: loss: 0.6637624812:
16: 102464: loss: 0.6637292766:
Dev-Acc: 16: Accuracy: 0.8370177746: precision: 0.0825746180: recall: 0.1773507907: f1: 0.1126836646
Train-Acc: 16: Accuracy: 0.8154718876: precision: 0.3051383399: recall: 0.2283873513: f1: 0.2612422921
17: 6464: loss: 0.6616526133:
17: 12864: loss: 0.6615059659:
17: 19264: loss: 0.6616113849:
17: 25664: loss: 0.6617103481:
17: 32064: loss: 0.6619153502:
17: 38464: loss: 0.6616411256:
17: 44864: loss: 0.6616178140:
17: 51264: loss: 0.6615200726:
17: 57664: loss: 0.6614339992:
17: 64064: loss: 0.6614314049:
17: 70464: loss: 0.6613335862:
17: 76864: loss: 0.6613137789:
17: 83264: loss: 0.6612236563:
17: 89664: loss: 0.6611476087:
17: 96064: loss: 0.6611135060:
17: 102464: loss: 0.6609907119:
Dev-Acc: 17: Accuracy: 0.8546594381: precision: 0.0883651047: recall: 0.1600068016: f1: 0.1138535995
Train-Acc: 17: Accuracy: 0.8254552484: precision: 0.3237936077: recall: 0.2037998817: f1: 0.2501513012
18: 6464: loss: 0.6599831951:
18: 12864: loss: 0.6595013550:
18: 19264: loss: 0.6592168297:
18: 25664: loss: 0.6587773001:
18: 32064: loss: 0.6586355296:
18: 38464: loss: 0.6586881478:
18: 44864: loss: 0.6587906809:
18: 51264: loss: 0.6587020084:
18: 57664: loss: 0.6586824624:
18: 64064: loss: 0.6585784659:
18: 70464: loss: 0.6584680368:
18: 76864: loss: 0.6583995837:
18: 83264: loss: 0.6583900699:
18: 89664: loss: 0.6583077300:
18: 96064: loss: 0.6582829084:
18: 102464: loss: 0.6582570617:
Dev-Acc: 18: Accuracy: 0.8694137931: precision: 0.0935685574: recall: 0.1424927733: f1: 0.1129608411
Train-Acc: 18: Accuracy: 0.8344337344: precision: 0.3494020927: recall: 0.1844060220: f1: 0.2414045355
19: 6464: loss: 0.6567877507:
19: 12864: loss: 0.6564474553:
19: 19264: loss: 0.6561197970:
19: 25664: loss: 0.6563489091:
19: 32064: loss: 0.6564688257:
19: 38464: loss: 0.6565198336:
19: 44864: loss: 0.6563883255:
19: 51264: loss: 0.6562746955:
19: 57664: loss: 0.6561242400:
19: 64064: loss: 0.6560438350:
19: 70464: loss: 0.6559758438:
19: 76864: loss: 0.6559130841:
19: 83264: loss: 0.6558893989:
19: 89664: loss: 0.6558391914:
19: 96064: loss: 0.6557892123:
19: 102464: loss: 0.6556680962:
Dev-Acc: 19: Accuracy: 0.8822134137: precision: 0.0993846977: recall: 0.1263390580: f1: 0.1112525268
Train-Acc: 19: Accuracy: 0.8412145376: precision: 0.3722506779: recall: 0.1624482283: f1: 0.2261888416
20: 6464: loss: 0.6538782811:
20: 12864: loss: 0.6538421893:
20: 19264: loss: 0.6538464985:
20: 25664: loss: 0.6541543302:
20: 32064: loss: 0.6539539053:
20: 38464: loss: 0.6539367777:
20: 44864: loss: 0.6537839980:
20: 51264: loss: 0.6536850227:
20: 57664: loss: 0.6535947394:
20: 64064: loss: 0.6536028994:
20: 70464: loss: 0.6535381840:
20: 76864: loss: 0.6534172841:
20: 83264: loss: 0.6532889235:
20: 89664: loss: 0.6531565496:
20: 96064: loss: 0.6530820624:
20: 102464: loss: 0.6530230637:
Dev-Acc: 20: Accuracy: 0.8933560848: precision: 0.1081951377: recall: 0.1142662812: f1: 0.1111478664
Train-Acc: 20: Accuracy: 0.8471313119: precision: 0.4031261360: recall: 0.1458155282: f1: 0.2141650171
