1: 6464: loss: 0.6882739544:
1: 12864: loss: 0.6880579573:
1: 19264: loss: 0.6880145288:
1: 25664: loss: 0.6878768784:
Dev-Acc: 1: Accuracy: 0.2531354129: precision: 0.0629464005: recall: 0.8496854276: f1: 0.1172096733
Train-Acc: 1: Accuracy: 0.5489448905: precision: 0.5302802294: recall: 0.8571428571: f1: 0.6552088045
2: 6464: loss: 0.6870893717:
2: 12864: loss: 0.6873049706:
2: 19264: loss: 0.6871852018:
2: 25664: loss: 0.6870756891:
Dev-Acc: 2: Accuracy: 0.2521332800: precision: 0.0631961381: recall: 0.8547866009: f1: 0.1176911281
Train-Acc: 2: Accuracy: 0.5535139441: precision: 0.5329901921: recall: 0.8645716915: f1: 0.6594459070
3: 6464: loss: 0.6869032294:
3: 12864: loss: 0.6865453583:
3: 19264: loss: 0.6861720175:
3: 25664: loss: 0.6861275023:
Dev-Acc: 3: Accuracy: 0.2510120571: precision: 0.0633586350: recall: 0.8586975004: f1: 0.1180099549
Train-Acc: 3: Accuracy: 0.5568339229: precision: 0.5349929164: recall: 0.8689106568: f1: 0.6622407055
4: 6464: loss: 0.6864585578:
4: 12864: loss: 0.6864523119:
4: 19264: loss: 0.6863032476:
4: 25664: loss: 0.6859311642:
Dev-Acc: 4: Accuracy: 0.2498015463: precision: 0.0637973100: recall: 0.8670294168: f1: 0.1188494977
Train-Acc: 4: Accuracy: 0.5594964623: precision: 0.5365893103: recall: 0.8725264611: f1: 0.6645137063
5: 6464: loss: 0.6854790407:
5: 12864: loss: 0.6850801709:
5: 19264: loss: 0.6856122528:
5: 25664: loss: 0.6857138661:
Dev-Acc: 5: Accuracy: 0.2490375489: precision: 0.0640519610: recall: 0.8719605509: f1: 0.1193376852
Train-Acc: 5: Accuracy: 0.5634080768: precision: 0.5389115262: recall: 0.8781802643: f1: 0.6679333967
6: 6464: loss: 0.6852564120:
6: 12864: loss: 0.6855466679:
6: 19264: loss: 0.6853523274:
6: 25664: loss: 0.6852363724:
Dev-Acc: 6: Accuracy: 0.2482140064: precision: 0.0642683459: recall: 0.8763815678: f1: 0.1197546354
Train-Acc: 6: Accuracy: 0.5665308237: precision: 0.5407669997: recall: 0.8825192295: f1: 0.6706132134
7: 6464: loss: 0.6854673630:
7: 12864: loss: 0.6847402734:
7: 19264: loss: 0.6845973132:
7: 25664: loss: 0.6846848007:
Dev-Acc: 7: Accuracy: 0.2469141930: precision: 0.0643370915: recall: 0.8791021935: f1: 0.1198993495
Train-Acc: 7: Accuracy: 0.5696206689: precision: 0.5426054071: recall: 0.8866609690: f1: 0.6732223526
8: 6464: loss: 0.6828162140:
8: 12864: loss: 0.6836124444:
8: 19264: loss: 0.6841279056:
8: 25664: loss: 0.6841229524:
Dev-Acc: 8: Accuracy: 0.2459616512: precision: 0.0644335661: recall: 0.8818228192: f1: 0.1200921648
Train-Acc: 8: Accuracy: 0.5715271831: precision: 0.5437369352: recall: 0.8892249030: f1: 0.6748322399
9: 6464: loss: 0.6846019173:
9: 12864: loss: 0.6838952500:
9: 19264: loss: 0.6835456065:
9: 25664: loss: 0.6837781557:
Dev-Acc: 9: Accuracy: 0.2451480329: precision: 0.0645841604: recall: 0.8852236014: f1: 0.1203852513
Train-Acc: 9: Accuracy: 0.5735980868: precision: 0.5449652569: recall: 0.8919860627: f1: 0.6765732522
10: 6464: loss: 0.6843559748:
10: 12864: loss: 0.6837264976:
10: 19264: loss: 0.6835877671:
10: 25664: loss: 0.6836181478:
Dev-Acc: 10: Accuracy: 0.2444435656: precision: 0.0646244594: recall: 0.8867539534: f1: 0.1204694033
Train-Acc: 10: Accuracy: 0.5761620402: precision: 0.5465279730: recall: 0.8946157386: f1: 0.6785340314
11: 6464: loss: 0.6834975719:
11: 12864: loss: 0.6828422758:
11: 19264: loss: 0.6827997273:
11: 25664: loss: 0.6827117972:
Dev-Acc: 11: Accuracy: 0.2432429790: precision: 0.0646677552: recall: 0.8889644618: f1: 0.1205650043
Train-Acc: 11: Accuracy: 0.5784958601: precision: 0.5479672184: recall: 0.8967194793: f1: 0.6802483605
12: 6464: loss: 0.6830476499:
12: 12864: loss: 0.6822834608:
12: 19264: loss: 0.6823450559:
12: 25664: loss: 0.6823730733:
Dev-Acc: 12: Accuracy: 0.2422705889: precision: 0.0646862648: recall: 0.8904948138: f1: 0.1206112320
Train-Acc: 12: Accuracy: 0.5814542174: precision: 0.5497670308: recall: 0.8998093485: f1: 0.6825242476
13: 6464: loss: 0.6820213437:
13: 12864: loss: 0.6822628385:
13: 19264: loss: 0.6821591657:
13: 25664: loss: 0.6819487436:
Dev-Acc: 13: Accuracy: 0.2415561974: precision: 0.0647469588: recall: 0.8923652440: f1: 0.1207338816
Train-Acc: 13: Accuracy: 0.5835579634: precision: 0.5510605817: recall: 0.9017816054: f1: 0.6840884722
14: 6464: loss: 0.6812338042:
14: 12864: loss: 0.6819754764:
14: 19264: loss: 0.6821125021:
14: 25664: loss: 0.6816578946:
Dev-Acc: 14: Accuracy: 0.2403357625: precision: 0.0647560870: recall: 0.8940656351: f1: 0.1207652909
Train-Acc: 14: Accuracy: 0.5856946111: precision: 0.5523220808: recall: 0.9046085070: f1: 0.6858737912
15: 6464: loss: 0.6807335544:
15: 12864: loss: 0.6811467764:
15: 19264: loss: 0.6811388763:
15: 25664: loss: 0.6810938682:
Dev-Acc: 15: Accuracy: 0.2397007495: precision: 0.0649192507: recall: 0.8974664173: f1: 0.1210800395
Train-Acc: 15: Accuracy: 0.5871737599: precision: 0.5532230874: recall: 0.9061205706: f1: 0.6870031153
16: 6464: loss: 0.6816451764:
16: 12864: loss: 0.6808053687:
16: 19264: loss: 0.6805088711:
16: 25664: loss: 0.6806998321:
Dev-Acc: 16: Accuracy: 0.2389367372: precision: 0.0649112891: recall: 0.8983166128: f1: 0.1210739209
Train-Acc: 16: Accuracy: 0.5894089937: precision: 0.5546579857: recall: 0.9073039248: f1: 0.6884493552
17: 6464: loss: 0.6803923142:
17: 12864: loss: 0.6802941766:
17: 19264: loss: 0.6804852843:
17: 25664: loss: 0.6802643709:
Dev-Acc: 17: Accuracy: 0.2379544377: precision: 0.0648751457: recall: 0.8989967693: f1: 0.1210172130
Train-Acc: 17: Accuracy: 0.5915784836: precision: 0.5560022513: recall: 0.9092104398: f1: 0.6900336784
18: 6464: loss: 0.6813094181:
18: 12864: loss: 0.6798016486:
18: 19264: loss: 0.6795857380:
18: 25664: loss: 0.6795864543:
Dev-Acc: 18: Accuracy: 0.2371606529: precision: 0.0649288577: recall: 0.9008671995: f1: 0.1211275978
Train-Acc: 18: Accuracy: 0.5933206677: precision: 0.5570928689: recall: 0.9105910197: f1: 0.6912711484
19: 6464: loss: 0.6790199393:
19: 12864: loss: 0.6794894442:
19: 19264: loss: 0.6792456893:
19: 25664: loss: 0.6794075042:
Dev-Acc: 19: Accuracy: 0.2365157157: precision: 0.0649943685: recall: 0.9027376297: f1: 0.1212584937
Train-Acc: 19: Accuracy: 0.5954244137: precision: 0.5583893157: recall: 0.9125632766: f1: 0.6928375343
20: 6464: loss: 0.6791063207:
20: 12864: loss: 0.6792558622:
20: 19264: loss: 0.6792063010:
20: 25664: loss: 0.6791039458:
Dev-Acc: 20: Accuracy: 0.2356822491: precision: 0.0650127164: recall: 0.9040979425: f1: 0.1213026864
Train-Acc: 20: Accuracy: 0.5975939035: precision: 0.5597456433: recall: 0.9143383078: f1: 0.6943931300
