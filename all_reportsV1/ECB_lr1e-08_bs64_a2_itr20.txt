1: 6464: loss: 0.6965257972:
1: 12864: loss: 0.6962349936:
1: 19264: loss: 0.6961640871:
1: 25664: loss: 0.6962596066:
1: 32064: loss: 0.6959437263:
1: 38464: loss: 0.6959494215:
1: 44864: loss: 0.6958481618:
Dev-Acc: 1: Accuracy: 0.2615097463: precision: 0.0631556139: recall: 0.8425437851: f1: 0.1175033793
Train-Acc: 1: Accuracy: 0.4554160237: precision: 0.3641258386: recall: 0.8491880876: f1: 0.5096971491
2: 6464: loss: 0.6952988476:
2: 12864: loss: 0.6955479854:
2: 19264: loss: 0.6952350148:
2: 25664: loss: 0.6950750951:
2: 32064: loss: 0.6949113355:
2: 38464: loss: 0.6949136390:
2: 44864: loss: 0.6949076594:
Dev-Acc: 2: Accuracy: 0.2685049176: precision: 0.0635037060: recall: 0.8391430029: f1: 0.1180720874
Train-Acc: 2: Accuracy: 0.4622751176: precision: 0.3670723712: recall: 0.8466241536: f1: 0.5121088003
3: 6464: loss: 0.6944885379:
3: 12864: loss: 0.6946468577:
3: 19264: loss: 0.6945521555:
3: 25664: loss: 0.6944985132:
3: 32064: loss: 0.6946387590:
3: 38464: loss: 0.6944069376:
3: 44864: loss: 0.6943806053:
Dev-Acc: 3: Accuracy: 0.2760061026: precision: 0.0640029116: recall: 0.8372725727: f1: 0.1189156554
Train-Acc: 3: Accuracy: 0.4693533182: precision: 0.3703341014: recall: 0.8453093156: f1: 0.5150307424
4: 6464: loss: 0.6939779025:
4: 12864: loss: 0.6937891623:
4: 19264: loss: 0.6934711466:
4: 25664: loss: 0.6932165998:
4: 32064: loss: 0.6932732004:
4: 38464: loss: 0.6933651421:
4: 44864: loss: 0.6934987161:
Dev-Acc: 4: Accuracy: 0.2837355137: precision: 0.0644059334: recall: 0.8335317123: f1: 0.1195726412
Train-Acc: 4: Accuracy: 0.4777682722: precision: 0.3743806470: recall: 0.8444546710: f1: 0.5187698148
5: 6464: loss: 0.6921691519:
5: 12864: loss: 0.6925304353:
5: 19264: loss: 0.6930198067:
5: 25664: loss: 0.6928890118:
5: 32064: loss: 0.6927699114:
5: 38464: loss: 0.6925516742:
5: 44864: loss: 0.6925402344:
Dev-Acc: 5: Accuracy: 0.2909291089: precision: 0.0647944151: recall: 0.8301309301: f1: 0.1202063353
Train-Acc: 5: Accuracy: 0.4856573045: precision: 0.3779334397: recall: 0.8406416409: f1: 0.5214394943
6: 6464: loss: 0.6922462946:
6: 12864: loss: 0.6922322354:
6: 19264: loss: 0.6919775999:
6: 25664: loss: 0.6919107300:
6: 32064: loss: 0.6918956200:
6: 38464: loss: 0.6917579113:
6: 44864: loss: 0.6919141752:
Dev-Acc: 6: Accuracy: 0.2993232906: precision: 0.0651916929: recall: 0.8251997960: f1: 0.1208371201
Train-Acc: 6: Accuracy: 0.4950364828: precision: 0.3825223496: recall: 0.8382749326: f1: 0.5253270162
7: 6464: loss: 0.6914094102:
7: 12864: loss: 0.6916160566:
7: 19264: loss: 0.6915772541:
7: 25664: loss: 0.6912945671:
7: 32064: loss: 0.6911585683:
7: 38464: loss: 0.6911032117:
7: 44864: loss: 0.6910842769:
Dev-Acc: 7: Accuracy: 0.3071618378: precision: 0.0657494431: recall: 0.8231593266: f1: 0.1217723780
Train-Acc: 7: Accuracy: 0.5026625395: precision: 0.3862198978: recall: 0.8350535796: f1: 0.5281606686
8: 6464: loss: 0.6918141061:
8: 12864: loss: 0.6914501959:
8: 19264: loss: 0.6914288334:
8: 25664: loss: 0.6911242934:
8: 32064: loss: 0.6907738578:
8: 38464: loss: 0.6906331354:
8: 44864: loss: 0.6907212870:
Dev-Acc: 8: Accuracy: 0.3152385354: precision: 0.0659479677: recall: 0.8155075667: f1: 0.1220278608
Train-Acc: 8: Accuracy: 0.5116910934: precision: 0.3907360485: recall: 0.8313062915: f1: 0.5316040611
9: 6464: loss: 0.6902189416:
9: 12864: loss: 0.6899276206:
9: 19264: loss: 0.6899513364:
9: 25664: loss: 0.6899566817:
9: 32064: loss: 0.6899001012:
9: 38464: loss: 0.6897258103:
9: 44864: loss: 0.6896219861:
Dev-Acc: 9: Accuracy: 0.3227893412: precision: 0.0662596142: recall: 0.8100663153: f1: 0.1224993572
Train-Acc: 9: Accuracy: 0.5211579204: precision: 0.3957613815: recall: 0.8286766156: f1: 0.5356877244
10: 6464: loss: 0.6909460759:
10: 12864: loss: 0.6901728460:
10: 19264: loss: 0.6895360581:
10: 25664: loss: 0.6894675440:
10: 32064: loss: 0.6893140575:
10: 38464: loss: 0.6892755379:
10: 44864: loss: 0.6891490701:
Dev-Acc: 10: Accuracy: 0.3313720524: precision: 0.0667981406: recall: 0.8063254549: f1: 0.1233755252
Train-Acc: 10: Accuracy: 0.5301645994: precision: 0.4006253789: recall: 0.8254552626: f1: 0.5394397663
11: 6464: loss: 0.6895451021:
11: 12864: loss: 0.6887412307:
11: 19264: loss: 0.6883622690:
11: 25664: loss: 0.6879275870:
11: 32064: loss: 0.6879074699:
11: 38464: loss: 0.6879151230:
11: 44864: loss: 0.6878873764:
Dev-Acc: 11: Accuracy: 0.3395380080: precision: 0.0672856145: recall: 0.8022445162: f1: 0.1241578947
Train-Acc: 11: Accuracy: 0.5394341946: precision: 0.4058323602: recall: 0.8224968773: f1: 0.5434957319
12: 6464: loss: 0.6883445072:
12: 12864: loss: 0.6879987514:
12: 19264: loss: 0.6883180579:
12: 25664: loss: 0.6879435483:
12: 32064: loss: 0.6879271671:
12: 38464: loss: 0.6876528027:
12: 44864: loss: 0.6874100228:
Dev-Acc: 12: Accuracy: 0.3477635384: precision: 0.0676913298: recall: 0.7968032648: f1: 0.1247819777
Train-Acc: 12: Accuracy: 0.5497118235: precision: 0.4117647059: recall: 0.8186838472: f1: 0.5479385753
13: 6464: loss: 0.6872439247:
13: 12864: loss: 0.6867068806:
13: 19264: loss: 0.6865425114:
13: 25664: loss: 0.6865852739:
13: 32064: loss: 0.6866354886:
13: 38464: loss: 0.6865656221:
13: 44864: loss: 0.6865743406:
Dev-Acc: 13: Accuracy: 0.3565843701: precision: 0.0681548535: recall: 0.7911919742: f1: 0.1254989751
Train-Acc: 13: Accuracy: 0.5600333214: precision: 0.4178207120: recall: 0.8132272697: f1: 0.5520226700
14: 6464: loss: 0.6854369712:
14: 12864: loss: 0.6858495528:
14: 19264: loss: 0.6859274791:
14: 25664: loss: 0.6858094162:
14: 32064: loss: 0.6858200060:
14: 38464: loss: 0.6858979396:
14: 44864: loss: 0.6857922562:
Dev-Acc: 14: Accuracy: 0.3651869297: precision: 0.0688396117: recall: 0.7886413875: f1: 0.1266261689
Train-Acc: 14: Accuracy: 0.5714504719: precision: 0.4251197739: recall: 0.8108605614: f1: 0.5577966715
15: 6464: loss: 0.6852971607:
15: 12864: loss: 0.6859939963:
15: 19264: loss: 0.6858850255:
15: 25664: loss: 0.6858197682:
15: 32064: loss: 0.6854893107:
15: 38464: loss: 0.6852484597:
15: 44864: loss: 0.6850361582:
Dev-Acc: 15: Accuracy: 0.3743649721: precision: 0.0695387673: recall: 0.7852406053: f1: 0.1277631761
Train-Acc: 15: Accuracy: 0.5836565495: precision: 0.4330931186: recall: 0.8059956610: f1: 0.5634320642
16: 6464: loss: 0.6848508155:
16: 12864: loss: 0.6846575853:
16: 19264: loss: 0.6846338675:
16: 25664: loss: 0.6843036510:
16: 32064: loss: 0.6841881373:
16: 38464: loss: 0.6843205429:
16: 44864: loss: 0.6843353988:
Dev-Acc: 16: Accuracy: 0.3826400936: precision: 0.0700297642: recall: 0.7801394321: f1: 0.1285226063
Train-Acc: 16: Accuracy: 0.5953805447: precision: 0.4412073016: recall: 0.8024455986: f1: 0.5693628137
17: 6464: loss: 0.6833965737:
17: 12864: loss: 0.6832490912:
17: 19264: loss: 0.6833758010:
17: 25664: loss: 0.6832446790:
17: 32064: loss: 0.6833266536:
17: 38464: loss: 0.6833205141:
17: 44864: loss: 0.6833444541:
Dev-Acc: 17: Accuracy: 0.3914708495: precision: 0.0706354246: recall: 0.7755483761: f1: 0.1294782263
Train-Acc: 17: Accuracy: 0.6058992147: precision: 0.4487411734: recall: 0.7979751496: f1: 0.5744439186
18: 6464: loss: 0.6823108369:
18: 12864: loss: 0.6827212119:
18: 19264: loss: 0.6828794255:
18: 25664: loss: 0.6825402410:
18: 32064: loss: 0.6825554479:
18: 38464: loss: 0.6825278945:
18: 44864: loss: 0.6824427026:
Dev-Acc: 18: Accuracy: 0.3992399573: precision: 0.0709644001: recall: 0.7687468118: f1: 0.1299343287
Train-Acc: 18: Accuracy: 0.6170315146: precision: 0.4570843912: recall: 0.7929787654: f1: 0.5799038462
19: 6464: loss: 0.6832124060:
19: 12864: loss: 0.6825007999:
19: 19264: loss: 0.6820396505:
19: 25664: loss: 0.6820539688:
19: 32064: loss: 0.6820010630:
19: 38464: loss: 0.6820225077:
19: 44864: loss: 0.6819564862:
Dev-Acc: 19: Accuracy: 0.4075448513: precision: 0.0715138586: recall: 0.7638156776: f1: 0.1307828922
Train-Acc: 19: Accuracy: 0.6289308071: precision: 0.4665006614: recall: 0.7882453488: f1: 0.5861217706
20: 6464: loss: 0.6814335120:
20: 12864: loss: 0.6815650257:
20: 19264: loss: 0.6816734823:
20: 25664: loss: 0.6817456695:
20: 32064: loss: 0.6816524314:
20: 38464: loss: 0.6814798340:
20: 44864: loss: 0.6814319329:
Dev-Acc: 20: Accuracy: 0.4169907868: precision: 0.0721994790: recall: 0.7587145043: f1: 0.1318518956
Train-Acc: 20: Accuracy: 0.6411806941: precision: 0.4767520889: recall: 0.7839721254: f1: 0.5929295943
