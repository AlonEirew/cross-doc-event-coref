1: 3232: loss: 0.6860061896:
1: 6432: loss: 0.6869547144:
1: 9632: loss: 0.6868006078:
1: 12832: loss: 0.6869323391:
1: 16032: loss: 0.6871223704:
1: 19232: loss: 0.6870933205:
1: 22432: loss: 0.6870580325:
1: 25632: loss: 0.6869593140:
1: 28832: loss: 0.6870076278:
Dev-Acc: 1: Accuracy: 0.2524408698: precision: 0.0630449278: recall: 0.8520659752: f1: 0.1174031208
Train-Acc: 1: Accuracy: 0.5513772964: precision: 0.5317180080: recall: 0.8612845967: f1: 0.6575156838
2: 3232: loss: 0.6860306555:
2: 6432: loss: 0.6863652569:
2: 9632: loss: 0.6868012063:
2: 12832: loss: 0.6868702081:
2: 16032: loss: 0.6868899282:
2: 19232: loss: 0.6867616944:
2: 22432: loss: 0.6864655121:
2: 25632: loss: 0.6865583897:
2: 28832: loss: 0.6865298803:
Dev-Acc: 2: Accuracy: 0.2509822845: precision: 0.0634438814: recall: 0.8600578133: f1: 0.1181706676
Train-Acc: 2: Accuracy: 0.5571625829: precision: 0.5351924556: recall: 0.8693051081: f1: 0.6625081417
3: 3232: loss: 0.6872999841:
3: 6432: loss: 0.6870673090:
3: 9632: loss: 0.6869837578:
3: 12832: loss: 0.6866726990:
3: 16032: loss: 0.6863840090:
3: 19232: loss: 0.6862495737:
3: 22432: loss: 0.6863665610:
3: 25632: loss: 0.6863034169:
3: 28832: loss: 0.6862819129:
Dev-Acc: 3: Accuracy: 0.2491962910: precision: 0.0640211905: recall: 0.8712803945: f1: 0.1192779077
Train-Acc: 3: Accuracy: 0.5619288683: precision: 0.5380390890: recall: 0.8759450398: f1: 0.6666166354
4: 3232: loss: 0.6846301955:
4: 6432: loss: 0.6852485487:
4: 9632: loss: 0.6854242361:
4: 12832: loss: 0.6852874053:
4: 16032: loss: 0.6854036652:
4: 19232: loss: 0.6854472883:
4: 22432: loss: 0.6851652578:
4: 25632: loss: 0.6850872720:
4: 28832: loss: 0.6851577873:
Dev-Acc: 4: Accuracy: 0.2477575839: precision: 0.0642749442: recall: 0.8770617242: f1: 0.1197724370
Train-Acc: 4: Accuracy: 0.5677470565: precision: 0.5415005437: recall: 0.8839655512: f1: 0.6715948254
5: 3232: loss: 0.6829378819:
5: 6432: loss: 0.6840888354:
5: 9632: loss: 0.6841654152:
5: 12832: loss: 0.6836755560:
5: 16032: loss: 0.6838100315:
5: 19232: loss: 0.6840052439:
5: 22432: loss: 0.6841343253:
5: 25632: loss: 0.6843716243:
5: 28832: loss: 0.6842861954:
Dev-Acc: 5: Accuracy: 0.2460807264: precision: 0.0644323491: recall: 0.8816527801: f1: 0.1200884741
Train-Acc: 5: Accuracy: 0.5712642670: precision: 0.5435831457: recall: 0.8888304516: f1: 0.6746002046
6: 3232: loss: 0.6834539264:
6: 6432: loss: 0.6835382080:
6: 9632: loss: 0.6837782458:
6: 12832: loss: 0.6838373576:
6: 16032: loss: 0.6839029098:
6: 19232: loss: 0.6838563283:
6: 22432: loss: 0.6838577676:
6: 25632: loss: 0.6837121428:
6: 28832: loss: 0.6838057778:
Dev-Acc: 6: Accuracy: 0.2448503673: precision: 0.0646141256: recall: 0.8860737970: f1: 0.1204451687
Train-Acc: 6: Accuracy: 0.5747814178: precision: 0.5456845656: recall: 0.8932351588: f1: 0.6774869110
7: 3232: loss: 0.6844305986:
7: 6432: loss: 0.6837730443:
7: 9632: loss: 0.6838543473:
7: 12832: loss: 0.6836653313:
7: 16032: loss: 0.6836250263:
7: 19232: loss: 0.6834964992:
7: 22432: loss: 0.6834838670:
7: 25632: loss: 0.6835196875:
7: 28832: loss: 0.6832848699:
Dev-Acc: 7: Accuracy: 0.2432826608: precision: 0.0646924942: recall: 0.8893045400: f1: 0.1206111271
Train-Acc: 7: Accuracy: 0.5786273479: precision: 0.5480398458: recall: 0.8969824469: f1: 0.6803799835
8: 3232: loss: 0.6826018465:
8: 6432: loss: 0.6820899692:
8: 9632: loss: 0.6822305228:
8: 12832: loss: 0.6823925465:
8: 16032: loss: 0.6825157297:
8: 19232: loss: 0.6825401051:
8: 22432: loss: 0.6827381141:
8: 25632: loss: 0.6826087608:
8: 28832: loss: 0.6824079995:
Dev-Acc: 8: Accuracy: 0.2417447120: precision: 0.0647513976: recall: 0.8921952049: f1: 0.1207400419
Train-Acc: 8: Accuracy: 0.5829005837: precision: 0.5506588462: recall: 0.9011241864: f1: 0.6835897564
9: 3232: loss: 0.6826129270:
9: 6432: loss: 0.6826856527:
9: 9632: loss: 0.6819809109:
9: 12832: loss: 0.6820442350:
9: 16032: loss: 0.6815844287:
9: 19232: loss: 0.6815949332:
9: 22432: loss: 0.6815621677:
9: 25632: loss: 0.6818366458:
9: 28832: loss: 0.6818195764:
Dev-Acc: 9: Accuracy: 0.2399289608: precision: 0.0647448364: recall: 0.8944057133: f1: 0.1207488264
Train-Acc: 9: Accuracy: 0.5861876607: precision: 0.5526252408: recall: 0.9050687003: f1: 0.6862398126
10: 3232: loss: 0.6813209647:
10: 6432: loss: 0.6819329450:
10: 9632: loss: 0.6817194208:
10: 12832: loss: 0.6812353988:
10: 16032: loss: 0.6811123881:
10: 19232: loss: 0.6809080029:
10: 22432: loss: 0.6808456724:
10: 25632: loss: 0.6807518274:
10: 28832: loss: 0.6805635932:
Dev-Acc: 10: Accuracy: 0.2390458733: precision: 0.0649200634: recall: 0.8983166128: f1: 0.1210891838
Train-Acc: 10: Accuracy: 0.5891460180: precision: 0.5544709569: recall: 0.9074354086: f1: 0.6883430994
11: 3232: loss: 0.6807294828:
11: 6432: loss: 0.6814203674:
11: 9632: loss: 0.6809514628:
11: 12832: loss: 0.6803110978:
11: 16032: loss: 0.6801954926:
11: 19232: loss: 0.6801509850:
11: 22432: loss: 0.6799191615:
11: 25632: loss: 0.6799712983:
11: 28832: loss: 0.6800369910:
Dev-Acc: 11: Accuracy: 0.2376269996: precision: 0.0649022542: recall: 0.8998469648: f1: 0.1210720782
Train-Acc: 11: Accuracy: 0.5922359228: precision: 0.5564133494: recall: 0.9097363750: f1: 0.6905017340
12: 3232: loss: 0.6800582713:
12: 6432: loss: 0.6805109128:
12: 9632: loss: 0.6797342151:
12: 12832: loss: 0.6791990131:
12: 16032: loss: 0.6790217844:
12: 19232: loss: 0.6792262402:
12: 22432: loss: 0.6791323647:
12: 25632: loss: 0.6793633907:
12: 28832: loss: 0.6794616540:
Dev-Acc: 12: Accuracy: 0.2364958674: precision: 0.0649927772: recall: 0.9027376297: f1: 0.1212557242
Train-Acc: 12: Accuracy: 0.5951614380: precision: 0.5582096755: recall: 0.9125632766: f1: 0.6926992365
13: 3232: loss: 0.6780264413:
13: 6432: loss: 0.6788798219:
13: 9632: loss: 0.6791439464:
13: 12832: loss: 0.6788009229:
13: 16032: loss: 0.6787829838:
13: 19232: loss: 0.6789562396:
13: 22432: loss: 0.6789295741:
13: 25632: loss: 0.6788548801:
13: 28832: loss: 0.6788933286:
Dev-Acc: 13: Accuracy: 0.2351861447: precision: 0.0650155177: recall: 0.9047780990: f1: 0.1213136806
Train-Acc: 13: Accuracy: 0.5981855392: precision: 0.5600981852: recall: 0.9150614687: f1: 0.6948729469
14: 3232: loss: 0.6764370108:
14: 6432: loss: 0.6775168416:
14: 9632: loss: 0.6780011135:
14: 12832: loss: 0.6786078124:
14: 16032: loss: 0.6786649183:
14: 19232: loss: 0.6785798883:
14: 22432: loss: 0.6783277894:
14: 25632: loss: 0.6782452854:
14: 28832: loss: 0.6782130458:
Dev-Acc: 14: Accuracy: 0.2341145426: precision: 0.0650996560: recall: 0.9074987247: f1: 0.1214845840
Train-Acc: 14: Accuracy: 0.6018670797: precision: 0.5624773195: recall: 0.9170994675: f1: 0.6972908128
15: 3232: loss: 0.6775809324:
15: 6432: loss: 0.6770623362:
15: 9632: loss: 0.6772869782:
15: 12832: loss: 0.6775373396:
15: 16032: loss: 0.6778827276:
15: 19232: loss: 0.6778727464:
15: 22432: loss: 0.6776818314:
15: 25632: loss: 0.6776197021:
15: 28832: loss: 0.6775645765:
Dev-Acc: 15: Accuracy: 0.2331421673: precision: 0.0653290803: recall: 0.9124298589: f1: 0.1219282200
Train-Acc: 15: Accuracy: 0.6050227284: precision: 0.5645272044: recall: 0.9188087568: f1: 0.6993594876
16: 3232: loss: 0.6776263201:
16: 6432: loss: 0.6782226595:
16: 9632: loss: 0.6782249947:
16: 12832: loss: 0.6777522929:
16: 16032: loss: 0.6773671657:
16: 19232: loss: 0.6771821946:
16: 22432: loss: 0.6772784230:
16: 25632: loss: 0.6773722434:
16: 28832: loss: 0.6770635719:
Dev-Acc: 16: Accuracy: 0.2318026572: precision: 0.0653486761: recall: 0.9144703282: f1: 0.1219805394
Train-Acc: 16: Accuracy: 0.6081454754: precision: 0.5665560770: recall: 0.9205837880: f1: 0.7014301100
17: 3232: loss: 0.6759550881:
17: 6432: loss: 0.6761955789:
17: 9632: loss: 0.6764228956:
17: 12832: loss: 0.6765298541:
17: 16032: loss: 0.6763763517:
17: 19232: loss: 0.6763561554:
17: 22432: loss: 0.6762807236:
17: 25632: loss: 0.6761523469:
17: 28832: loss: 0.6761284402:
Dev-Acc: 17: Accuracy: 0.2310485691: precision: 0.0654677394: recall: 0.9173609930: f1: 0.1222136644
Train-Acc: 17: Accuracy: 0.6113668084: precision: 0.5686218910: recall: 0.9228190126: f1: 0.7036619295
18: 3232: loss: 0.6770643979:
18: 6432: loss: 0.6770660651:
18: 9632: loss: 0.6764838000:
18: 12832: loss: 0.6757748213:
18: 16032: loss: 0.6753402514:
18: 19232: loss: 0.6753212780:
18: 22432: loss: 0.6752879230:
18: 25632: loss: 0.6752535060:
18: 28832: loss: 0.6751431561:
Dev-Acc: 18: Accuracy: 0.2297686040: precision: 0.0655549097: recall: 0.9204216970: f1: 0.1223926831
Train-Acc: 18: Accuracy: 0.6144566536: precision: 0.5706402662: recall: 0.9245940438: f1: 0.7057229596
19: 3232: loss: 0.6738530314:
19: 6432: loss: 0.6738608074:
19: 9632: loss: 0.6741480929:
19: 12832: loss: 0.6744476856:
19: 16032: loss: 0.6743153188:
19: 19232: loss: 0.6743780242:
19: 22432: loss: 0.6745252837:
19: 25632: loss: 0.6745488492:
19: 28832: loss: 0.6743391628:
Dev-Acc: 19: Accuracy: 0.2287267745: precision: 0.0656397732: recall: 0.9231423227: f1: 0.1225646235
Train-Acc: 19: Accuracy: 0.6190257072: precision: 0.5736244968: recall: 0.9273552035: f1: 0.7088086026
20: 3232: loss: 0.6737096804:
20: 6432: loss: 0.6736881509:
20: 9632: loss: 0.6743373517:
20: 12832: loss: 0.6743243659:
20: 16032: loss: 0.6743749959:
20: 19232: loss: 0.6744826068:
20: 22432: loss: 0.6742762838:
20: 25632: loss: 0.6744231039:
20: 28832: loss: 0.6742296415:
Dev-Acc: 20: Accuracy: 0.2278536260: precision: 0.0657063859: recall: 0.9253528312: f1: 0.1227002165
Train-Acc: 20: Accuracy: 0.6221813560: precision: 0.5756749053: recall: 0.9294589442: f1: 0.7109881820
