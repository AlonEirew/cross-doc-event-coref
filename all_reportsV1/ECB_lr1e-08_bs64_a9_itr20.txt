1: 6464: loss: 0.7110565066:
1: 12864: loss: 0.7110144559:
1: 19264: loss: 0.7109243800:
1: 25664: loss: 0.7107757550:
1: 32064: loss: 0.7106803607:
1: 38464: loss: 0.7107098168:
1: 44864: loss: 0.7106387964:
1: 51264: loss: 0.7105895158:
1: 57664: loss: 0.7106262376:
1: 64064: loss: 0.7104750583:
1: 70464: loss: 0.7103121630:
1: 76864: loss: 0.7102387806:
1: 83264: loss: 0.7100467551:
1: 89664: loss: 0.7099856320:
1: 96064: loss: 0.7098837868:
1: 102464: loss: 0.7097852886:
1: 108864: loss: 0.7097489700:
1: 115264: loss: 0.7095969486:
1: 121664: loss: 0.7095099534:
1: 128064: loss: 0.7094359130:
1: 134464: loss: 0.7093237446:
1: 140864: loss: 0.7092520426:
1: 147264: loss: 0.7091644998:
Dev-Acc: 1: Accuracy: 0.3088089228: precision: 0.0641179847: recall: 0.7976534603: f1: 0.1186948876
Train-Acc: 1: Accuracy: 0.3306357265: precision: 0.1095944752: recall: 0.7991585037: f1: 0.1927550365
2: 6464: loss: 0.7061999524:
2: 12864: loss: 0.7061354408:
2: 19264: loss: 0.7061993051:
2: 25664: loss: 0.7060441555:
2: 32064: loss: 0.7059802693:
2: 38464: loss: 0.7056638297:
2: 44864: loss: 0.7056751250:
2: 51264: loss: 0.7055298912:
2: 57664: loss: 0.7054157516:
2: 64064: loss: 0.7053811998:
2: 70464: loss: 0.7052105616:
2: 76864: loss: 0.7050560343:
2: 83264: loss: 0.7049937377:
2: 89664: loss: 0.7048291141:
2: 96064: loss: 0.7047235454:
2: 102464: loss: 0.7046251807:
2: 108864: loss: 0.7045295858:
2: 115264: loss: 0.7044006918:
2: 121664: loss: 0.7042838195:
2: 128064: loss: 0.7041306027:
2: 134464: loss: 0.7040097550:
2: 140864: loss: 0.7039267984:
2: 147264: loss: 0.7038342242:
Dev-Acc: 2: Accuracy: 0.3769348264: precision: 0.0652499389: recall: 0.7262370345: f1: 0.1197415086
Train-Acc: 2: Accuracy: 0.3914535642: precision: 0.1114649362: recall: 0.7294720926: f1: 0.1933808536
3: 6464: loss: 0.7000874531:
3: 12864: loss: 0.7006840578:
3: 19264: loss: 0.7008085159:
3: 25664: loss: 0.7006524517:
3: 32064: loss: 0.7005955853:
3: 38464: loss: 0.7004278008:
3: 44864: loss: 0.7005141054:
3: 51264: loss: 0.7003147329:
3: 57664: loss: 0.7002662921:
3: 64064: loss: 0.7003052008:
3: 70464: loss: 0.7000914325:
3: 76864: loss: 0.6999705640:
3: 83264: loss: 0.6998625325:
3: 89664: loss: 0.6997368025:
3: 96064: loss: 0.6996866099:
3: 102464: loss: 0.6996635818:
3: 108864: loss: 0.6995560381:
3: 115264: loss: 0.6994442106:
3: 121664: loss: 0.6993334178:
3: 128064: loss: 0.6992629777:
3: 134464: loss: 0.6991719739:
3: 140864: loss: 0.6990634753:
3: 147264: loss: 0.6989272256:
Dev-Acc: 3: Accuracy: 0.4490395188: precision: 0.0628203096: recall: 0.6065295018: f1: 0.1138489036
Train-Acc: 3: Accuracy: 0.4581224024: precision: 0.1124743433: recall: 0.6412464664: f1: 0.1913806128
4: 6464: loss: 0.6952680367:
4: 12864: loss: 0.6950923964:
4: 19264: loss: 0.6951107186:
4: 25664: loss: 0.6949549554:
4: 32064: loss: 0.6951972036:
4: 38464: loss: 0.6952048952:
4: 44864: loss: 0.6950599767:
4: 51264: loss: 0.6949924443:
4: 57664: loss: 0.6949220122:
4: 64064: loss: 0.6948374236:
4: 70464: loss: 0.6948130434:
4: 76864: loss: 0.6947571122:
4: 83264: loss: 0.6946696261:
4: 89664: loss: 0.6945297267:
4: 96064: loss: 0.6944112590:
4: 102464: loss: 0.6943263203:
4: 108864: loss: 0.6942689053:
4: 115264: loss: 0.6941731016:
4: 121664: loss: 0.6940526688:
4: 128064: loss: 0.6939711499:
4: 134464: loss: 0.6938639175:
4: 140864: loss: 0.6937489326:
4: 147264: loss: 0.6937044698:
Dev-Acc: 4: Accuracy: 0.5245276690: precision: 0.0600866453: recall: 0.4881822819: f1: 0.1070030934
Train-Acc: 4: Accuracy: 0.5282098651: precision: 0.1146093143: recall: 0.5528236145: f1: 0.1898579847
5: 6464: loss: 0.6909270382:
5: 12864: loss: 0.6906023973:
5: 19264: loss: 0.6906893981:
5: 25664: loss: 0.6908469629:
5: 32064: loss: 0.6906531569:
5: 38464: loss: 0.6906379715:
5: 44864: loss: 0.6905919553:
5: 51264: loss: 0.6905595105:
5: 57664: loss: 0.6904994278:
5: 64064: loss: 0.6903711366:
5: 70464: loss: 0.6903464035:
5: 76864: loss: 0.6902056955:
5: 83264: loss: 0.6900705406:
5: 89664: loss: 0.6898923843:
5: 96064: loss: 0.6897387967:
5: 102464: loss: 0.6896390271:
5: 108864: loss: 0.6895276512:
5: 115264: loss: 0.6894259317:
5: 121664: loss: 0.6893508804:
5: 128064: loss: 0.6891807516:
5: 134464: loss: 0.6890908474:
5: 140864: loss: 0.6889528005:
5: 147264: loss: 0.6888303680:
Dev-Acc: 5: Accuracy: 0.5966919065: precision: 0.0610131825: recall: 0.4108144873: f1: 0.1062468392
Train-Acc: 5: Accuracy: 0.5941621065: precision: 0.1194352187: recall: 0.4799158504: f1: 0.1912697165
6: 6464: loss: 0.6862581122:
6: 12864: loss: 0.6859651768:
6: 19264: loss: 0.6859555568:
6: 25664: loss: 0.6858638825:
6: 32064: loss: 0.6855964394:
6: 38464: loss: 0.6854996237:
6: 44864: loss: 0.6854378561:
6: 51264: loss: 0.6854891920:
6: 57664: loss: 0.6854811770:
6: 64064: loss: 0.6853217235:
6: 70464: loss: 0.6852285877:
6: 76864: loss: 0.6851140415:
6: 83264: loss: 0.6850373284:
6: 89664: loss: 0.6849663911:
6: 96064: loss: 0.6849220870:
6: 102464: loss: 0.6847878425:
6: 108864: loss: 0.6847088606:
6: 115264: loss: 0.6846380249:
6: 121664: loss: 0.6845539606:
6: 128064: loss: 0.6844142273:
6: 134464: loss: 0.6843597201:
6: 140864: loss: 0.6842399939:
6: 147264: loss: 0.6841351104:
Dev-Acc: 6: Accuracy: 0.6630219221: precision: 0.0626966082: recall: 0.3422887264: f1: 0.1059808361
Train-Acc: 6: Accuracy: 0.6554072499: precision: 0.1262081299: recall: 0.4129248570: f1: 0.1933269722
7: 6464: loss: 0.6818090260:
7: 12864: loss: 0.6814007989:
7: 19264: loss: 0.6814411422:
7: 25664: loss: 0.6812433983:
7: 32064: loss: 0.6813216139:
7: 38464: loss: 0.6811841821:
7: 44864: loss: 0.6811335193:
7: 51264: loss: 0.6809574702:
7: 57664: loss: 0.6807397589:
7: 64064: loss: 0.6806144053:
7: 70464: loss: 0.6806116708:
7: 76864: loss: 0.6805434502:
7: 83264: loss: 0.6803856101:
7: 89664: loss: 0.6802668989:
7: 96064: loss: 0.6802019942:
7: 102464: loss: 0.6801644743:
7: 108864: loss: 0.6800082354:
7: 115264: loss: 0.6799488487:
7: 121664: loss: 0.6798048835:
7: 128064: loss: 0.6796794317:
7: 134464: loss: 0.6795341774:
7: 140864: loss: 0.6794313376:
7: 147264: loss: 0.6793125851:
Dev-Acc: 7: Accuracy: 0.7212851048: precision: 0.0643414806: recall: 0.2788641388: f1: 0.1045584954
Train-Acc: 7: Accuracy: 0.7100256085: precision: 0.1348345844: recall: 0.3507330222: f1: 0.1947862280
8: 6464: loss: 0.6762682629:
8: 12864: loss: 0.6761818996:
8: 19264: loss: 0.6763420359:
8: 25664: loss: 0.6761827579:
8: 32064: loss: 0.6763087848:
8: 38464: loss: 0.6760362566:
8: 44864: loss: 0.6759625666:
8: 51264: loss: 0.6757390592:
8: 57664: loss: 0.6756504495:
8: 64064: loss: 0.6755839226:
8: 70464: loss: 0.6754552020:
8: 76864: loss: 0.6753539515:
8: 83264: loss: 0.6752797653:
8: 89664: loss: 0.6751269633:
8: 96064: loss: 0.6750352013:
8: 102464: loss: 0.6748752064:
8: 108864: loss: 0.6747766434:
8: 115264: loss: 0.6747329226:
8: 121664: loss: 0.6746212600:
8: 128064: loss: 0.6745310906:
8: 134464: loss: 0.6744412234:
8: 140864: loss: 0.6743474824:
8: 147264: loss: 0.6742816983:
Dev-Acc: 8: Accuracy: 0.7692689300: precision: 0.0658269606: recall: 0.2239415065: f1: 0.1017459827
Train-Acc: 8: Accuracy: 0.7556045055: precision: 0.1441117376: recall: 0.2923542173: f1: 0.1930582387
9: 6464: loss: 0.6722624499:
9: 12864: loss: 0.6718464503:
9: 19264: loss: 0.6716113897:
9: 25664: loss: 0.6716561691:
9: 32064: loss: 0.6712195535:
9: 38464: loss: 0.6712077996:
9: 44864: loss: 0.6711086371:
9: 51264: loss: 0.6710045898:
9: 57664: loss: 0.6709311032:
9: 64064: loss: 0.6708694094:
9: 70464: loss: 0.6707210358:
9: 76864: loss: 0.6706053525:
9: 83264: loss: 0.6704791143:
9: 89664: loss: 0.6703906237:
9: 96064: loss: 0.6703353643:
9: 102464: loss: 0.6703049463:
9: 108864: loss: 0.6702749140:
9: 115264: loss: 0.6701806812:
9: 121664: loss: 0.6701392314:
9: 128064: loss: 0.6700102550:
9: 134464: loss: 0.6698946336:
9: 140864: loss: 0.6697961606:
9: 147264: loss: 0.6696726115:
Dev-Acc: 9: Accuracy: 0.8068443537: precision: 0.0654982730: recall: 0.1741200476: f1: 0.0951894027
Train-Acc: 9: Accuracy: 0.7940043211: precision: 0.1553883640: recall: 0.2389717967: f1: 0.1883224536
10: 6464: loss: 0.6672574997:
10: 12864: loss: 0.6663397789:
10: 19264: loss: 0.6665889941:
10: 25664: loss: 0.6665169953:
10: 32064: loss: 0.6665024010:
10: 38464: loss: 0.6662243841:
10: 44864: loss: 0.6661983840:
10: 51264: loss: 0.6661757641:
10: 57664: loss: 0.6662642285:
10: 64064: loss: 0.6662204746:
10: 70464: loss: 0.6661144244:
10: 76864: loss: 0.6659661851:
10: 83264: loss: 0.6658324508:
10: 89664: loss: 0.6657267801:
10: 96064: loss: 0.6656497559:
10: 102464: loss: 0.6655318576:
10: 108864: loss: 0.6655020017:
10: 115264: loss: 0.6654850580:
10: 121664: loss: 0.6654099410:
10: 128064: loss: 0.6653209894:
10: 134464: loss: 0.6652134706:
10: 140864: loss: 0.6650657846:
10: 147264: loss: 0.6649619938:
Dev-Acc: 10: Accuracy: 0.8372558951: precision: 0.0648523451: recall: 0.1333106615: f1: 0.0872565387
Train-Acc: 10: Accuracy: 0.8227466941: precision: 0.1669406496: recall: 0.1936098876: f1: 0.1792889322
11: 6464: loss: 0.6625962359:
11: 12864: loss: 0.6624474344:
11: 19264: loss: 0.6622220979:
11: 25664: loss: 0.6620203562:
11: 32064: loss: 0.6620350872:
11: 38464: loss: 0.6618345969:
11: 44864: loss: 0.6615736876:
11: 51264: loss: 0.6615340728:
11: 57664: loss: 0.6613693403:
11: 64064: loss: 0.6613326513:
11: 70464: loss: 0.6612471254:
11: 76864: loss: 0.6611155982:
11: 83264: loss: 0.6611156018:
11: 89664: loss: 0.6610386590:
11: 96064: loss: 0.6609510133:
11: 102464: loss: 0.6608583058:
11: 108864: loss: 0.6607963469:
11: 115264: loss: 0.6607330096:
11: 121664: loss: 0.6606674349:
11: 128064: loss: 0.6606030378:
11: 134464: loss: 0.6604602305:
11: 140864: loss: 0.6603308987:
11: 147264: loss: 0.6603267423:
Dev-Acc: 11: Accuracy: 0.8640260100: precision: 0.0686004191: recall: 0.1057643258: f1: 0.0832218357
Train-Acc: 11: Accuracy: 0.8451120853: precision: 0.1801394529: recall: 0.1545592006: f1: 0.1663718067
12: 6464: loss: 0.6583149171:
12: 12864: loss: 0.6574698201:
12: 19264: loss: 0.6577112287:
12: 25664: loss: 0.6575034527:
12: 32064: loss: 0.6572419581:
12: 38464: loss: 0.6571897825:
12: 44864: loss: 0.6572786711:
12: 51264: loss: 0.6571090433:
12: 57664: loss: 0.6569875477:
12: 64064: loss: 0.6569743729:
12: 70464: loss: 0.6567243392:
12: 76864: loss: 0.6567003096:
12: 83264: loss: 0.6566771999:
12: 89664: loss: 0.6566000324:
12: 96064: loss: 0.6564477047:
12: 102464: loss: 0.6563979964:
12: 108864: loss: 0.6562722219:
12: 115264: loss: 0.6561619887:
12: 121664: loss: 0.6560759200:
12: 128064: loss: 0.6559993186:
12: 134464: loss: 0.6558945255:
12: 140864: loss: 0.6557984732:
12: 147264: loss: 0.6556686646:
Dev-Acc: 12: Accuracy: 0.8847733736: precision: 0.0743985744: recall: 0.0851895936: f1: 0.0794292509
Train-Acc: 12: Accuracy: 0.8612385988: precision: 0.1924040067: recall: 0.1212280586: f1: 0.1487396653
13: 6464: loss: 0.6547485846:
13: 12864: loss: 0.6532153901:
13: 19264: loss: 0.6534625729:
13: 25664: loss: 0.6531279726:
13: 32064: loss: 0.6526379020:
13: 38464: loss: 0.6523978655:
13: 44864: loss: 0.6523616085:
13: 51264: loss: 0.6524333842:
13: 57664: loss: 0.6523466767:
13: 64064: loss: 0.6522318494:
13: 70464: loss: 0.6521972362:
13: 76864: loss: 0.6521537761:
13: 83264: loss: 0.6520643810:
13: 89664: loss: 0.6519479680:
13: 96064: loss: 0.6518737698:
13: 102464: loss: 0.6517809271:
13: 108864: loss: 0.6517179135:
13: 115264: loss: 0.6516655458:
13: 121664: loss: 0.6514935717:
13: 128064: loss: 0.6514503119:
13: 134464: loss: 0.6513405792:
13: 140864: loss: 0.6512458285:
13: 147264: loss: 0.6510995047:
Dev-Acc: 13: Accuracy: 0.9014823437: precision: 0.0711864407: recall: 0.0571331406: f1: 0.0633902462
Train-Acc: 13: Accuracy: 0.8736506701: precision: 0.2059859155: recall: 0.0923016238: f1: 0.1274799110
14: 6464: loss: 0.6488789541:
14: 12864: loss: 0.6488559577:
14: 19264: loss: 0.6487926453:
14: 25664: loss: 0.6484964891:
14: 32064: loss: 0.6485141711:
14: 38464: loss: 0.6482979667:
14: 44864: loss: 0.6481546550:
14: 51264: loss: 0.6481332545:
14: 57664: loss: 0.6480562954:
14: 64064: loss: 0.6480358090:
14: 70464: loss: 0.6479232553:
14: 76864: loss: 0.6477509176:
14: 83264: loss: 0.6476977266:
14: 89664: loss: 0.6475836580:
14: 96064: loss: 0.6474961972:
14: 102464: loss: 0.6474027150:
14: 108864: loss: 0.6473054468:
14: 115264: loss: 0.6472426032:
14: 121664: loss: 0.6470460436:
14: 128064: loss: 0.6469313281:
14: 134464: loss: 0.6468245236:
14: 140864: loss: 0.6466912814:
14: 147264: loss: 0.6465650837:
Dev-Acc: 14: Accuracy: 0.9145300984: precision: 0.0709576138: recall: 0.0384288386: f1: 0.0498566071
Train-Acc: 14: Accuracy: 0.8820590377: precision: 0.2130389064: recall: 0.0665965420: f1: 0.1014725033
15: 6464: loss: 0.6434288085:
15: 12864: loss: 0.6438256633:
15: 19264: loss: 0.6440332437:
15: 25664: loss: 0.6438347173:
15: 32064: loss: 0.6437688425:
15: 38464: loss: 0.6437566955:
15: 44864: loss: 0.6438723840:
15: 51264: loss: 0.6437297706:
15: 57664: loss: 0.6436383713:
15: 64064: loss: 0.6434901638:
15: 70464: loss: 0.6434322969:
15: 76864: loss: 0.6433851629:
15: 83264: loss: 0.6433154820:
15: 89664: loss: 0.6432039557:
15: 96064: loss: 0.6431022482:
15: 102464: loss: 0.6430046085:
15: 108864: loss: 0.6428824512:
15: 115264: loss: 0.6428401244:
15: 121664: loss: 0.6426602612:
15: 128064: loss: 0.6425155499:
15: 134464: loss: 0.6424634252:
15: 140864: loss: 0.6423496407:
15: 147264: loss: 0.6422252008:
Dev-Acc: 15: Accuracy: 0.9233112335: precision: 0.0620853081: recall: 0.0222751233: f1: 0.0327868852
Train-Acc: 15: Accuracy: 0.8875418901: precision: 0.2169106663: recall: 0.0477286174: f1: 0.0782411898
16: 6464: loss: 0.6405625927:
16: 12864: loss: 0.6391739219:
16: 19264: loss: 0.6392817988:
16: 25664: loss: 0.6389050975:
16: 32064: loss: 0.6390265200:
16: 38464: loss: 0.6388876313:
16: 44864: loss: 0.6388529616:
16: 51264: loss: 0.6387088186:
16: 57664: loss: 0.6385794893:
16: 64064: loss: 0.6387204520:
16: 70464: loss: 0.6386479251:
16: 76864: loss: 0.6386794078:
16: 83264: loss: 0.6386181114:
16: 89664: loss: 0.6386367834:
16: 96064: loss: 0.6385315325:
16: 102464: loss: 0.6384780030:
16: 108864: loss: 0.6383682989:
16: 115264: loss: 0.6382739819:
16: 121664: loss: 0.6381876593:
16: 128064: loss: 0.6381175297:
16: 134464: loss: 0.6380076226:
16: 140864: loss: 0.6378659075:
16: 147264: loss: 0.6378473950:
Dev-Acc: 16: Accuracy: 0.9293538332: precision: 0.0552763819: recall: 0.0130930114: f1: 0.0211712950
Train-Acc: 16: Accuracy: 0.8917625546: precision: 0.2350951374: recall: 0.0365524949: f1: 0.0632680929
17: 6464: loss: 0.6365518540:
17: 12864: loss: 0.6354084042:
17: 19264: loss: 0.6350072602:
17: 25664: loss: 0.6348887955:
17: 32064: loss: 0.6349737344:
17: 38464: loss: 0.6345888053:
17: 44864: loss: 0.6346399300:
17: 51264: loss: 0.6347532526:
17: 57664: loss: 0.6348236704:
17: 64064: loss: 0.6348310999:
17: 70464: loss: 0.6346590629:
17: 76864: loss: 0.6343822805:
17: 83264: loss: 0.6342213168:
17: 89664: loss: 0.6342732555:
17: 96064: loss: 0.6341447520:
17: 102464: loss: 0.6340607294:
17: 108864: loss: 0.6339729687:
17: 115264: loss: 0.6338904062:
17: 121664: loss: 0.6337212308:
17: 128064: loss: 0.6336236638:
17: 134464: loss: 0.6334748075:
17: 140864: loss: 0.6333878702:
17: 147264: loss: 0.6333100429:
Dev-Acc: 17: Accuracy: 0.9333425760: precision: 0.0636079249: recall: 0.0103723856: f1: 0.0178362573
Train-Acc: 17: Accuracy: 0.8943198919: precision: 0.2452830189: recall: 0.0273486293: f1: 0.0492103862
18: 6464: loss: 0.6307776785:
18: 12864: loss: 0.6301742640:
18: 19264: loss: 0.6300197937:
18: 25664: loss: 0.6302380788:
18: 32064: loss: 0.6302481396:
18: 38464: loss: 0.6301093547:
18: 44864: loss: 0.6300064942:
18: 51264: loss: 0.6299765628:
18: 57664: loss: 0.6299069059:
18: 64064: loss: 0.6298001052:
18: 70464: loss: 0.6298185992:
18: 76864: loss: 0.6297487880:
18: 83264: loss: 0.6296680755:
18: 89664: loss: 0.6296117828:
18: 96064: loss: 0.6296117395:
18: 102464: loss: 0.6294802653:
18: 108864: loss: 0.6294411891:
18: 115264: loss: 0.6293118269:
18: 121664: loss: 0.6292091001:
18: 128064: loss: 0.6290809292:
18: 134464: loss: 0.6289595834:
18: 140864: loss: 0.6288020304:
18: 147264: loss: 0.6288004293:
Dev-Acc: 18: Accuracy: 0.9366268516: precision: 0.0726351351: recall: 0.0073116817: f1: 0.0132859571
Train-Acc: 18: Accuracy: 0.8961869478: precision: 0.2542372881: recall: 0.0197225692: f1: 0.0366054542
19: 6464: loss: 0.6273031032:
19: 12864: loss: 0.6266768879:
19: 19264: loss: 0.6270842445:
19: 25664: loss: 0.6268345995:
19: 32064: loss: 0.6268534232:
19: 38464: loss: 0.6264107279:
19: 44864: loss: 0.6262715257:
19: 51264: loss: 0.6259648287:
19: 57664: loss: 0.6257016606:
19: 64064: loss: 0.6255652704:
19: 70464: loss: 0.6254664240:
19: 76864: loss: 0.6253954915:
19: 83264: loss: 0.6252703785:
19: 89664: loss: 0.6252239390:
19: 96064: loss: 0.6252216171:
19: 102464: loss: 0.6252155595:
19: 108864: loss: 0.6250575572:
19: 115264: loss: 0.6248884190:
19: 121664: loss: 0.6248869575:
19: 128064: loss: 0.6248681277:
19: 134464: loss: 0.6247433544:
19: 140864: loss: 0.6246419463:
19: 147264: loss: 0.6245947244:
Dev-Acc: 19: Accuracy: 0.9385120273: precision: 0.0927835052: recall: 0.0061214079: f1: 0.0114850853
Train-Acc: 19: Accuracy: 0.8974097371: precision: 0.2359249330: recall: 0.0115705739: f1: 0.0220592843
20: 6464: loss: 0.6218923563:
20: 12864: loss: 0.6224630496:
20: 19264: loss: 0.6223964403:
20: 25664: loss: 0.6219106095:
20: 32064: loss: 0.6218958542:
20: 38464: loss: 0.6216012025:
20: 44864: loss: 0.6216222898:
20: 51264: loss: 0.6216798434:
20: 57664: loss: 0.6217186765:
20: 64064: loss: 0.6215335746:
20: 70464: loss: 0.6216069600:
20: 76864: loss: 0.6216317051:
20: 83264: loss: 0.6214272093:
20: 89664: loss: 0.6213191973:
20: 96064: loss: 0.6212152294:
20: 102464: loss: 0.6210454657:
20: 108864: loss: 0.6210497396:
20: 115264: loss: 0.6209227250:
20: 121664: loss: 0.6207439895:
20: 128064: loss: 0.6206148010:
20: 134464: loss: 0.6205156303:
20: 140864: loss: 0.6204057346:
20: 147264: loss: 0.6203208954:
Dev-Acc: 20: Accuracy: 0.9395935535: precision: 0.0809716599: recall: 0.0034007822: f1: 0.0065274151
Train-Acc: 20: Accuracy: 0.8984353542: precision: 0.2561475410: recall: 0.0082177372: f1: 0.0159245812
