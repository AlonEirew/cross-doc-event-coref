ssh://alon_nlp@MLU-01-TitanXP.iil.intel.com:22/home/alon_nlp/venv/bin/python -u /home/alon_nlp/cross-doc-coref/src/pairwize_model/train.py
2019-11-15 10:24:27.822282: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-15 10:24:27.848103: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999980000 Hz
2019-11-15 10:24:27.851356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e2c790 executing computations on platform Host. Devices:
2019-11-15 10:24:27.851386: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
INFO:src.utils.dataset_utils:Create Features:SPLIT.TRAIN
INFO:src.utils.json_utils:Loading mentions from-/home/alon_nlp/cross-doc-coref/resources/corpora/head_lemma/WEC_Train_Event_gold_mentions.json
INFO:src.utils.json_utils:Mentions file-/home/alon_nlp/cross-doc-coref/resources/corpora/head_lemma/WEC_Train_Event_gold_mentions.json, took:1.4939 sec to load
INFO:src.utils.dataset_utils:Create pos/neg examples
INFO:src.utils.dataset_utils:pos-160369
INFO:src.utils.dataset_utils:neg-170460
INFO:src.utils.dataset_utils:Create Features:SPLIT.VALIDATION
INFO:src.utils.json_utils:Loading mentions from-/home/alon_nlp/cross-doc-coref/resources/corpora/head_lemma/WEC_Dev_Event_gold_mentions.json
INFO:src.utils.json_utils:Mentions file-/home/alon_nlp/cross-doc-coref/resources/corpora/head_lemma/WEC_Dev_Event_gold_mentions.json, took:0.1688 sec to load
INFO:src.utils.dataset_utils:Create pos/neg examples
INFO:src.utils.dataset_utils:pos-25384
INFO:src.utils.dataset_utils:neg-26955
INFO:__main__:1: 3232: loss: 0.6940723640:
INFO:__main__:1: 6432: loss: 0.6935448602:
INFO:__main__:1: 9632: loss: 0.6933420654:
INFO:__main__:1: 12832: loss: 0.6930307311:
INFO:__main__:1: 16032: loss: 0.6924981456:
INFO:__main__:1: 19232: loss: 0.6922112468:
INFO:__main__:1: 22432: loss: 0.6918318075:
INFO:__main__:1: 25632: loss: 0.6913092647:
INFO:__main__:1: 28832: loss: 0.6908868119:
INFO:__main__:1: 32032: loss: 0.6905276645:
INFO:__main__:1: 35232: loss: 0.6901767324:
INFO:__main__:1: 38432: loss: 0.6897644599:
INFO:__main__:1: 41632: loss: 0.6894443647:
INFO:__main__:1: 44832: loss: 0.6890411141:
INFO:__main__:1: 48032: loss: 0.6886382927:
INFO:__main__:1: 51232: loss: 0.6882948211:
INFO:__main__:1: 54432: loss: 0.6878554481:
INFO:__main__:1: 57632: loss: 0.6874596219:
INFO:__main__:1: 60832: loss: 0.6870906036:
INFO:__main__:1: 64032: loss: 0.6867929285:
INFO:__main__:1: 67232: loss: 0.6864205577:
INFO:__main__:1: 70432: loss: 0.6861039622:
INFO:__main__:1: 73632: loss: 0.6857422253:
INFO:__main__:1: 76832: loss: 0.6853950278:
INFO:__main__:1: 80032: loss: 0.6849916667:
INFO:__main__:1: 83232: loss: 0.6846410258:
INFO:__main__:1: 86432: loss: 0.6842689100:
INFO:__main__:1: 89632: loss: 0.6838948512:
INFO:__main__:1: 92832: loss: 0.6835355061:
INFO:__main__:1: 96032: loss: 0.6831977247:
INFO:__main__:1: 99232: loss: 0.6828190303:
INFO:__main__:1: 102432: loss: 0.6824219012:
INFO:__main__:1: 105632: loss: 0.6820657741:
INFO:__main__:1: 108832: loss: 0.6817305633:
INFO:__main__:1: 112032: loss: 0.6813937476:
INFO:__main__:1: 115232: loss: 0.6810401299:
INFO:__main__:1: 118432: loss: 0.6806886874:
INFO:__main__:1: 121632: loss: 0.6803575707:
INFO:__main__:1: 124832: loss: 0.6799871315:
INFO:__main__:1: 128032: loss: 0.6796415079:
INFO:__main__:1: 131232: loss: 0.6792990357:
INFO:__main__:1: 134432: loss: 0.6789471845:
INFO:__main__:1: 137632: loss: 0.6785891502:
INFO:__main__:1: 140832: loss: 0.6782386027:
INFO:__main__:1: 144032: loss: 0.6778846476:
INFO:__main__:1: 147232: loss: 0.6775276750:
INFO:__main__:1: 150432: loss: 0.6771761640:
INFO:__main__:1: 153632: loss: 0.6768016759:
INFO:__main__:1: 156832: loss: 0.6764538081:
INFO:__main__:1: 160032: loss: 0.6760964842:
INFO:__main__:1: 163232: loss: 0.6757612916:
INFO:__main__:1: 166432: loss: 0.6753939555:
INFO:__main__:1: 169632: loss: 0.6750557991:
INFO:__main__:1: 172832: loss: 0.6746989826:
INFO:__main__:1: 176032: loss: 0.6743578587:
INFO:__main__:1: 179232: loss: 0.6739822369:
INFO:__main__:1: 182432: loss: 0.6736295101:
INFO:__main__:1: 185632: loss: 0.6732821836:
INFO:__main__:1: 188832: loss: 0.6729364177:
INFO:__main__:1: 192032: loss: 0.6725870770:
INFO:__main__:1: 195232: loss: 0.6722371639:
INFO:__main__:1: 198432: loss: 0.6718850367:
INFO:__main__:1: 201632: loss: 0.6715153157:
INFO:__main__:1: 204832: loss: 0.6711434677:
INFO:__main__:1: 208032: loss: 0.6707637892:
INFO:__main__:1: 211232: loss: 0.6704200549:
INFO:__main__:1: 214432: loss: 0.6700471046:
INFO:__main__:1: 217632: loss: 0.6696640402:
INFO:__main__:1: 220832: loss: 0.6693161959:
INFO:__main__:1: 224032: loss: 0.6689616065:
INFO:__main__:1: 227232: loss: 0.6686048479:
INFO:__main__:1: 230432: loss: 0.6682351838:
INFO:__main__:1: 233632: loss: 0.6678628951:
INFO:__main__:1: 236832: loss: 0.6675090323:
INFO:__main__:1: 240032: loss: 0.6671459184:
INFO:__main__:1: 243232: loss: 0.6667874493:
INFO:__main__:1: 246432: loss: 0.6664224862:
INFO:__main__:1: 249632: loss: 0.6660672563:
INFO:__main__:1: 252832: loss: 0.6656901425:
INFO:__main__:1: 256032: loss: 0.6653576685:
INFO:__main__:1: 259232: loss: 0.6649879782:
INFO:__main__:1: 262432: loss: 0.6646291714:
INFO:__main__:1: 265632: loss: 0.6642783425:
INFO:__main__:1: 268832: loss: 0.6638995681:
INFO:__main__:1: 272032: loss: 0.6635320280:
INFO:__main__:1: 275232: loss: 0.6631869916:
INFO:__main__:1: 278432: loss: 0.6628475368:
INFO:__main__:1: 281632: loss: 0.6624653468:
INFO:__main__:1: 284832: loss: 0.6620873799:
INFO:__main__:1: 288032: loss: 0.6617109015:
INFO:__main__:1: 291232: loss: 0.6613574236:
INFO:__main__:1: 294432: loss: 0.6609767054:
INFO:__main__:1: 297632: loss: 0.6605942429:
INFO:__main__:1: 300832: loss: 0.6602288941:
INFO:__main__:1: 304032: loss: 0.6598606543:
INFO:__main__:1: 307232: loss: 0.6594838364:
INFO:__main__:1: 310432: loss: 0.6591035614:
INFO:__main__:1: 313632: loss: 0.6587522179:
INFO:__main__:1: 316832: loss: 0.6583671695:
INFO:__main__:1: 320032: loss: 0.6580140836:
INFO:__main__:1: 323232: loss: 0.6576231090:
INFO:__main__:1: 326432: loss: 0.6572300240:
INFO:__main__:1: 329632: loss: 0.6568281805:
INFO:__main__:Dev-Acc: 1: Accuracy: 0.6146468520: precision: 0.5779918045: recall: 0.7612669398: f1: 0.6570889369
INFO:__main__:Train-Acc: 1: Accuracy: 0.8682007790: precision: 0.9340098127: recall: 0.7834618910: f1: 0.8521375840
INFO:__main__:2: 3232: loss: 0.6157682526:
INFO:__main__:2: 6432: loss: 0.6159468046:
INFO:__main__:2: 9632: loss: 0.6149904309:
INFO:__main__:2: 12832: loss: 0.6146293990:
INFO:__main__:2: 16032: loss: 0.6143749366:
INFO:__main__:2: 19232: loss: 0.6139067589:
INFO:__main__:2: 22432: loss: 0.6132371205:
INFO:__main__:2: 25632: loss: 0.6131054617:
INFO:__main__:2: 28832: loss: 0.6128765839:
INFO:__main__:2: 32032: loss: 0.6126520885:
INFO:__main__:2: 35232: loss: 0.6125183782:
INFO:__main__:2: 38432: loss: 0.6121635132:
INFO:__main__:2: 41632: loss: 0.6118417894:
INFO:__main__:2: 44832: loss: 0.6112856979:
INFO:__main__:2: 48032: loss: 0.6108316951:
INFO:__main__:2: 51232: loss: 0.6105724067:
INFO:__main__:2: 54432: loss: 0.6102504332:
INFO:__main__:2: 57632: loss: 0.6098666448:
INFO:__main__:2: 60832: loss: 0.6094407314:
INFO:__main__:2: 64032: loss: 0.6090029306:
INFO:__main__:2: 67232: loss: 0.6086323113:
INFO:__main__:2: 70432: loss: 0.6082843786:
INFO:__main__:2: 73632: loss: 0.6078809011:
INFO:__main__:2: 76832: loss: 0.6075031746:
INFO:__main__:2: 80032: loss: 0.6070094038:
INFO:__main__:2: 83232: loss: 0.6066220816:
INFO:__main__:2: 86432: loss: 0.6063247102:
INFO:__main__:2: 89632: loss: 0.6058402180:
INFO:__main__:2: 92832: loss: 0.6053663082:
INFO:__main__:2: 96032: loss: 0.6048857966:
INFO:__main__:2: 99232: loss: 0.6043650114:
INFO:__main__:2: 102432: loss: 0.6038829452:
INFO:__main__:2: 105632: loss: 0.6035059468:
INFO:__main__:2: 108832: loss: 0.6030783794:
INFO:__main__:2: 112032: loss: 0.6027375687:
INFO:__main__:2: 115232: loss: 0.6022984423:
INFO:__main__:2: 118432: loss: 0.6018525764:
INFO:__main__:2: 121632: loss: 0.6013949971:
INFO:__main__:2: 124832: loss: 0.6008580593:
INFO:__main__:2: 128032: loss: 0.6004580310:
INFO:__main__:2: 131232: loss: 0.6000208686:
INFO:__main__:2: 134432: loss: 0.5996086371:
INFO:__main__:2: 137632: loss: 0.5991599662:
INFO:__main__:2: 140832: loss: 0.5986192840:
INFO:__main__:2: 144032: loss: 0.5981772434:
INFO:__main__:2: 147232: loss: 0.5977278615:
INFO:__main__:2: 150432: loss: 0.5973378957:
INFO:__main__:2: 153632: loss: 0.5969048146:
INFO:__main__:2: 156832: loss: 0.5964048081:
INFO:__main__:2: 160032: loss: 0.5959239567:
INFO:__main__:2: 163232: loss: 0.5954547459:
INFO:__main__:2: 166432: loss: 0.5950178404:
INFO:__main__:2: 169632: loss: 0.5945065514:
INFO:__main__:2: 172832: loss: 0.5940048852:
INFO:__main__:2: 176032: loss: 0.5936133908:
INFO:__main__:2: 179232: loss: 0.5931227736:
INFO:__main__:2: 182432: loss: 0.5927154927:
INFO:__main__:2: 185632: loss: 0.5922918360:
INFO:__main__:2: 188832: loss: 0.5917860201:
INFO:__main__:2: 192032: loss: 0.5913340156:
INFO:__main__:2: 195232: loss: 0.5909378618:
INFO:__main__:2: 198432: loss: 0.5904872499:
INFO:__main__:2: 201632: loss: 0.5899904812:
INFO:__main__:2: 204832: loss: 0.5894865131:
INFO:__main__:2: 208032: loss: 0.5890803824:
INFO:__main__:2: 211232: loss: 0.5886276944:
INFO:__main__:2: 214432: loss: 0.5881578800:
INFO:__main__:2: 217632: loss: 0.5877160728:
INFO:__main__:2: 220832: loss: 0.5872641051:
INFO:__main__:2: 224032: loss: 0.5868061934:
INFO:__main__:2: 227232: loss: 0.5863089668:
INFO:__main__:2: 230432: loss: 0.5858403068:
INFO:__main__:2: 233632: loss: 0.5853694561:
INFO:__main__:2: 236832: loss: 0.5849614249:
INFO:__main__:2: 240032: loss: 0.5844939280:
INFO:__main__:2: 243232: loss: 0.5840484153:
INFO:__main__:2: 246432: loss: 0.5835609813:
INFO:__main__:2: 249632: loss: 0.5831107938:
INFO:__main__:2: 252832: loss: 0.5826506255:
INFO:__main__:2: 256032: loss: 0.5821781640:
INFO:__main__:2: 259232: loss: 0.5816802768:
INFO:__main__:2: 262432: loss: 0.5812574191:
INFO:__main__:2: 265632: loss: 0.5808337922:
INFO:__main__:2: 268832: loss: 0.5804187845:
INFO:__main__:2: 272032: loss: 0.5799589522:
INFO:__main__:2: 275232: loss: 0.5795255184:
INFO:__main__:2: 278432: loss: 0.5790700158:
INFO:__main__:2: 281632: loss: 0.5786038080:
INFO:__main__:2: 284832: loss: 0.5781655706:
INFO:__main__:2: 288032: loss: 0.5777358038:
INFO:__main__:2: 291232: loss: 0.5773012719:
INFO:__main__:2: 294432: loss: 0.5767785891:
INFO:__main__:2: 297632: loss: 0.5763110911:
INFO:__main__:2: 300832: loss: 0.5758833273:
INFO:__main__:2: 304032: loss: 0.5754146478:
INFO:__main__:2: 307232: loss: 0.5749745110:
INFO:__main__:2: 310432: loss: 0.5745194566:
INFO:__main__:2: 313632: loss: 0.5740239054:
INFO:__main__:2: 316832: loss: 0.5735594759:
INFO:__main__:2: 320032: loss: 0.5730827226:
INFO:__main__:2: 323232: loss: 0.5725892179:
INFO:__main__:2: 326432: loss: 0.5721708371:
INFO:__main__:2: 329632: loss: 0.5716781937:
INFO:__main__:Dev-Acc: 2: Accuracy: 0.6051510572: precision: 0.5653933581: recall: 0.8034982666: f1: 0.6637378372
INFO:__main__:Train-Acc: 2: Accuracy: 0.9109479189: precision: 0.9895074562: recall: 0.8250409992: f1: 0.8998207989
INFO:__main__:3: 3232: loss: 0.5235067171:
INFO:__main__:3: 6432: loss: 0.5217264995:
INFO:__main__:3: 9632: loss: 0.5207649806:
INFO:__main__:3: 12832: loss: 0.5205249842:
INFO:__main__:3: 16032: loss: 0.5202951630:
INFO:__main__:3: 19232: loss: 0.5196785351:
INFO:__main__:3: 22432: loss: 0.5192980877:
INFO:__main__:3: 25632: loss: 0.5190873700:
INFO:__main__:3: 28832: loss: 0.5186902745:
INFO:__main__:3: 32032: loss: 0.5181411383:
INFO:__main__:3: 35232: loss: 0.5174125502:
INFO:__main__:3: 38432: loss: 0.5171463603:
INFO:__main__:3: 41632: loss: 0.5167418129:
INFO:__main__:3: 44832: loss: 0.5163305918:
INFO:__main__:3: 48032: loss: 0.5162099665:
INFO:__main__:3: 51232: loss: 0.5155394208:
INFO:__main__:3: 54432: loss: 0.5147839531:
INFO:__main__:3: 57632: loss: 0.5142264495:
INFO:__main__:3: 60832: loss: 0.5136930510:
INFO:__main__:3: 64032: loss: 0.5130714720:
INFO:__main__:3: 67232: loss: 0.5127058370:
INFO:__main__:3: 70432: loss: 0.5121037847:
INFO:__main__:3: 73632: loss: 0.5116316392:
INFO:__main__:3: 76832: loss: 0.5111584127:
INFO:__main__:3: 80032: loss: 0.5106434343:
INFO:__main__:3: 83232: loss: 0.5101165512:
INFO:__main__:3: 86432: loss: 0.5095566829:
INFO:__main__:3: 89632: loss: 0.5092302498:
INFO:__main__:3: 92832: loss: 0.5087977535:
INFO:__main__:3: 96032: loss: 0.5083915251:
INFO:__main__:3: 99232: loss: 0.5078847130:
INFO:__main__:3: 102432: loss: 0.5072823515:
INFO:__main__:3: 105632: loss: 0.5067536089:
INFO:__main__:3: 108832: loss: 0.5063302088:
INFO:__main__:3: 112032: loss: 0.5058391107:
INFO:__main__:3: 115232: loss: 0.5055003212:
INFO:__main__:3: 118432: loss: 0.5049741358:
INFO:__main__:3: 121632: loss: 0.5044324695:
INFO:__main__:3: 124832: loss: 0.5040420670:
INFO:__main__:3: 128032: loss: 0.5035868907:
INFO:__main__:3: 131232: loss: 0.5031299058:
INFO:__main__:3: 134432: loss: 0.5026510837:
INFO:__main__:3: 137632: loss: 0.5020965683:
INFO:__main__:3: 140832: loss: 0.5015633496:
INFO:__main__:3: 144032: loss: 0.5009632892:
INFO:__main__:3: 147232: loss: 0.5004441364:
INFO:__main__:3: 150432: loss: 0.4998893811:
INFO:__main__:3: 153632: loss: 0.4994365888:
INFO:__main__:3: 156832: loss: 0.4988584423:
INFO:__main__:3: 160032: loss: 0.4983668946:
INFO:__main__:3: 163232: loss: 0.4979828728:
INFO:__main__:3: 166432: loss: 0.4975035819:
INFO:__main__:3: 169632: loss: 0.4970237864:
INFO:__main__:3: 172832: loss: 0.4965219558:
INFO:__main__:3: 176032: loss: 0.4961247745:
INFO:__main__:3: 179232: loss: 0.4956369312:
INFO:__main__:3: 182432: loss: 0.4951066483:
INFO:__main__:3: 185632: loss: 0.4946002249:
INFO:__main__:3: 188832: loss: 0.4941761486:
INFO:__main__:3: 192032: loss: 0.4937549758:
INFO:__main__:3: 195232: loss: 0.4933958146:
INFO:__main__:3: 198432: loss: 0.4930288592:
INFO:__main__:3: 201632: loss: 0.4925391951:
INFO:__main__:3: 204832: loss: 0.4919692602:
INFO:__main__:3: 208032: loss: 0.4915421625:
INFO:__main__:3: 211232: loss: 0.4910787071:
INFO:__main__:3: 214432: loss: 0.4905891749:
INFO:__main__:3: 217632: loss: 0.4902053665:
INFO:__main__:3: 220832: loss: 0.4897993446:
INFO:__main__:3: 224032: loss: 0.4893054990:
INFO:__main__:3: 227232: loss: 0.4889430613:
INFO:__main__:3: 230432: loss: 0.4884779900:
INFO:__main__:3: 233632: loss: 0.4879226248:
INFO:__main__:3: 236832: loss: 0.4875033417:
INFO:__main__:3: 240032: loss: 0.4870195579:
INFO:__main__:3: 243232: loss: 0.4866136544:
INFO:__main__:3: 246432: loss: 0.4861894551:
INFO:__main__:3: 249632: loss: 0.4857164390:
INFO:__main__:3: 252832: loss: 0.4852338544:
INFO:__main__:3: 256032: loss: 0.4847347946:
INFO:__main__:3: 259232: loss: 0.4842712090:
INFO:__main__:3: 262432: loss: 0.4838654458:
INFO:__main__:3: 265632: loss: 0.4834130733:
INFO:__main__:3: 268832: loss: 0.4829608327:
INFO:__main__:3: 272032: loss: 0.4824907690:
INFO:__main__:3: 275232: loss: 0.4820316288:
INFO:__main__:3: 278432: loss: 0.4815127768:
INFO:__main__:3: 281632: loss: 0.4811209199:
INFO:__main__:3: 284832: loss: 0.4806856316:
INFO:__main__:3: 288032: loss: 0.4802358736:
INFO:__main__:3: 291232: loss: 0.4797275200:
INFO:__main__:3: 294432: loss: 0.4792027324:
INFO:__main__:3: 297632: loss: 0.4787338919:
INFO:__main__:3: 300832: loss: 0.4783335799:
INFO:__main__:3: 304032: loss: 0.4778657848:
INFO:__main__:3: 307232: loss: 0.4773765009:
INFO:__main__:3: 310432: loss: 0.4768564493:
INFO:__main__:3: 313632: loss: 0.4764086192:
INFO:__main__:3: 316832: loss: 0.4758679571:
INFO:__main__:3: 320032: loss: 0.4754515306:
INFO:__main__:3: 323232: loss: 0.4749754466:
INFO:__main__:3: 326432: loss: 0.4745131015:
INFO:__main__:3: 329632: loss: 0.4740402081:
INFO:__main__:Dev-Acc: 3: Accuracy: 0.6028965116: precision: 0.5594960940: recall: 0.8520721714: f1: 0.6754629774
INFO:__main__:Train-Acc: 3: Accuracy: 0.9281138778: precision: 0.9813028127: recall: 0.8682476040: f1: 0.9213199145

Process finished with exit code 0
