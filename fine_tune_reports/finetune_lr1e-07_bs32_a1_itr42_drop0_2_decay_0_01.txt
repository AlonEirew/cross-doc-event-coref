ssh://alon_nlp@MLU-01-TitanXP.iil.intel.com:22/home/alon_nlp/venv/bin/python -u /home/alon_nlp/cross-doc-coref/src/pairwize_model/train.py
2019-11-15 13:55:34.564176: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-15 13:55:34.592024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999980000 Hz
2019-11-15 13:55:34.595004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x671b8a0 executing computations on platform Host. Devices:
2019-11-15 13:55:34.595024: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
INFO:__main__:Loading model to fine tune-/home/alon_nlp/cross-doc-coref/saved_models/WEC_trained_model
INFO:src.utils.dataset_utils:Create Features:SPLIT.TRAIN
INFO:src.utils.json_utils:Loading mentions from-/home/alon_nlp/cross-doc-coref/resources/corpora/single_sent_full_context_mean/ECB_Train_Event_gold_mentions.json
INFO:src.utils.json_utils:Mentions file-/home/alon_nlp/cross-doc-coref/resources/corpora/single_sent_full_context_mean/ECB_Train_Event_gold_mentions.json, took:0.0373 sec to load
INFO:src.utils.dataset_utils:Create pos/neg examples
INFO:src.utils.dataset_utils:pos-15211
INFO:src.utils.dataset_utils:neg-15211
INFO:src.utils.dataset_utils:Create Features:SPLIT.VALIDATION
INFO:src.utils.json_utils:Loading mentions from-/home/alon_nlp/cross-doc-coref/resources/corpora/single_sent_full_context_mean/ECB_Dev_Event_gold_mentions.json
INFO:src.utils.json_utils:Mentions file-/home/alon_nlp/cross-doc-coref/resources/corpora/single_sent_full_context_mean/ECB_Dev_Event_gold_mentions.json, took:0.0098 sec to load
INFO:src.utils.dataset_utils:Create pos/neg examples
INFO:src.utils.dataset_utils:pos-5881
INFO:src.utils.dataset_utils:neg-94903
INFO:__main__:1: 3232: loss: 0.6416053903:
INFO:__main__:1: 6432: loss: 0.6429328963:
INFO:__main__:1: 9632: loss: 0.6427821960:
INFO:__main__:1: 12832: loss: 0.6434363380:
INFO:__main__:1: 16032: loss: 0.6428802226:
INFO:__main__:1: 19232: loss: 0.6424910677:
INFO:__main__:1: 22432: loss: 0.6414539988:
INFO:__main__:1: 25632: loss: 0.6406819034:
INFO:__main__:1: 28832: loss: 0.6402765985:
INFO:__main__:Dev-Acc: 1: Accuracy: 0.2760656476: precision: 0.0588351353: recall: 0.7605849345: f1: 0.1092214341
INFO:__main__:Train-Acc: 1: Accuracy: 0.5685688257: precision: 0.5463473160: recall: 0.8082966274: f1: 0.6519952274
INFO:__main__:2: 3232: loss: 0.6375552326:
INFO:__main__:2: 6432: loss: 0.6350249940:
INFO:__main__:2: 9632: loss: 0.6335818728:
INFO:__main__:2: 12832: loss: 0.6328449863:
INFO:__main__:2: 16032: loss: 0.6320719174:
INFO:__main__:2: 19232: loss: 0.6313743570:
INFO:__main__:2: 22432: loss: 0.6302400569:
INFO:__main__:2: 25632: loss: 0.6299529582:
INFO:__main__:2: 28832: loss: 0.6297419345:
INFO:__main__:Dev-Acc: 2: Accuracy: 0.2762839198: precision: 0.0593391862: recall: 0.7677265771: f1: 0.1101635984
INFO:__main__:Train-Acc: 2: Accuracy: 0.5884228945: precision: 0.5608542213: recall: 0.8149365591: f1: 0.6644333074
INFO:__main__:3: 3232: loss: 0.6232273388:
INFO:__main__:3: 6432: loss: 0.6247002944:
INFO:__main__:3: 9632: loss: 0.6237289941:
INFO:__main__:3: 12832: loss: 0.6234047176:
INFO:__main__:3: 16032: loss: 0.6231586686:
INFO:__main__:3: 19232: loss: 0.6228254892:
INFO:__main__:3: 22432: loss: 0.6219033122:
INFO:__main__:3: 25632: loss: 0.6206589814:
INFO:__main__:3: 28832: loss: 0.6203666016:
INFO:__main__:Dev-Acc: 3: Accuracy: 0.2726127207: precision: 0.0635389156: recall: 0.8345519469: f1: 0.1180872180
INFO:__main__:Train-Acc: 3: Accuracy: 0.6237263083: precision: 0.5856077147: recall: 0.8463611860: f1: 0.6922435811
INFO:__main__:4: 3232: loss: 0.6150553685:
INFO:__main__:4: 6432: loss: 0.6137588730:
INFO:__main__:4: 9632: loss: 0.6129853600:
INFO:__main__:4: 12832: loss: 0.6127926023:
INFO:__main__:4: 16032: loss: 0.6126362268:
INFO:__main__:4: 19232: loss: 0.6123539482:
INFO:__main__:4: 22432: loss: 0.6113156642:
INFO:__main__:4: 25632: loss: 0.6109988158:
INFO:__main__:4: 28832: loss: 0.6105318413:
INFO:__main__:Dev-Acc: 4: Accuracy: 0.2676019967: precision: 0.0649057861: recall: 0.8615881653: f1: 0.1207175871
INFO:__main__:Train-Acc: 4: Accuracy: 0.6582736373: precision: 0.6109498134: recall: 0.8715403327: f1: 0.7183419128
INFO:__main__:5: 3232: loss: 0.6005189866:
INFO:__main__:5: 6432: loss: 0.6016099176:
INFO:__main__:5: 9632: loss: 0.6023127286:
INFO:__main__:5: 12832: loss: 0.6022860941:
INFO:__main__:5: 16032: loss: 0.6013497646:
INFO:__main__:5: 19232: loss: 0.6007417518:
INFO:__main__:5: 22432: loss: 0.6013080840:
INFO:__main__:5: 25632: loss: 0.6012397680:
INFO:__main__:5: 28832: loss: 0.6007655936:
INFO:__main__:Dev-Acc: 5: Accuracy: 0.2694971263: precision: 0.0653105749: recall: 0.8653290257: f1: 0.1214543979
INFO:__main__:Train-Acc: 5: Accuracy: 0.6918677688: precision: 0.6401171444: recall: 0.8765367168: f1: 0.7399001110
INFO:__main__:6: 3232: loss: 0.5968150502:
INFO:__main__:6: 6432: loss: 0.5935244599:
INFO:__main__:6: 9632: loss: 0.5935351761:
INFO:__main__:6: 12832: loss: 0.5947964494:
INFO:__main__:6: 16032: loss: 0.5939254518:
INFO:__main__:6: 19232: loss: 0.5933378981:
INFO:__main__:6: 22432: loss: 0.5923255769:
INFO:__main__:6: 25632: loss: 0.5920932323:
INFO:__main__:6: 28832: loss: 0.5914914951:
INFO:__main__:Dev-Acc: 6: Accuracy: 0.2768891752: precision: 0.0659072944: recall: 0.8648189083: f1: 0.1224804335
INFO:__main__:Train-Acc: 6: Accuracy: 0.7203997374: precision: 0.6678515997: recall: 0.8769311682: f1: 0.7582423829
INFO:__main__:7: 3232: loss: 0.5845613074:
INFO:__main__:7: 6432: loss: 0.5838575912:
INFO:__main__:7: 9632: loss: 0.5843448007:
INFO:__main__:7: 12832: loss: 0.5840485708:
INFO:__main__:7: 16032: loss: 0.5839130602:
INFO:__main__:7: 19232: loss: 0.5828997111:
INFO:__main__:7: 22432: loss: 0.5827344417:
INFO:__main__:7: 25632: loss: 0.5823303323:
INFO:__main__:7: 28832: loss: 0.5818500625:
INFO:__main__:Dev-Acc: 7: Accuracy: 0.2859878540: precision: 0.0665634675: recall: 0.8627784390: f1: 0.1235918109
INFO:__main__:Train-Acc: 7: Accuracy: 0.7484715581: precision: 0.6980766207: recall: 0.8756820722: f1: 0.7768575761
INFO:__main__:8: 3232: loss: 0.5760767162:
INFO:__main__:8: 6432: loss: 0.5753682972:
INFO:__main__:8: 9632: loss: 0.5745068506:
INFO:__main__:8: 12832: loss: 0.5738356020:
INFO:__main__:8: 16032: loss: 0.5736897972:
INFO:__main__:8: 19232: loss: 0.5738122758:
INFO:__main__:8: 22432: loss: 0.5734218560:
INFO:__main__:8: 25632: loss: 0.5726474336:
INFO:__main__:8: 28832: loss: 0.5719524504:
INFO:__main__:Dev-Acc: 8: Accuracy: 0.2952551842: precision: 0.0675385024: recall: 0.8649889475: f1: 0.1252940235
INFO:__main__:Train-Acc: 8: Accuracy: 0.7756887078: precision: 0.7309068884: recall: 0.8726579449: f1: 0.7955172000
INFO:__main__:9: 3232: loss: 0.5693998510:
INFO:__main__:9: 6432: loss: 0.5669750218:
INFO:__main__:9: 9632: loss: 0.5665218327:
INFO:__main__:9: 12832: loss: 0.5654789200:
INFO:__main__:9: 16032: loss: 0.5638984244:
INFO:__main__:9: 19232: loss: 0.5630143844:
INFO:__main__:9: 22432: loss: 0.5623010167:
INFO:__main__:9: 25632: loss: 0.5622267744:
INFO:__main__:9: 28832: loss: 0.5620753536:
INFO:__main__:Dev-Acc: 9: Accuracy: 0.3058918118: precision: 0.0685368744: recall: 0.8653290257: f1: 0.1270138395
INFO:__main__:Train-Acc: 9: Accuracy: 0.8023799062: precision: 0.7664677597: recall: 0.8697653014: f1: 0.8148558758
INFO:__main__:10: 3232: loss: 0.5588147095:
INFO:__main__:10: 6432: loss: 0.5596634516:
INFO:__main__:10: 9632: loss: 0.5581573050:
INFO:__main__:10: 12832: loss: 0.5568433458:
INFO:__main__:10: 16032: loss: 0.5555238269:
INFO:__main__:10: 19232: loss: 0.5546206430:
INFO:__main__:10: 22432: loss: 0.5544171335:
INFO:__main__:10: 25632: loss: 0.5535213730:
INFO:__main__:10: 28832: loss: 0.5529019793:
INFO:__main__:Dev-Acc: 10: Accuracy: 0.3165879548: precision: 0.0694524181: recall: 0.8639687128: f1: 0.1285694404
INFO:__main__:Train-Acc: 10: Accuracy: 0.8242390752: precision: 0.7985833636: recall: 0.8672013674: f1: 0.8314790885
INFO:__main__:11: 3232: loss: 0.5498639584:
INFO:__main__:11: 6432: loss: 0.5469009633:
INFO:__main__:11: 9632: loss: 0.5468870648:
INFO:__main__:11: 12832: loss: 0.5458592738:
INFO:__main__:11: 16032: loss: 0.5452014114:
INFO:__main__:11: 19232: loss: 0.5447829973:
INFO:__main__:11: 22432: loss: 0.5443048214:
INFO:__main__:11: 25632: loss: 0.5434913331:
INFO:__main__:11: 28832: loss: 0.5432047301:
INFO:__main__:Dev-Acc: 11: Accuracy: 0.3281969428: precision: 0.0704379968: recall: 0.8619282435: f1: 0.1302331556
INFO:__main__:Train-Acc: 11: Accuracy: 0.8421537280: precision: 0.8274300094: recall: 0.8646374334: f1: 0.8456246383
INFO:__main__:12: 3232: loss: 0.5344842434:
INFO:__main__:12: 6432: loss: 0.5364948884:
INFO:__main__:12: 9632: loss: 0.5338241338:
INFO:__main__:12: 12832: loss: 0.5329189110:
INFO:__main__:12: 16032: loss: 0.5332630053:
INFO:__main__:12: 19232: loss: 0.5341664847:
INFO:__main__:12: 22432: loss: 0.5342275203:
INFO:__main__:12: 25632: loss: 0.5338776753:
INFO:__main__:12: 28832: loss: 0.5336942233:
INFO:__main__:Dev-Acc: 12: Accuracy: 0.3393990993: precision: 0.0714275627: recall: 0.8600578133: f1: 0.1319008006
INFO:__main__:Train-Acc: 12: Accuracy: 0.8580961823: precision: 0.8553627349: recall: 0.8619420156: f1: 0.8586397721
INFO:__main__:13: 3232: loss: 0.5239080152:
INFO:__main__:13: 6432: loss: 0.5276812890:
INFO:__main__:13: 9632: loss: 0.5290976402:
INFO:__main__:13: 12832: loss: 0.5275905444:
INFO:__main__:13: 16032: loss: 0.5269354976:
INFO:__main__:13: 19232: loss: 0.5264999536:
INFO:__main__:13: 22432: loss: 0.5259469393:
INFO:__main__:13: 25632: loss: 0.5251401260:
INFO:__main__:13: 28832: loss: 0.5245767547:
INFO:__main__:Dev-Acc: 13: Accuracy: 0.3501647115: precision: 0.0726860879: recall: 0.8620982826: f1: 0.1340684622
INFO:__main__:Train-Acc: 13: Accuracy: 0.8683190346: precision: 0.8775523957: recall: 0.8560909868: f1: 0.8666888519
INFO:__main__:14: 3232: loss: 0.5107928875:
INFO:__main__:14: 6432: loss: 0.5147007680:
INFO:__main__:14: 9632: loss: 0.5172352649:
INFO:__main__:14: 12832: loss: 0.5187359758:
INFO:__main__:14: 16032: loss: 0.5185253721:
INFO:__main__:14: 19232: loss: 0.5174534326:
INFO:__main__:14: 22432: loss: 0.5161024025:
INFO:__main__:14: 25632: loss: 0.5153650180:
INFO:__main__:14: 28832: loss: 0.5147201966:
INFO:__main__:Dev-Acc: 14: Accuracy: 0.3596602678: precision: 0.0736228429: recall: 0.8610780480: f1: 0.1356477017
INFO:__main__:Train-Acc: 14: Accuracy: 0.8750246763: precision: 0.8947477683: recall: 0.8500427322: f1: 0.8718225339
INFO:__main__:15: 3232: loss: 0.5073893341:
INFO:__main__:15: 6432: loss: 0.5092559707:
INFO:__main__:15: 9632: loss: 0.5094477717:
INFO:__main__:15: 12832: loss: 0.5081986062:
INFO:__main__:15: 16032: loss: 0.5091034094:
INFO:__main__:15: 19232: loss: 0.5075638416:
INFO:__main__:15: 22432: loss: 0.5069119750:
INFO:__main__:15: 25632: loss: 0.5064712327:
INFO:__main__:15: 28832: loss: 0.5054969702:
INFO:__main__:Dev-Acc: 15: Accuracy: 0.3695527017: precision: 0.0744294529: recall: 0.8573371876: f1: 0.1369680670
INFO:__main__:Train-Acc: 15: Accuracy: 0.8814674020: precision: 0.9106220367: recall: 0.8459667346: f1: 0.8771044919
INFO:__main__:16: 3232: loss: 0.4945095500:
INFO:__main__:16: 6432: loss: 0.4995371723:
INFO:__main__:16: 9632: loss: 0.5003510539:
INFO:__main__:16: 12832: loss: 0.4995005988:
INFO:__main__:16: 16032: loss: 0.4972250874:
INFO:__main__:16: 19232: loss: 0.4964091172:
INFO:__main__:16: 22432: loss: 0.4966628878:
INFO:__main__:16: 25632: loss: 0.4968159339:
INFO:__main__:16: 28832: loss: 0.4958950424:
INFO:__main__:Dev-Acc: 16: Accuracy: 0.3775797784: precision: 0.0751894307: recall: 0.8554667574: f1: 0.1382294758
INFO:__main__:Train-Acc: 16: Accuracy: 0.8860693574: precision: 0.9223908509: recall: 0.8430740911: f1: 0.8809507453
INFO:__main__:17: 3232: loss: 0.4893381599:
INFO:__main__:17: 6432: loss: 0.4898806600:
INFO:__main__:17: 9632: loss: 0.4903956900:
INFO:__main__:17: 12832: loss: 0.4894786254:
INFO:__main__:17: 16032: loss: 0.4889799510:
INFO:__main__:17: 19232: loss: 0.4890436310:
INFO:__main__:17: 22432: loss: 0.4878653639:
INFO:__main__:17: 25632: loss: 0.4873537070:
INFO:__main__:17: 28832: loss: 0.4873554546:
INFO:__main__:Dev-Acc: 17: Accuracy: 0.3853587806: precision: 0.0758371287: recall: 0.8522360143: f1: 0.1392802557
INFO:__main__:Train-Acc: 17: Accuracy: 0.8895865083: precision: 0.9312327172: recall: 0.8412990599: f1: 0.8839843885
INFO:__main__:18: 3232: loss: 0.4887784255:
INFO:__main__:18: 6432: loss: 0.4868877567:
INFO:__main__:18: 9632: loss: 0.4835807368:
INFO:__main__:18: 12832: loss: 0.4808734164:
INFO:__main__:18: 16032: loss: 0.4799452430:
INFO:__main__:18: 19232: loss: 0.4792079230:
INFO:__main__:18: 22432: loss: 0.4791163747:
INFO:__main__:18: 25632: loss: 0.4779323216:
INFO:__main__:18: 28832: loss: 0.4779270161:
INFO:__main__:Dev-Acc: 18: Accuracy: 0.3927111328: precision: 0.0767359305: recall: 0.8527461316: f1: 0.1408015723
INFO:__main__:Train-Acc: 18: Accuracy: 0.8924791813: precision: 0.9380686821: recall: 0.8404444152: f1: 0.8865772045
INFO:__main__:19: 3232: loss: 0.4664889839:
INFO:__main__:19: 6432: loss: 0.4676269712:
INFO:__main__:19: 9632: loss: 0.4677402766:
INFO:__main__:19: 12832: loss: 0.4705486665:
INFO:__main__:19: 16032: loss: 0.4702620046:
INFO:__main__:19: 19232: loss: 0.4702963930:
INFO:__main__:19: 22432: loss: 0.4700572744:
INFO:__main__:19: 25632: loss: 0.4694784618:
INFO:__main__:19: 28832: loss: 0.4684016527:
INFO:__main__:Dev-Acc: 19: Accuracy: 0.3998849094: precision: 0.0774243480: recall: 0.8505356232: f1: 0.1419288937
INFO:__main__:Train-Acc: 19: Accuracy: 0.8953389525: precision: 0.9458076952: recall: 0.8387351259: f1: 0.8890592334
INFO:__main__:20: 3232: loss: 0.4655861530:
INFO:__main__:20: 6432: loss: 0.4661059795:
INFO:__main__:20: 9632: loss: 0.4674430938:
INFO:__main__:20: 12832: loss: 0.4670546367:
INFO:__main__:20: 16032: loss: 0.4654678735:
INFO:__main__:20: 19232: loss: 0.4645754904:
INFO:__main__:20: 22432: loss: 0.4625073192:
INFO:__main__:20: 25632: loss: 0.4613982993:
INFO:__main__:20: 28832: loss: 0.4600870187:
INFO:__main__:Dev-Acc: 20: Accuracy: 0.4060465991: precision: 0.0780834766: recall: 0.8493453494: f1: 0.1430187113
INFO:__main__:Train-Acc: 20: Accuracy: 0.8969824910: precision: 0.9498621769: recall: 0.8382091907: f1: 0.8905496962
INFO:__main__:21: 3232: loss: 0.4541951263:
INFO:__main__:21: 6432: loss: 0.4529877079:
INFO:__main__:21: 9632: loss: 0.4546028022:
INFO:__main__:21: 12832: loss: 0.4539139282:
INFO:__main__:21: 16032: loss: 0.4525674111:
INFO:__main__:21: 19232: loss: 0.4522787357:
INFO:__main__:21: 22432: loss: 0.4525004059:
INFO:__main__:21: 25632: loss: 0.4519439343:
INFO:__main__:21: 28832: loss: 0.4513135136:
INFO:__main__:Dev-Acc: 21: Accuracy: 0.4123273492: precision: 0.0787441368: recall: 0.8478149974: f1: 0.1441040462
INFO:__main__:Train-Acc: 21: Accuracy: 0.8992177248: precision: 0.9549029890: recall: 0.8380119650: f1: 0.8926470588
INFO:__main__:22: 3232: loss: 0.4444798744:
INFO:__main__:22: 6432: loss: 0.4440705438:
INFO:__main__:22: 9632: loss: 0.4450768235:
INFO:__main__:22: 12832: loss: 0.4450406708:
INFO:__main__:22: 16032: loss: 0.4461016576:
INFO:__main__:22: 19232: loss: 0.4452893335:
INFO:__main__:22: 22432: loss: 0.4445210512:
INFO:__main__:22: 25632: loss: 0.4440591943:
INFO:__main__:22: 28832: loss: 0.4433911558:
INFO:__main__:Dev-Acc: 22: Accuracy: 0.4172884524: precision: 0.0792637294: recall: 0.8464546846: f1: 0.1449537010
INFO:__main__:Train-Acc: 22: Accuracy: 0.9005325437: precision: 0.9584618858: recall: 0.8373545461: f1: 0.8938245614
INFO:__main__:23: 3232: loss: 0.4386820972:
INFO:__main__:23: 6432: loss: 0.4396565862:
INFO:__main__:23: 9632: loss: 0.4373664287:
INFO:__main__:23: 12832: loss: 0.4367290066:
INFO:__main__:23: 16032: loss: 0.4357438810:
INFO:__main__:23: 19232: loss: 0.4357745462:
INFO:__main__:23: 22432: loss: 0.4364657014:
INFO:__main__:23: 25632: loss: 0.4353659467:
INFO:__main__:23: 28832: loss: 0.4351431346:
INFO:__main__:Dev-Acc: 23: Accuracy: 0.4220808744: precision: 0.0797296863: recall: 0.8445842544: f1: 0.1457046891
INFO:__main__:Train-Acc: 23: Accuracy: 0.9017487764: precision: 0.9607902277: recall: 0.8376832555: f1: 0.8950233555
INFO:__main__:24: 3232: loss: 0.4336602545:
INFO:__main__:24: 6432: loss: 0.4300043012:
INFO:__main__:24: 9632: loss: 0.4296813737:
INFO:__main__:24: 12832: loss: 0.4292984265:
INFO:__main__:24: 16032: loss: 0.4282266959:
INFO:__main__:24: 19232: loss: 0.4285380619:
INFO:__main__:24: 22432: loss: 0.4284230378:
INFO:__main__:24: 25632: loss: 0.4277529250:
INFO:__main__:24: 28832: loss: 0.4270571225:
INFO:__main__:Dev-Acc: 24: Accuracy: 0.4268336296: precision: 0.0802931517: recall: 0.8439040979: f1: 0.1466347574
INFO:__main__:Train-Acc: 24: Accuracy: 0.9026362896: precision: 0.9629601633: recall: 0.8374860298: f1: 0.8958509142
INFO:__main__:25: 3232: loss: 0.4290444434:
INFO:__main__:25: 6432: loss: 0.4263311811:
INFO:__main__:25: 9632: loss: 0.4243350623:
INFO:__main__:25: 12832: loss: 0.4230059592:
INFO:__main__:25: 16032: loss: 0.4214029645:
INFO:__main__:25: 19232: loss: 0.4205225367:
INFO:__main__:25: 22432: loss: 0.4196162350:
INFO:__main__:25: 25632: loss: 0.4185921713:
INFO:__main__:25: 28832: loss: 0.4185256044:
INFO:__main__:Dev-Acc: 25: Accuracy: 0.4301575720: precision: 0.0807034097: recall: 0.8435640197: f1: 0.1473134085
INFO:__main__:Train-Acc: 25: Accuracy: 0.9034909606: precision: 0.9641533691: recall: 0.8381434488: f1: 0.8967433354
INFO:__main__:26: 3232: loss: 0.4170272061:
INFO:__main__:26: 6432: loss: 0.4153360701:
INFO:__main__:26: 9632: loss: 0.4160773020:
INFO:__main__:26: 12832: loss: 0.4130856262:
INFO:__main__:26: 16032: loss: 0.4126115649:
INFO:__main__:26: 19232: loss: 0.4127579211:
INFO:__main__:26: 22432: loss: 0.4123420994:
INFO:__main__:26: 25632: loss: 0.4112104895:
INFO:__main__:26: 28832: loss: 0.4112664227:
INFO:__main__:Dev-Acc: 26: Accuracy: 0.4336501658: precision: 0.0812367087: recall: 0.8444142153: f1: 0.1482144723
INFO:__main__:Train-Acc: 26: Accuracy: 0.9039840102: precision: 0.9658126137: recall: 0.8376175136: f1: 0.8971587508
INFO:__main__:27: 3232: loss: 0.3996470189:
INFO:__main__:27: 6432: loss: 0.4044983041:
INFO:__main__:27: 9632: loss: 0.4034441282:
INFO:__main__:27: 12832: loss: 0.4024519814:
INFO:__main__:27: 16032: loss: 0.4021335835:
INFO:__main__:27: 19232: loss: 0.4021511608:
INFO:__main__:27: 22432: loss: 0.4025114383:
INFO:__main__:27: 25632: loss: 0.4021485681:
INFO:__main__:27: 28832: loss: 0.4028955036:
INFO:__main__:Dev-Acc: 27: Accuracy: 0.4360910356: precision: 0.0814136900: recall: 0.8425437851: f1: 0.1484799904
INFO:__main__:Train-Acc: 27: Accuracy: 0.9043455720: precision: 0.9661941939: recall: 0.8380119650: f1: 0.8975496409
INFO:__main__:28: 3232: loss: 0.3943917972:
INFO:__main__:28: 6432: loss: 0.3922292855:
INFO:__main__:28: 9632: loss: 0.3938037228:
INFO:__main__:28: 12832: loss: 0.3954414883:
INFO:__main__:28: 16032: loss: 0.3957403665:
INFO:__main__:28: 19232: loss: 0.3962296969:
INFO:__main__:28: 22432: loss: 0.3960743342:
INFO:__main__:28: 25632: loss: 0.3957636111:
INFO:__main__:28: 28832: loss: 0.3961983255:
INFO:__main__:Dev-Acc: 28: Accuracy: 0.4390280247: precision: 0.0818668075: recall: 0.8432239415: f1: 0.1492438492
INFO:__main__:Train-Acc: 28: Accuracy: 0.9050030112: precision: 0.9668813945: recall: 0.8387351259: f1: 0.8982609308
INFO:__main__:29: 3232: loss: 0.3908285016:
INFO:__main__:29: 6432: loss: 0.3905419688:
INFO:__main__:29: 9632: loss: 0.3923726223:
INFO:__main__:29: 12832: loss: 0.3919084676:
INFO:__main__:29: 16032: loss: 0.3907679672:
INFO:__main__:29: 19232: loss: 0.3899294443:
INFO:__main__:29: 22432: loss: 0.3884811628:
INFO:__main__:29: 25632: loss: 0.3883668701:
INFO:__main__:29: 28832: loss: 0.3883660899:
INFO:__main__:Dev-Acc: 29: Accuracy: 0.4411613047: precision: 0.0821307265: recall: 0.8428838633: f1: 0.1496769129
INFO:__main__:Train-Acc: 29: Accuracy: 0.9056932926: precision: 0.9679963598: recall: 0.8391295773: f1: 0.8989682009
INFO:__main__:30: 3232: loss: 0.3717087272:
INFO:__main__:30: 6432: loss: 0.3787361434:
INFO:__main__:30: 9632: loss: 0.3813305281:
INFO:__main__:30: 12832: loss: 0.3841085830:
INFO:__main__:30: 16032: loss: 0.3841757123:
INFO:__main__:30: 19232: loss: 0.3830032573:
INFO:__main__:30: 22432: loss: 0.3828594674:
INFO:__main__:30: 25632: loss: 0.3818195196:
INFO:__main__:30: 28832: loss: 0.3819710297:
INFO:__main__:Dev-Acc: 30: Accuracy: 0.4426397085: precision: 0.0822368421: recall: 0.8416935895: f1: 0.1498342742
INFO:__main__:Train-Acc: 30: Accuracy: 0.9065150619: precision: 0.9684114840: recall: 0.8404444152: f1: 0.8999014501
INFO:__main__:31: 3232: loss: 0.3857671228:
INFO:__main__:31: 6432: loss: 0.3798370472:
INFO:__main__:31: 9632: loss: 0.3765326438:
INFO:__main__:31: 12832: loss: 0.3758984944:
INFO:__main__:31: 16032: loss: 0.3760365293:
INFO:__main__:31: 19232: loss: 0.3750690061:
INFO:__main__:31: 22432: loss: 0.3752073632:
INFO:__main__:31: 25632: loss: 0.3751834939:
INFO:__main__:31: 28832: loss: 0.3752374985:
INFO:__main__:Dev-Acc: 31: Accuracy: 0.4443562329: precision: 0.0824877959: recall: 0.8418636286: f1: 0.1502534066
INFO:__main__:Train-Acc: 31: Accuracy: 0.9073368311: precision: 0.9684711931: recall: 0.8420879627: f1: 0.9008685867
INFO:__main__:32: 3232: loss: 0.3766319108:
INFO:__main__:32: 6432: loss: 0.3742325774:
INFO:__main__:32: 9632: loss: 0.3727300743:
INFO:__main__:32: 12832: loss: 0.3716771314:
INFO:__main__:32: 16032: loss: 0.3703273897:
INFO:__main__:32: 19232: loss: 0.3703156548:
INFO:__main__:32: 22432: loss: 0.3691897986:
INFO:__main__:32: 25632: loss: 0.3694172701:
INFO:__main__:32: 28832: loss: 0.3689207675:
INFO:__main__:Dev-Acc: 32: Accuracy: 0.4452194870: precision: 0.0825936061: recall: 0.8416935895: f1: 0.1504262076
INFO:__main__:Train-Acc: 32: Accuracy: 0.9079613686: precision: 0.9690121684: recall: 0.8428768654: f1: 0.9015540398
INFO:__main__:33: 3232: loss: 0.3689175531:
INFO:__main__:33: 6432: loss: 0.3680482206:
INFO:__main__:33: 9632: loss: 0.3667433616:
INFO:__main__:33: 12832: loss: 0.3662055689:
INFO:__main__:33: 16032: loss: 0.3664681565:
INFO:__main__:33: 19232: loss: 0.3664646172:
INFO:__main__:33: 22432: loss: 0.3651115490:
INFO:__main__:33: 25632: loss: 0.3646743329:
INFO:__main__:33: 28832: loss: 0.3639400761:
INFO:__main__:Dev-Acc: 33: Accuracy: 0.4458842576: precision: 0.0826721013: recall: 0.8415235504: f1: 0.1505536627
INFO:__main__:Train-Acc: 33: Accuracy: 0.9089146256: precision: 0.9693631150: recall: 0.8445204129: f1: 0.9026455398
INFO:__main__:34: 3232: loss: 0.3552496088:
INFO:__main__:34: 6432: loss: 0.3547588897:
INFO:__main__:34: 9632: loss: 0.3554763685:
INFO:__main__:34: 12832: loss: 0.3546952780:
INFO:__main__:34: 16032: loss: 0.3556334705:
INFO:__main__:34: 19232: loss: 0.3569584495:
INFO:__main__:34: 22432: loss: 0.3562083893:
INFO:__main__:34: 25632: loss: 0.3557754169:
INFO:__main__:34: 28832: loss: 0.3562182193:
INFO:__main__:Dev-Acc: 34: Accuracy: 0.4462414682: precision: 0.0827357970: recall: 0.8416935895: f1: 0.1506619997
INFO:__main__:Train-Acc: 34: Accuracy: 0.9092433453: precision: 0.9689618804: recall: 0.8455722832: f1: 0.9030717922
INFO:__main__:35: 3232: loss: 0.3524916744:
INFO:__main__:35: 6432: loss: 0.3521444255:
INFO:__main__:35: 9632: loss: 0.3526559544:
INFO:__main__:35: 12832: loss: 0.3527174498:
INFO:__main__:35: 16032: loss: 0.3529408339:
INFO:__main__:35: 19232: loss: 0.3525593924:
INFO:__main__:35: 22432: loss: 0.3512333580:
INFO:__main__:35: 25632: loss: 0.3505114726:
INFO:__main__:35: 28832: loss: 0.3501503144:
INFO:__main__:Dev-Acc: 35: Accuracy: 0.4461918473: precision: 0.0827567766: recall: 0.8420336677: f1: 0.1507022322
INFO:__main__:Train-Acc: 35: Accuracy: 0.9095720649: precision: 0.9691971682: recall: 0.8460324765: f1: 0.9034364141
INFO:__main__:36: 3232: loss: 0.3424740136:
INFO:__main__:36: 6432: loss: 0.3447008077:
INFO:__main__:36: 9632: loss: 0.3453092413:
INFO:__main__:36: 12832: loss: 0.3440668476:
INFO:__main__:36: 16032: loss: 0.3459294419:
INFO:__main__:36: 19232: loss: 0.3469644260:
INFO:__main__:36: 22432: loss: 0.3463507993:
INFO:__main__:36: 25632: loss: 0.3454473437:
INFO:__main__:36: 28832: loss: 0.3447681995:
INFO:__main__:Dev-Acc: 36: Accuracy: 0.4464994371: precision: 0.0827996723: recall: 0.8420336677: f1: 0.1507733528
INFO:__main__:Train-Acc: 36: Accuracy: 0.9099007845: precision: 0.9694323144: recall: 0.8464926698: f1: 0.9038009336
INFO:__main__:37: 3232: loss: 0.3337081920:
INFO:__main__:37: 6432: loss: 0.3353139729:
INFO:__main__:37: 9632: loss: 0.3369998597:
INFO:__main__:37: 12832: loss: 0.3405503249:
INFO:__main__:37: 16032: loss: 0.3414638373:
INFO:__main__:37: 19232: loss: 0.3401304639:
INFO:__main__:37: 22432: loss: 0.3400548484:
INFO:__main__:37: 25632: loss: 0.3396031230:
INFO:__main__:37: 28832: loss: 0.3398274446:
INFO:__main__:Dev-Acc: 37: Accuracy: 0.4456957281: precision: 0.0827712855: recall: 0.8430539024: f1: 0.1507426156
INFO:__main__:Train-Acc: 37: Accuracy: 0.9106896520: precision: 0.9697698902: recall: 0.8478075077: f1: 0.9046967624
INFO:__main__:38: 3232: loss: 0.3436998521:
INFO:__main__:38: 6432: loss: 0.3426310828:
INFO:__main__:38: 9632: loss: 0.3406412145:
INFO:__main__:38: 12832: loss: 0.3383712398:
INFO:__main__:38: 16032: loss: 0.3370932646:
INFO:__main__:38: 19232: loss: 0.3361835776:
INFO:__main__:38: 22432: loss: 0.3360122881:
INFO:__main__:38: 25632: loss: 0.3338812965:
INFO:__main__:38: 28832: loss: 0.3339294812:
INFO:__main__:Dev-Acc: 38: Accuracy: 0.4452293813: precision: 0.0827203123: recall: 0.8432239415: f1: 0.1506607930
INFO:__main__:Train-Acc: 38: Accuracy: 0.9111827612: precision: 0.9705107952: recall: 0.8481362172: f1: 0.9052062868
INFO:__main__:39: 3232: loss: 0.3333985941:
INFO:__main__:39: 6432: loss: 0.3295026683:
INFO:__main__:39: 9632: loss: 0.3285125159:
INFO:__main__:39: 12832: loss: 0.3281359253:
INFO:__main__:39: 16032: loss: 0.3265471604:
INFO:__main__:39: 19232: loss: 0.3271337057:
INFO:__main__:39: 22432: loss: 0.3284630696:
INFO:__main__:39: 25632: loss: 0.3288183933:
INFO:__main__:39: 28832: loss: 0.3291335563:
INFO:__main__:Dev-Acc: 39: Accuracy: 0.4448622763: precision: 0.0827944804: recall: 0.8447542935: f1: 0.1508082265
INFO:__main__:Train-Acc: 39: Accuracy: 0.9117415547: precision: 0.9706899143: recall: 0.8491223457: f1: 0.9058456359
INFO:__main__:40: 3232: loss: 0.3269752896:
INFO:__main__:40: 6432: loss: 0.3269599019:
INFO:__main__:40: 9632: loss: 0.3285204524:
INFO:__main__:40: 12832: loss: 0.3302540042:
INFO:__main__:40: 16032: loss: 0.3278412936:
INFO:__main__:40: 19232: loss: 0.3267505492:
INFO:__main__:40: 22432: loss: 0.3262187851:
INFO:__main__:40: 25632: loss: 0.3267640453:
INFO:__main__:40: 28832: loss: 0.3246326442:
INFO:__main__:Dev-Acc: 40: Accuracy: 0.4437311292: precision: 0.0826513639: recall: 0.8449243326: f1: 0.1505734762
INFO:__main__:Train-Acc: 40: Accuracy: 0.9124975801: precision: 0.9707404907: recall: 0.8506344093: f1: 0.9067274001
INFO:__main__:41: 3232: loss: 0.3266812624:
INFO:__main__:41: 6432: loss: 0.3248008453:
INFO:__main__:41: 9632: loss: 0.3222297499:
INFO:__main__:41: 12832: loss: 0.3227929804:
INFO:__main__:41: 16032: loss: 0.3205381963:
INFO:__main__:41: 19232: loss: 0.3201281744:
INFO:__main__:41: 22432: loss: 0.3198118331:
INFO:__main__:41: 25632: loss: 0.3208338628:
INFO:__main__:41: 28832: loss: 0.3197108551:
INFO:__main__:Dev-Acc: 41: Accuracy: 0.4428083897: precision: 0.0825791667: recall: 0.8456044890: f1: 0.1504644338
INFO:__main__:Train-Acc: 41: Accuracy: 0.9132207632: precision: 0.9712828972: recall: 0.8516205378: f1: 0.9075241698
INFO:__main__:42: 3232: loss: 0.3171657394:
INFO:__main__:42: 6432: loss: 0.3229554363:
INFO:__main__:42: 9632: loss: 0.3195483443:
INFO:__main__:42: 12832: loss: 0.3177819953:
INFO:__main__:42: 16032: loss: 0.3150971823:
INFO:__main__:42: 19232: loss: 0.3135318808:
INFO:__main__:42: 22432: loss: 0.3134280019:
INFO:__main__:42: 25632: loss: 0.3154088340:
INFO:__main__:42: 28832: loss: 0.3145147207:
INFO:__main__:Dev-Acc: 42: Accuracy: 0.4412307441: precision: 0.0824170365: recall: 0.8462846455: f1: 0.1502059787
INFO:__main__:Train-Acc: 42: Accuracy: 0.9141082764: precision: 0.9716232405: recall: 0.8531326014: f1: 0.9085308223
INFO:__main__:43: 3232: loss: 0.3127363455:
INFO:__main__:43: 6432: loss: 0.3135841397:
INFO:__main__:43: 9632: loss: 0.3096876269:
INFO:__main__:43: 12832: loss: 0.3122864603:
INFO:__main__:43: 16032: loss: 0.3117124452:
INFO:__main__:43: 19232: loss: 0.3109826720:
INFO:__main__:43: 22432: loss: 0.3103067612:
INFO:__main__:43: 25632: loss: 0.3102291784:
INFO:__main__:43: 28832: loss: 0.3100790275:
INFO:__main__:Dev-Acc: 43: Accuracy: 0.4404369593: precision: 0.0823218125: recall: 0.8464546846: f1: 0.1500504891
INFO:__main__:Train-Acc: 43: Accuracy: 0.9146999121: precision: 0.9722263812: recall: 0.8537900204: f1: 0.9091672792
